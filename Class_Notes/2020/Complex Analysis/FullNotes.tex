\input{"/home/zack/Dropbox/Document Archive/Latex/preamble.tex"}
\let\Begin\begin
\let\End\end
\newcommand\wrapenv[1]{#1}

\makeatletter
\def\ScaleWidthIfNeeded{%
 \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\def\ScaleHeightIfNeeded{%
  \ifdim\Gin@nat@height>0.9\textheight
    0.9\textheight
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\setkeys{Gin}{width=\ScaleWidthIfNeeded,height=\ScaleHeightIfNeeded,keepaspectratio}%

\title{
\textbf{
    Full Notes
  }
  }
\author{D. Zack Garza}
\date{\today}

\begin{document}

\maketitle
% \todo{Insert title and subtitle.}
\tableofcontents


\hypertarget{friday-january-10}{%
\section{Friday January 10}\label{friday-january-10}}

Recall that \(\CC\) is a field, where
\(z = x + iy \implies \bar z = x - iy\), and if \(z\neq 0\) then
\(z\inv = \bar z / \abs{z}^2\).

\textbf{Lemma (Triangle Inequality:}
\(\abs{z + w} \leq \abs z + \abs w\)

\emph{Proof:} \begin{align*}
(\abs z + \abs w)^2 - \abs{z+w}^2 = 2( \abs{z\bar w} - \Re z\bar w ) \geq 0
.\end{align*}

\textbf{Lemma (Reverse Triangle Inequality):}
\(\abs{\abs z - \abs w} \leq \abs{z-w}\).

\emph{Proof:} \begin{align*}
\abs z = \abs{z-w + w} \leq \abs{z-w} + \abs w \implies \abs w - \abs z \leq \abs{z-w} = \abs{w-z}
.\end{align*}

\textbf{Claim:} \((\CC, \abs{\wait})\) is a normed space.

\textbf{Definition:} \(\lim z_n = z \iff \abs{z_n - z} \to 0 \in \RR\).

\textbf{Definition:} A disc is defined as
\(D_r(z_0) \definedas \theset{z\in\CC \suchthat \abs{z-z_0} < r}\), and
a subset is open iff it contains a disc. By convention, \(D_r\) denotes
a disc about \(z_0 = 0\).

\textbf{Definition:} \(\sum_k z_k\) converges iff
\(S_N \definedas \sum_{\abs k < N} z_k\) converges.

Note that \(z_n \to z\) and \(z_n = x_n + iy_n\), and
\begin{align*}\abs{z_n - z} = \sqrt{(x_n - x)^2 - (y_n - y)^2} < \varepsilon \implies \abs{x - x_n}, \abs{y - y_n} < \varepsilon.\end{align*}

Since \(\RR\) is complete iff every Cauchy sequence converges iff every
bounded monotone sequence has a limit.

\begin{quote}
Note: This is useful precisely when you don't know the limiting term.
\end{quote}

Note that \(\sum_k z_k\) thus converges if
\(\abs{\sum_{k=m}^n z_k} < \varepsilon\) for \(m, n\) large enough, so
sums converges iff they have small tails.

\textbf{Definition:} \(S_N = \sum^N z_k\) converges absolutely iff
\(\tilde S \definedas \sum^N \abs{z_k}\) converges.

Note that the partial sums \(\sum^N \abs{z_k}\) are monotone, so
\(\tilde S_N\) converges iff the partial sums are bounded above.

\textbf{Definition:} A sum of the form \(\sum_{k=0}^\infty a_k z_k\) is
a power series.

\emph{Examples}:

\begin{align*}
\sum x^k &= \frac 1 {1-x} \\
\sum (-x^2)^k &= \frac 1 {1+x^2}
.\end{align*}

Note that both of these have a radius of convergence equal to 1, since
the first has a pole at \(x=1\) and the second as a pole at \(x = i\).

\hypertarget{monday-january-13th}{%
\section{Monday January 13th}\label{monday-january-13th}}

Recall that \(\sum z_k\) converges iff \(s_n = \sum_{k=1}^n z_k\)
converges.

\textbf{Lemma:} Absolute convergence implies convergence.

The most interesting series: \(f(z) = \sum a_k z^k\), i.e.~power series.

\textbf{Divergence lemma:} If \(\sum z_k\) converges, then
\(\lim z_k = 0\).

\emph{Corollary:} If \(\sum z_k\) converges, \(\theset{z_k}\) is
uniformly bounded by a constant \(C > 0\), i.e.~\(\abs{z_k} < C\) for
all \(k\).

\textbf{Proposition:} If \(\sum a_k z_k\) converges at some point
\(z_0\), then it converges for all \(\abs z < \abs z_0\).

The inequality is necessarily strict. For example,
\(\sum \frac{z^{n-1}}{n}\) converges at \(z=-1\) (alternating harmonic
series) but not at \(z=1\) (harmonic series).

\emph{Proof:} Suppose \(\sum a_k z_1^k\) converges. The terms are
uniformly bounded, so \(\abs{a_k z_1^k} \leq C\) for all \(k\). Then we
have
\begin{align*}\abs {a_k} \leq C/\abs{z_1}^k\end{align*}, so if
\(\abs z < \abs{z_1}\) we have
\begin{align*}\abs{a_k z^k} \leq \abs{z}^k \frac{C}{\abs{z_1}^k} = C (\abs{z} / \abs{z_1} )^k.\end{align*}
So if \(\abs{z} < \abs{z_1}\), the parenthesized quantity is less than
1, and the original series is bounded by a geometric series. Letting
\(r = \abs{z} / \abs{z_1}\), we have

\begin{align*}
\sum \abs{a_k z^k} \leq \sum c r^k = \frac{c}{1-r}
,\end{align*}

and so we have absolute convergence.

\(\qed\)

\emph{Exercise (future problem set):} Show that
\(\sum \frac 1 k z^{k-1}\) converges for all \(\abs{z} = 1\) except for
\(z = 1\). (Use summation by parts.)

Definition The radius of convergence is the real number \(R\) such that
\(f(z) = \sum a_k z^k\) converges precisely for \(\abs z < R\) and
diverges for \(\abs z > R\). We denote a disc of radius \(R\) centered
at zero by \(D_R\).

If \(R=\infty\), then \(f\) is said to be \emph{entire}.

\textbf{Proposition:} Suppose that \(\sum a_k z^k\) converges for all
\(\abs{z} < R\). Then \(f(z) = \sum a_k z^k\) is continuous on \(D_R\),
i.e.~using the sequential definition of continuity,
\(\lim_{z\to z_0} f(z) = f(z_0)\) for all \(z_0 \in D_R\).

Recall that \(S_n(z) \to S(z)\) uniformly on \(\Omega\) iff
\(\forall \varepsilon > 0\), there exists a \(M\in \NN\) such that
\(n> M \implies \abs{S_n(z) - S(z)} < \varepsilon\) for all
\(z\in \Omega\)

Note that arbitrary limits of continuous functions may not be
continuous. Counterexample: \(f_n(x) = x^n\) on \([0, 1]\); then
\(f_n \to \delta(1)\). Note that it uniformly converges on
\([0, 1-\varepsilon]\) for any \(\varepsilon > 0\).

\emph{Exercise:} Show that the uniform limit of continuous functions is
continuous.

\begin{quote}
Hint: Use the triangle inequality.
\end{quote}

Proof of proposition: Write
\(f(z) = \sum_{k=0}^N a_k z^k + \sum_{N+1}^\infty a_k z^k \definedas S_N(z) + R_N(z)\).
Note that if \(\abs{z} < R\), then there exists a \(T\) such that
\(\abs{z} < T < R\) where \(f(z)\) converges uniformly on \(D_T\).

\begin{quote}
Check!
\end{quote}

We need to show that \(\abs{R_N(z)}\) is uniformly small for
\(\abs{z} < s < T\). Note that \(\sum a_k z^k\) converges on \(D_T\), so
we can find a \(C\) such that \(\abs{a_k z^k} \leq C\) for all \(k\).
Then \(\abs{a_k} \leq C/T^k\) for all \(k\), and so

\begin{align*}
\abs{\sum_{k=N+1}^\infty a_k z^k}
&\leq \sum_{k=N+1}^\infty \abs{a_k} \abs{z}^k \\
&\leq \sum_{k=N+1}^\infty  (c/T^k) s^k \\
&= c\sum \abs{s/T}^k \\
&= c \frac{r^{N+!}}{1-r}
&= C \varepsilon_n \to 0
,\end{align*}

which follows because \(0 < r = s/T < 1\).

So \(S_N(z) \to f(z)\) uniformly on \(\abs{z} < s\) and \(S_N(z)\) are
all continuous, so \(f(z)\) is continuous.

There are two ways to compute the radius of convergence:

\begin{itemize}
\tightlist
\item
  Root test: \(\lim_k \abs{a_k}^{1/k} = L \implies R = \frac 1 L\).
\item
  Ratio test: \(\lim_k \abs{a_{k+1} / a_k} = L \implies R = \frac 1 L\).
\end{itemize}

As long as these series converge, we can compute derivatives and
integrals term-by-term, and they have the same radius of convergence.

\hypertarget{wednesday-january-15th}{%
\section{Wednesday January 15th}\label{wednesday-january-15th}}

See references: Taylor's Complex Analysis, Stein, Barry Simon (5 volume
set), Hormander (technically a PDEs book, but mostly analysis)

Good Paper:
\href{https://projecteuclid.org/download/pdf_1/euclid.acta/1485892151}{Hormander
1955}

We'll mostly be working from Simon Vol. 2A, most problems from from
Stein's Complex.

\hypertarget{topology-and-algebra-of-cc}{%
\subsection{\texorpdfstring{Topology and Algebra of
\(\CC\)}{Topology and Algebra of \textbackslash CC}}\label{topology-and-algebra-of-cc}}

To do analysis, we'll need the following notions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Continuity of a complex-valued function \(f: \Omega \to \Omega\)
\item
  Complex-differentiability: For \(\Omega \subset \CC\) open and
  \(z_0 \in \Omega\), there exists \(\varepsilon > 0\) such that
  \(D_\varepsilon = \theset{z \suchthat \abs{z - z_0} < \varepsilon} \subset \Omega\),
  and \(f\) is \textbf{holomorphic} (complex-differentiable) at \(z_0\)
  iff
  \begin{align*}\lim_{h\to 0} \frac 1 h (f(z_0 + h) - f(z_0))\end{align*}
  exists; if so we denote it by \(f'(z_0)\).
\end{enumerate}

\emph{Example:} \(f(z) = z\) is holomorphic, since
\(f(z+ h) - f(z) = z+h-z = h\), so \(f'(z_0) = \frac h h = 1\) for all
\(z_0\).

\emph{Example:} Given \(f(z) = \bar z\), we have
\(f(z+h)-f(z) = \bar h\), so the ratio is \(\frac{\bar h}{h}\) and the
limit doesn't exist. Note that if \(h\in \RR\), then \(\bar h = h\) and
the ratio is identically 1, while if \(h\) is purely imaginary, then
\(\bar h = -h\) and the limit is identically \(-1\).

We say \(f\) is holomorphic on an open set \(\Omega\) iff it is
holomorphic at every point, and is holomorphic on a closed set \(C\) iff
there exists an open \(\Omega \supset C\) such that \(f\) is holomorphic
on \(\Omega\).

If \(f\) is holomorphic, writing \(h = h_1 + ih_2\), then the following
two limits exist and are equal:

\begin{align*}
\lim_{h_1 \to 0} \frac{f(x_0 + iy_0 + h_1) - f(x_0 + iy_0)}{h_1} = \dd{f}{x}(x_0, y_0) \\
\lim_{h_2 \to 0} \frac{f(x_0 + iy_0 + ih_2) - f(x_0 + iy_0)}{ih_2} = \frac 1 i \dd{f}{y}(x_0, y_0) \\
\implies \dd{f}{x} = \frac 1  i \dd{f}{y}
.\end{align*}

So if we write \(f(z) = u(x, y) + i v(x, y)\), we have

\begin{align*}
\dd{u}{x} + i \dd{v}{x} \mid_{(x_0, y_0)} = \frac 1 i \qty{
\dd{u}{y} + i \dd{v}{y}
} \mid_{(x_0, y_0)}
,\end{align*}

and equating real and imaginary parts yields the Cauchy-Riemann
equations:

\begin{align*}
\dd{u}{x} + i \dd{v}{x} = -i \dd{u}{y} + \dd{v}{y} \\
\iff \dd{u}{x} = \dd{v}{y} \quad\text{and}\quad \dd{u}{y} = - \dd{v}{x}
.\end{align*}

The usual rules of derivatives apply:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \((\sum f)' = \sum f'\)
\end{enumerate}

\begin{quote}
Proof: Direct.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \((\prod f)' =\) product rule
\end{enumerate}

\begin{quote}
Proof: Consider \((f(z+h)g(z+h) - f(z)g(z))/h\) and use continuity of
\(g\) at \(z\).
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Quotient rule
\end{enumerate}

\begin{quote}
Proof: Nice trick, write \(q = \frac f g\) so \(qg = f\), then
\(f' = q'g + qg'\)and \(q' = \frac {f'} g - \frac{fg'}{g^2}\).
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Chain rule
\end{enumerate}

\begin{quote}
Proof: Use the fact that if \(f'(g(z)) = a\), then
\begin{align*}f(z+h) - f(z) = a h + r(z, h),\quad \abs{r(z, h)} = o(\abs h) \to 0.\end{align*}
Write \(b = g'(z)\), then
\begin{align*}f(g(z + h)) = f(g(z) + b h + r_1 ) = f(g(z)) + f'(g(z))bh + r_2\end{align*}
by considering error terms, and so
\begin{align*}\frac 1 h (f(g(z+h)) - f(g(z))) \to f'(g(z)) g'(z)\end{align*}.
\end{quote}

\hypertarget{friday-january-17th}{%
\section{Friday January 17th}\label{friday-january-17th}}

Reference: See Lang's Complex Analysis, there are plenty of solution
manuals.

Let \(f; \Omega \to \CC\) be a complex-valued function. Recall that
\(f\) is \emph{complex differentiable} iff the usual ratio/limit exists.
Note that \(h = x+iy\) and \(h\to 0 \iff x,y\to 0\).

We can write \(f'(z) = \dd{f}{x} = \frac 1 i \dd{f}{y}\). This follows
from Cauchy-Riemann since \(u_x = v_y\) and \(u_y = -v_x\).

Definition: We want to define \(\del, \bar \del\) operators. We have the
identities

\begin{align*}
x = \frac{z + \bar z}{z} \quad y = \frac{z - \bar z}{iz}
.\end{align*}

We can then write

\begin{align*}
dz = dx + idy \\
d\bar z = dx - i dy
.\end{align*}

We define the dual operators by \(\inner{\dd{}{z}}{dz} = 1\) and
similarly \(\inner{ \dd{}{\bar z} }{d\bar z} = 1\). By the chain rule,
we can write

\begin{align*}
f_z &= f_x x_z + f_y y_z \\
&= \frac 1 2 f_x + f_y \frac{1}{2i} \\
&= \frac 1 2 \qty{\dd{}{x} + i \dd{}{y} }f 
,\end{align*}

and similarly
\(f_{\bar z} = f_x x_{\bar z} + f_y z_{\bar z} = \frac 1 2 \qty{ \dd{}{x} - \frac{1}{2i} \dd{}{y} }f\).

We thus find \(\del_x = \del_z + \del_{\bar z}\) and
\(\del_y = i\qty{ \del_z - \del_{\bar z} }\), and define

\begin{align*}
\del f &= \dd{f}{z} dz \\
\bar{\del} f &= \dd{f}{\bar z} d\bar z \\
df = f_z dz + f_{\bar z} d\bar z
.\end{align*}

Proposition: \(f\) is holomorphic iff \(f_{\bar z} = 0\).

\begin{quote}
This means that \(f\) depends on \(z\) alone and not \(\bar z\).
\end{quote}

Proof: \(\bar \del f = 0\) iff \(\frac 1 2 (f_x + if_y) = 0\), so
\((u_x - v_y) + i (v_x + u_y) = 0\). \(\qed\)

Application to PDEs: We can write \(u_{xx} = v_{xy}, u_{yy} = v_{yx}\)
and so \(u_{xx} + u_{yy} = 0 = v_{xx} + v_{yy}\). Thus \(\Delta f = 0\),
and \(f\) satisfies Laplace's equation and is said to be
\emph{harmonic}.

Corollary: If \(f\) is analytic, then \(u, v\) are both harmonic
functions.

\textbf{Theorem (Chain Rule):} Let \(w = f(z)\) and \(g(w) = g(f(z))\).
Then

\begin{align*}
h_z &= g_w f_z + g_{\bar w} \bar f_z \\
h_{\bar z} &= g_w f_{\bar z} + g_{\bar w} \bar f_{\bar z}
.\end{align*}

If \(f, g\) are holomorphic, \(f_{\bar z} = g_{\bar w} = 0\), so
\(h_{\bar z} = 0\) and \(h\) is holomorphic and \(h_z = g_w f_z\).

Example: Given a power series \(f=\sum a_n (z- z_0)^n\). Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  There exists a radius of convergence \(R\) such that \(f\) converges
  precisely on \(D_R(z_0)\).
\item
  \(f\) is continuous on \(D_R(z_0)^\circ\).
\item
  By the root test,
  \(R = (\limsup \abs{a_n}^{1/n})\inv = \liminf \abs{a_n/a_{n+1}} = (\limsup \abs{a_{k+1}/a_k})\inv\).
\end{enumerate}

Recall the ratio test: \(\sum a_k\) converges absolutely iff
\(\limsup \abs{a_{k+1} / a_k} < 1\)

\textbf{Theorem:} If \(f(z) = \sum_{n=0} a_n z^n\) is holomorphic on
\(\abs{z} < R\) for \(R> 0\) then \(f'(z) = \sum_{n=1} a_n n z^{n-1}\).

\begin{quote}
\emph{Exercise:} Show \(\lim_n n^{\frac 1 n} = 1\). Also tricky: show
\(\lim \sin(n)\) doesn't exist, and \(\sin(n)\) is dense in \([-1, 1]\).
\end{quote}

Proof: Consider \(\limsup \abs{a_n n}^{\frac 1 n}\).

Remark: An analytic function is holomorphic in its domain of
convergence, so analytic implies holomorphic. The converse requires
Cauchy's integral formula.

\begin{quote}
Note: look for 13 equivalent statements, Springer GTM Lipman.
\end{quote}

Proof: Given \(\abs z < R\), fix \(r>0\) such that \(\abs {z} < r < R\).
Suppose that \(\abs{w-z} < r - \abs{z}\), so \(\abs w < r\).

\begin{figure}
\centering
\includegraphics{figures/2020-01-17-14:14.png}
\caption{Image}
\end{figure}

We want to show \begin{align*}
\abs{S} = \abs{\frac{f(w) - f(z)}{w - z} - \sum_{n=1} a_n n z^{n-1}} \to 0 \quad \text{as } w\to z
.\end{align*}

Idea: write everything in terms of power series. Use the fact that
\(a^n - b^n = (a-b)(a^{n-1} + a^{n-2}b + \cdots)\), and so
\(\abs{(w^k-z^k)/(w-z)} \leq k r^{k-1}\).

\begin{align*}
S 
&= \sum_{n=1} a_n \qty{ \frac{w^n - z^n}{w-z} - n z^{n-1}  } \\
&= \sum a_n \qty{ w^{n-1} + w^{n-2}z + \cdots + z^{n-1} + nz^{n-1} } \\
&=  \sum a_n \qty{ (w^{n-1} - z^{n-1}) + (w^{n-2} - z^{n-2})z + \cdots + (w-z) z^{n-2} }
&= \sum a_n (w-z) \qty{ \cdots + z^{n-2} }\\
&\leq \sum_{n=2} \abs{a_n} \frac 1 2 n(n-1) r^{n-2} \abs{z-w}
.\end{align*}

\(\qed\)

Next time: trying to prove holomorphic functions are analytic.

\hypertarget{wednesday-january-22nd}{%
\section{Wednesday January 22nd}\label{wednesday-january-22nd}}

\begin{quote}
Note: multiple complex variables, see Hormander or Steven Krantz
\end{quote}

Recall from last time that if \(f(z) = \sum_{n=0}^\infty a_n z^n\) with
\(z_0 \neq 0\) has radius of convergence
\(R = (\limsup \abs{a_n}^{1/n})\inv > 0\), then \(f'\) exists and is
obtained by differentiating term-by-term. We have \(f\) analytic implies
\(f\) holomorphic (and smooth), we want to show the converse. For this,
we need integration.

\textbf{Definition:} A parameterized curve is a function \(z(t)\) which
maps a closed interval \([a, b] \subset \RR\) to \(\CC\).

\textbf{Definition:} The curve is said to be smooth iff \(z'\) exists
and is continuous on \([a,b]\), and \(z'(t) \neq 0\) for any \(t\). At
the boundary \(\theset{a, b}\), we define the derivative by taking
one-sided limits.

\textbf{Definition:} A curve is said to be piecewise smooth iff \(z(t)\)
is continuous on \([a, b]\) and there are \(a < a_1 < \cdots < a_n = b\)
with \(z\) smooth on each \([a_k, a_{k+1}]\).

\begin{quote}
Note: may fail to have tangent lines at \(a_i\).
\end{quote}

\textbf{Definition:} Two parameterizations
\(z: [a,b] \to \CC, \tilde z: [c, d] \to \CC\) are equivalent iff there
exists a \(C^1\) bijection \(s: [c, d] \to [a, b]\) where
\(s \mapsto t(s)\) such that \(s'>0\) and \(\tilde z(s) = z(s(t))\).

Note that \(s' > 0\) preserves orientation and \(s'<0\) reverses
orientation.

\textbf{Definition:}

\begin{align*}
\gamma: [a, b] \to \CC \implies \gamma^- \definedas [a,b] to \CC,~~ t \mapsto \gamma(a+b-t)
.\end{align*}

\textbf{Definition:} A curve is closed iff \(z(a) = z(b)\), and is
simple iff \(z(t) \neq z_{t_1}\) for \(t\neq t_1\).

\textbf{Definition:} For
\(C_r(z_0) \definedas \theset{z\suchthat \abs{z-z_0} = r}\), the
positive orientation is given by \(z(t) = z_0 + re^{2\pi i t}\) for
\(t\in [0, 1]\).

\textbf{Definition:} The integral of \(f\) over \(\gamma\) is defined as

\begin{align*}
\int_\gamma f ~dz = \int_a^b f(z(t)) z'(t)~dt
.\end{align*}

Note: This doesn't depend on parameterization, since if \(t = t(s)\),
then a change of variables yields

\begin{align*}
\int_\gamma f ~dz - \int_c^d f(z(t(s)))z'(t(s))t'(s) ~ds = \int_c^d f(\tilde z(s)) \tilde z'(s) ~ds
.\end{align*}

Definition: The length of \(\gamma\) is defined as
\(\abs \gamma = \int \abs{z'(t)} ~dt\).

Proposition:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We can extend this definition to piecewise smooth curves by
  \begin{align*}
  \int_\gamma f~dz = \sum \int_{a_k}^{a_{k+1}} f ~dz
  \end{align*}
\item
  This integral is linear and \(\int_\gamma f = -\int_{\gamma^-} f\).
\item
  We have an inequality
\end{enumerate}

\begin{align*}
\abs{\int_\gamma f} \leq \max_{a\leq t \leq b} \abs{f(z(t))} \abs\gamma
.\end{align*}

Definition: A function \(F\) is a primitive for \(f\) on \(\Omega\) iff
\(F\) is holomorphic on \(\Omega\) and \(F'(z) = f(z)\) on \(\Omega\).

Recall that in \(\RR\), we have \(F(x) \int_a^x f(t)~dt\) as an
antiderivative with \(F'(x) = f(x)\), and \(\int f = F(b) - F(a)\).

Theorem: If \(f\) is continuous, has a primitive \(F\) in \(\Omega\),
and \(\gamma\) is a curve beginning at \(w_0\) and ending at \(w_1\),
then \(\int_\gamma f = F(w_1) - F(w_0)\).

Proof: Use definitions, write \(z(t)\) where \(z(a) = w_1, z(b) = w_2\).
Then

\begin{align*}
\int_\gamma f = \int_a^b f(z(t)) z'(t) ~ dt \\
= \int_a^b F'(z(t)) z'(t) ~dt \\
= \int_a^b F_t ~dt \\
= F(z(b)) - F(z(a)) \quad\text{by FTC}\\
= F(w_1) - F(w_2)
.\end{align*}

Note that if \(\gamma\) is piecewise smooth, the sum of the integrals
telescopes to yield the same conclusion.

\textbf{Corollary:} If \(f\) is continuous and \(\gamma\) is a closed
curve in \(\Omega\), and \(f\) has a primitive in \(\Omega\), then
\(\oint f = 0\).

\hypertarget{friday-january-24th}{%
\section{Friday January 24th}\label{friday-january-24th}}

\textbf{Corollary:} If \(\gamma\) is a closed curve on \(\Omega\) an
open set and \(f\) is continuous with a primitive in \(\Omega\) (i.e.~an
\(F\) holomorphic in \(\Omega\) with \(F'=f\)) then
\(\int_\gamma f ~dz = 0\).

\emph{Proof (easy):} \begin{align*}
\int_\gamma f ~dz = \int_\gamma F' = F'(z) z(t) ~dt  = F(z(b)) - F(z(a)) = 0
.\end{align*}

Corollary: If \(f\) is holomorphic with \(f'=0\) on \(\Omega\), then
\(f\) is constant.

\emph{Proof (easy):} Pick \(w_0 \in \Omega\); we want to fix
\(w_0 \in \Omega\) and show \(f(w) = f(w_0)\) for all \(w\in \Omega\).

Take any path \(\gamma: w_0 \to w\), then

\begin{align*}
0 = \int_\gamma f' = f(w) - f(w_0)
.\end{align*}

Example: Let \(f(z) = e^{-z^2}\), this is holomorphic. Write
\(f(z) = \sum (-1)^n z^{2n}/n!\), so
\(\int f = \sum (-1)^n z^{2n+1}/(n! (2n+1))\). Since \(f\) is entire,
\(\int f\) is entire, and \((\int f)' = f\) so this function has a
primitive. Thus \(\int_\gamma f(z) = 0\) for \emph{any} closed curve. So
take \(\gamma\) a rectangle with vertices \(\pm a , \pm a + ib\).

\begin{figure}
\centering
\includegraphics{figures/2020-01-24-13:36.png}
\caption{Image}
\end{figure}

So

\begin{align*}
\int_\gamma f = \int_{-a}^a e^{-x^2} ~dx + \int e^{-(a+iy)^2} i ~dy - \int_{-a}^a e^{-(x+ib)^2} ~dx - \int_0^b e^{-(a+iy)^2} i dy = 0
.\end{align*}

We can do some estimates,

\begin{align*}
e^{-(a+iy)^2} = e^{-(a^2 + 2iay - y^2)} = e^{-a^2 + y^2} e^{2iay} \leq e^{-a^2 + y^2} \leq e^{-a^2 + b^2} \\
\abs {\int_0^b e^{-(a+ib)^2} i ~dy} \leq e^{-a^2 + b^2} \cdot b \\
\int_{-a}^a e^{-(x^2 + 2ib x)-b^2} = e^{b^2} \int_{-a}^a e^{-x^2} ( \cos(2bx) - i \sin(2bx) ) \equalsbecause{odd fn} e^{b^2} \int_{-a}^a e^{-x^2} \cos(2bx) ~dx
.\end{align*}

Now take \(a\to \infty\) to obtain

\begin{align*}
\int_\RR e^{-x^2} ~dx - e^{b^2} \int_\RR e^{-x^2} \cos(2bx) ~dx
.\end{align*}

We can compute

\begin{align*}
\int_\RR e^{-x^2} = \left[ \qty{\int_\RR e^{-x^2}}^2 \right]^{1/2} = \qty{ \int_0^{2\pi} \int_0^\infty e^{r^2} r~dr~d\theta} = \sqrt{\pi}
.\end{align*}

and then conclude

\begin{align*}
\int_\RR e^{-x^2} \cos(2bx) \sqrt{\pi} e^{-b^2}
.\end{align*}

Make a change of variables \(2b = 2\pi \xi\), so \(b = \pi \xi\), then

\begin{align*}
\int_\RR e^{-x^2} \cos(2\pi \xi x) ~dx = \sqrt{\pi} e^{-\pi^2 \xi^2}
.\end{align*}

Thus \(\mcf(e^{-x^2}) = \sqrt{\pi} e^{-\pi^2 \xi^2}\), allowing
computation of the Fourier transform. Note that this can be used to
prove the Fourier inversion formula.

\textbf{Exercise:} Show that this is an approximate identity and prove
the Fourier inversion formula.

\textbf{Exercise:} Show
\(\mcf(e^{-ax^2}) = \sqrt{\pi/a} e^{-\pi^2/a \cdot \xi^2}\), and thus
taking \(a = \pi\) makes \(e^{\pi x^2}\) is an eigenfunction of \(\mcf\)
with eigenvalue \(1\).

Theorem: If \(f\) has a primitive on \(\Omega\) then \(F(z)\) is
holomorphic and \(\int_\gamma f = 0\). If \(f\) is holomorphic, then
\(\int_\gamma f = 0\).

\textbf{Theorem (Green's):} Take \(\Omega \in \RR^2\) bounded with
\(\bd \Omega\) piecewise smooth. If \(f, g\in C^1{\bar \Omega}\), then

\begin{align*}
\int_{\bd \Omega} f ~dx + g ~dy = \iint_{\Omega} \qty{g_x - f_y} ~dA
.\end{align*}

Proof: Not given here!

\textbf{Proof of Theorem}: Write \(\gamma = \bd \Gamma\), and noting
that \(f_z = f_x = \frac 1 i f_y\) implies that \(\dd{f}{\bar z}\), so

\begin{align*}
\int_\gamma f ~dz = \int_\gamma f(z) ~(dx + i dy) \\
= \int f(z) ~dx + i f(z) ~dy \\
= \iint_\Gamma \qty{if_x - f_y} ~dA \\
= i \iint_\Gamma \qty{f_x - \frac 1 i f_y} ~dA \\
= i \iint 0 ~dA = 0
.\end{align*}

Next class: We'll prove that this integral over any triangle is zero by
a limiting process.

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\begin{quote}
Collection of facts used on problem sets
\end{quote}

\textbf{Standard forms of conic sections:}

\begin{itemize}
\tightlist
\item
  Circle: \(x^2 + y^2 = r^2\)
\item
  Ellipse: \(\qty{\frac x a}^2 + \qty{\frac y b}^2 = 1\)
\item
  Hyperbola: \(\qty{\frac x a}^2 - \qty{\frac y b}^2 = 1\)

  \begin{itemize}
  \tightlist
  \item
    Rectangular Hyperbola: \(xy = \frac{c^2}{2}\).
  \end{itemize}
\item
  Parabola: \(-4ax + y^2 = 0\).
\end{itemize}

\begin{quote}
Mnemonic: Write \(f(x, y) = Ax^2 + Bxy + Cy^2 + \cdots\), then consider
the discriminant \(\Delta = B^2 - 4AC\):

\begin{itemize}
\tightlist
\item
  \(\Delta < 0 \iff\) ellipse

  \begin{itemize}
  \tightlist
  \item
    \(\Delta < 0\) and \(A=C, B=0 \iff\) circle
  \end{itemize}
\item
  \(\Delta = 0 \iff\) parabola
\item
  \(\Delta > 0 \iff\) hyperbola
\end{itemize}
\end{quote}

\textbf{Completing the square:}

\begin{align*}
x^2 - bx = (x - s)^2 - s^2 \quad\text{where} s = \frac{b}{2} \\
x^2 + bx = (x + s)^2 - s^2 \quad\text{where} s = \frac{b}{2}
.\end{align*}

\textbf{Useful Properties}

\begin{itemize}
\tightlist
\item
  \(\Re(z) = \frac 1 2 (z + \bar z)\) and
  \(\Im(z) = \frac{1}{2i}(z - \bar z)\).
\item
  \(z\bar z = \abs{z}^2\)
\item
  \(\cos(\theta) = \frac 1 2 \qty{e^{i\theta} + e^{-i\theta}}\)
\item
  \(\sin(\theta) = \frac{1}{2i}\qty{e^{i\theta} - e^{-i\theta}}\).
\end{itemize}

\textbf{Useful Series}

\begin{align*} 
\sum_{k=1}^{n} k &=\frac{n(n+1)}{2} \\ 
\sum_{k=1}^{n} k^{2} &=\frac{n(n+1)(2 n+1)}{6} \\ 
\sum_{k=1}^{n} k^{3} &=\frac{n^{2}(n+1)^{2}}{4} 
\end{align*}

\textbf{Cauchy-Riemann Equations}

\begin{align*}
u_x = v_y \quad\text{and}\quad u_y = -v_x \\
\frac{\partial u}{\partial r}=\frac{1}{r} \frac{\partial v}{\partial \theta} \quad \text { and } \quad \frac{\partial v}{\partial r}=-\frac{1}{r} \frac{\partial u}{\partial \theta} \\
.\end{align*}

\hypertarget{useful-techniques}{%
\subsection{Useful Techniques}\label{useful-techniques}}

\textbf{Showing a function is constant:} Write \(f = u + iv\) and use
Cauchy-Riemann to show \(u_x, u_y = 0\), etc.

\textbf{Deriving Polar Cauchy-Riemann:} See
\href{https://users.math.msu.edu/users/shapiro/Teaching/classes/425/crpolar.pdf}{walkthrough
here}. Take derivative along two paths, along a ray with constant angle
\(\theta_0\) and along a circular arc of constant radius \(r_0\). Then
equate real and imaginary parts. See problem set 1.

Computing Arguments: \(\Arg(z/w) = \Arg(z) - \Arg(w)\).

The sum of the interior angles of an \(n\dash\)gon is \((n-2)\pi\),
where each angle is \(\frac{n-2}{n}\pi\).

%\listoftodos

\bibliography{/home/zack/Notes/library.bib}

\end{document}
