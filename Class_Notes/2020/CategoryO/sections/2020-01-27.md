# Monday January 27th

Fix $\Delta = \theset{\alpha_1, \cdots, \alpha_\ell}$, $x_i \in g_{\alpha_i}$ and $y_i \in g_{-\alpha_i}$ with $h_i = [x_i y_i]$.

Lemma:
For $k\geq 0$ and $1 \leq i, j \leq \ell$,

a. $[x_j y_i^{k+1}] = 0$ if $j\neq i$
b. $[h_j y_i^{k+1}] = -(k+1) \alpha_i(h_j) y_i^{k+1}$
c. $[x_i y_i^{k+1}] = (k+1) y_i^{k} (k\cdot 1 - h_i)$.

*Sketch of proof for (c):*

By induction, where $k=0$ is clear.

\begin{align*}
[x+i y_i^{k+1}]
&= [x_i y_i] y_i^k + y_i [x_i y_i^k] \\
&=h_i y_i^k + y_i(-k y_i^{k-1} ((k-1)1 - h_i)) \quad\text{by I.H.} \\
&= (k+1)y_i^k h_i - (k^2 -k + 2k)y_i^k \\
&= -(k+1) y_i^k ( k\cdot 1 - h_i )\\
.\end{align*}

$\qed$

**Proposition:** 
Suppose $\lambda \in \lieh\dual, \alpha \in \Delta$, and $n\definedas (\lambda, \alpha\dual) \in \ZZ^+$.
Then in $M(\lambda)$, $y_\alpha^{n+1} v^+$ is a maximal weight vector of weight $\mu \definedas \lambda - (n+1)\alpha < \lambda$.

> Note this is free as an $U(\lien^-)\dash$module, so $v^+ \neq 0$.
> Note that $n = \lambda(h_\alpha)$.

By the universal property, there is a nonzero homomorphism $M(\mu) \to M(\lambda)$ with image contained in $N(\lambda)$, the unique maximal proper submodules of $M(\lambda)$.

*Proof:*
Say $\alpha = \alpha_i$.
Fix $j\neq i$.

\begin{align*}
x_i y_\alpha^{n+1} \tensor 1 
&= [x_j y_^{n+1}] \tensor 1 + y_i^{n+1} \tensor x_j \cdot 1 \\
&= [x_j y_^{n+1}] \tensor 1 + y_i^{n+1} \tensor 0 \quad\text{by a} \\
&= 0
.\end{align*}


\begin{align*}
x_i y_i^{n+1} \tensor 1 
&= [x_i y_i^{n+1} \tensor 1] \\
&= -(n+1) y_i^n (n\cdot 1 - h_i) \tensor 1 \\
&= -(n+1) (n - \lambda(h_i)) 1 \tensor 1 \\
&\definedas -(n+1) (\lambda(h_i) - \lambda(h_i)) 1 \tensor 1 \\
&= 0
.\end{align*}

Since $g_{\alpha_j}$ generate $\lien$ as a Lie algebra, since $[\lieg_\alpha, \lieg_\beta] = \lieg_{\alpha + \beta}$.
This shows that $\lien \cdot y_i^{n+1} v^+ = 0$, and the weight of $y_i^{n+1} v^+$ is $\lambda - (n+1)\alpha_i$.
So $y_i^{n+1}$ is a maximal vector of weight $\mu$.
The universal property implies there is a nonzero map $M(\mu) \to M(\lambda)$ sending highest weight vectors to highest weight vectors and preserving weights.
The image is proper since all weights of $M_\mu$ are less than or equal to $\mu < \lambda$.

$\qed$

Consider $\liesl(2)$, then $M(1) \supset M(-3)$.
Note that reflecting through 0 doesn't send 1 to -3, but shifting the origin to $-1$ and reflecting about that with $s_\alpha \cdot$ fixes this problem.
Note that $L(1)$ is the quotient.

For $\lambda \in \lieh\dual$ and $\alpha \in \Delta$, we can compute $s_\alpha \cdot \lambda \definedas s_\alpha(\lambda + \rho) - \rho$ where $\rho = \sum_{j=1}^\ell e_i$.
Then $(w_j, \alpha_i\dual) = \delta_{ij}$ and $(\rho, \alpha_i\dual) = 1$.

\begin{align*}
s\alpha \cdot \lambda 
&= s_\alpha(\lambda + \rho) - \rho \\
&= (\lambda + \rho) - (\lambda + \rho, \alpha\dual)\alpha -\rho \\
&= \lambda + \rho - ((\lambda< \alpha\dual) +1)\alpha - \rho \\
&= \lambda - (n+1)\alpha \\
&= \mu
.\end{align*}

So this gives a well-defined, nonzero map $M(s_\alpha \cdot \lambda) \to M(\lambda)$ for $s_\alpha \cdot \lambda < \lambda$.

![Image](figures/2020-01-27-09:35.png)

**Corollary:**
Let $\lambda, \alpha, n$ be as in the above proposition.
Let $\bar v^+$ now be a maximal vector of weight $\lambda$ in $L(\lambda)$.
Then $y_\alpha^{n+1} \bar v^+ = 0$.

*Proof:*
If not, then this would be a maximal vector, since it's the image of the vector $y_i^{n+1}v^+ \in M(\lambda)$ under the map $M(\lambda) \to L(\lambda)$.
