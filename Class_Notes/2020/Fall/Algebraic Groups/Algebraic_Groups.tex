\input{"/home/zack/Notes/Latex/preamble.tex"}

\addbibresource{Algebraic\_Groups.bib}

\let\Begin\begin
\let\End\end
\newcommand\wrapenv[1]{#1}

\makeatletter
\def\ScaleWidthIfNeeded{%
 \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\def\ScaleHeightIfNeeded{%
  \ifdim\Gin@nat@height>0.9\textheight
    0.9\textheight
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\setkeys{Gin}{width=\ScaleWidthIfNeeded,height=\ScaleHeightIfNeeded,keepaspectratio}%

\title{
\rule{\linewidth}{1pt} \\
\textbf{
    Algebraic Groups
  }
    \\ {\normalsize University of Georgia, Fall 2020} \\
  \rule{\linewidth}{2pt}
}
\titlehead{
    \begin{center}
  \includegraphics[width=\linewidth,height=0.5\textheight,keepaspectratio]{figures/cover.png}
  \end{center}
       \begin{minipage}{.35\linewidth}
    \begin{flushleft}
      \vspace{2em}
      {\fontsize{6pt}{2pt} \textit{Notes: These are notes live-tex'd
from a graduate course in Algebraic Groups taught by Dan Nakano at the
University of Georgia in Fall 2020. As such, any errors or inaccuracies
are almost certainly my own. } } \\
    \end{flushleft}
    \end{minipage}
    \hfill
    \begin{minipage}{.65\linewidth}
    \end{minipage}
  }







\begin{document}

\date{}
\maketitle
\begin{flushleft}
\textbf{D. Zack Garza} \\
\textit{University of Georgia} \\
\textit{dzackgarza@gmail.com} \\
{\tiny \textit{Last updated:} 2020-10-24 }
\end{flushleft}


\newpage
\tableofcontents

\newcommand{\ext}{\operatorname{Ext}}
\newcommand{\Ext}{\operatorname{Ext}}
\def\Endo{\operatorname{End}}
\def\Ind{\operatorname{Ind}}
\def\ind{\operatorname{Ind}}
\def\coind{\operatorname{Coind}}
\def\Res{\operatorname{Res}}
\def\Hol{\operatorname{Hol}}
\def\res{\operatorname{Res}}
\def\endo{\operatorname{End}}
\def\ind{\operatorname{Ind}}
\renewcommand{\AA}[0]{{\mathbb{A}}}
\DeclareMathOperator{\Exists}{\exists}
\DeclareMathOperator{\Forall}{\forall}
\newcommand{\Af}[0]{{\mathbb{A}}}
\newcommand{\CC}[0]{{\mathbb{C}}}
\newcommand{\CP}[0]{{\mathbb{CP}}}
\newcommand{\DD}[0]{{\mathbb{D}}}
\newcommand{\FF}[0]{{\mathbb{F}}}
\newcommand{\GF}[0]{{\mathbb{GF}}}
\newcommand{\GG}[0]{{\mathbb{G}}}
\newcommand{\HH}[0]{{\mathbb{H}}}
\newcommand{\HP}[0]{{\mathbb{HP}}}
\newcommand{\KK}[0]{{\mathbb{K}}}
\newcommand{\kk}[0]{{\Bbbk}}
\newcommand{\bbm}[0]{{\mathbb{M}}}
\newcommand{\NN}[0]{{\mathbb{N}}}
\newcommand{\OP}[0]{{\mathbb{OP}}}
\newcommand{\PP}[0]{{\mathbb{P}}}
\newcommand{\QQ}[0]{{\mathbb{Q}}}
\newcommand{\RP}[0]{{\mathbb{RP}}}
\newcommand{\RR}[0]{{\mathbb{R}}}
\newcommand{\SpSp}[0]{{\mathbb{S}}}
\renewcommand{\SS}[0]{{\mathbb{S}}}
\newcommand{\TT}[0]{{\mathbb{T}}}
\newcommand{\ZZ}[0]{{\mathbb{Z}}}
\newcommand{\ZnZ}[0]{\mathbb{Z}/n\mathbb{Z}}
\newcommand{\ZpZ}[0]{\mathbb{Z}/p\mathbb{Z}}
\newcommand{\Qp}[0]{\mathbb{Q}_{(p)}}
\newcommand{\Zp}[0]{\mathbb{Z}_{(p)}}
\newcommand{\Arg}[0]{\operatorname{Arg}}
\newcommand{\PGL}[0]{\operatorname{PGL}}
\newcommand{\GL}[0]{\operatorname{GL}}
\newcommand{\Gl}[0]{\operatorname{GL}}
\newcommand{\gl}[0]{\operatorname{GL}}
\newcommand{\mat}[0]{\operatorname{Mat}}
\newcommand{\Mat}[0]{\operatorname{Mat}}
\newcommand{\Rat}[0]{\operatorname{Rat}}
\newcommand{\Perv}[0]{\operatorname{Perv}}
\newcommand{\Gal}[0]{\operatorname{Gal}}
\newcommand{\Hilb}[0]{\operatorname{Hilb}}
\newcommand{\Quot}[0]{\operatorname{Quot}}
\newcommand{\Art}[0]{\operatorname{Art}}
\newcommand{\red}[0]{\operatorname{red}}
\newcommand{\alg}[0]{\operatorname{alg}}
\newcommand{\Pic}[0]{{\operatorname{Pic}~}}
\newcommand{\lcm}[0]{\operatorname{lcm}}
\newcommand{\maps}[0]{\operatorname{Maps}}
\newcommand{\maxspec}[0]{{\operatorname{maxSpec}~}}
\newcommand{\Tr}[0]{\operatorname{Tr}}
\newcommand{\adj}[0]{\operatorname{adj}}
\newcommand{\ad}[0]{\operatorname{ad}~}
\newcommand{\ann}[0]{\operatorname{Ann}}
\newcommand{\Ann}[0]{\operatorname{Ann}}
\newcommand{\arcsec}[0]{\operatorname{arcsec}}
\newcommand{\ch}[0]{\operatorname{char}~}
\newcommand{\Sp}[0]{{\operatorname{Sp}}}
\newcommand{\syl}[0]{{\operatorname{Syl}}}
\newcommand{\txand}[0]{{\text{ and }}}
\newcommand{\codim}[0]{\operatorname{codim}}
\newcommand{\txor}[0]{{\text{ or }}}
\newcommand{\txt}[1]{{\text{ {#1} }}}
\newcommand{\Gr}[0]{{\text{Gr}}}
\newcommand{\Aut}[0]{{\operatorname{Aut}}}
\newcommand{\aut}[0]{\operatorname{Aut}}
\newcommand{\Inn}[0]{{\operatorname{Inn}}}
\newcommand{\Out}[0]{{\operatorname{Out}}}
\newcommand{\mltext}[1]{\left\{\begin{array}{c}#1\end{array}\right\}}
\newcommand{\Fun}[0]{{\text{Fun}}}
\newcommand{\SL}[0]{{\text{SL}}}
\newcommand{\PSL}[0]{{\text{PSL}}}
\newcommand{\SO}[0]{{\text{SO}}}
\newcommand{\SU}[0]{{\text{SU}}}
\newcommand{\SP}[0]{{\text{SP}}}
\newcommand{\per}[0]{{\text{Per}}}
\newcommand{\loc}[0]{{\text{loc}}}
\newcommand{\Top}[0]{{\text{Top}}}
\newcommand{\Sch}[0]{{\text{Sch}}}
\newcommand{\sch}[0]{{\text{Sch}}}
\newcommand{\Set}[0]{{\text{Set}}}
\newcommand{\Sets}[0]{{\text{Set}}}
\newcommand{\Grp}[0]{{\text{Grp}}}
\newcommand{\Groups}[0]{{\text{Groups}}}
\newcommand{\Homeo}[0]{{\text{Homeo}}}
\newcommand{\Diffeo}[0]{{\text{Diffeo}}}
\newcommand{\MCG}[0]{{\text{MCG}}}
\newcommand{\set}[0]{{\text{Set}}}
\newcommand{\Tor}[0]{\text{Tor}}
\newcommand{\sets}[0]{{\text{Set}}}
\newcommand{\Sm}[0]{{\text{Sm}_k}}
\newcommand{\orr}[0]{{\text{ or }}}
\newcommand{\annd}[0]{{\text{ and }}}
\newcommand{\bung}[0]{\text{Bun}_G}
\newcommand{\const}[0]{{\text{const.}}}
\newcommand{\disc}[0]{{\text{disc}}}
\newcommand{\op}[0]{^\text{op}}
\newcommand{\id}[0]{\text{id}}
\newcommand{\im}[1]{\operatorname{im}({#1})}
\newcommand{\pt}[0]{{\{\text{pt}\}}}
\newcommand{\sep}[0]{^\text{sep}}

\newcommand{\st}[0]{~{\text{s.t.}}~}
\newcommand{\tors}[0]{{\text{tors}}}
\newcommand{\tor}[0]{\text{Tor}}
\newcommand{\height}[0]{\text{ht}}
\newcommand{\cpt}[0]{\text{compact}}
\newcommand{\abs}[1]{{\left\lvert {#1} \right\rvert}}
\newcommand{\stack}[1]{\mathclap{\substack{ #1 }}} 
\newcommand{\qtext}[1]{{\quad \text{#1} \quad}}
\newcommand{\qst}[0]{{\quad \text{such that} \quad}}
\newcommand{\actsonl}[0]{\curvearrowleft}
\newcommand{\actson}[0]{\curvearrowright}
\newcommand{\bd}[0]{{\del}}
\newcommand{\bigast}[0]{{\mathop{\Large \ast}}}
\newcommand{\coker}[0]{\operatorname{coker}}
\newcommand{\cok}[0]{\operatorname{coker}}
\newcommand{\conjugate}[1]{{\overline{{#1}}}}
\newcommand{\converges}[1]{\overset{#1}}
\newcommand{\correspond}[1]{\theset{\substack{#1}}}
\newcommand{\cross}[0]{\times}
\newcommand{\by}[0]{\times}
\newcommand{\dash}[0]{{\hbox{-}}}
\newcommand{\dd}[2]{{\frac{\partial #1}{\partial #2}\,}}
\newcommand{\definedas}[0]{\coloneqq}
\newcommand{\da}[0]{\coloneqq}
\newcommand{\del}[0]{{\partial}}
\newcommand{\directlim}[0]{\varinjlim}
\newcommand{\disjoint}[0]{{\coprod}}
\newcommand{\divides}[0]{{~\Bigm|~}}
\newcommand{\dual}[0]{^\vee}
\newcommand{\sm}[0]{\setminus}
\newcommand{\smz}[0]{\setminus\theset{0}}
\newcommand{\eps}[0]{\varepsilon}
\newcommand{\equalsbecause}[1] {\stackrel{\mathclap{\scriptscriptstyle{#1}}}{=}}
\newcommand{\floor}[1]{{\left\lfloor #1 \right\rfloor}}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand{\from}[0]{\leftarrow}
\newcommand{\tofrom}[0]{\rightleftharpoons}
\newcommand{\up}[0]{\uparrow}
\newcommand{\generators}[1]{\left\langle{#1}\right\rangle}
\newcommand{\gs}[1]{\left\langle{#1}\right\rangle}
\newcommand{\homotopic}[0]{\simeq}
\newcommand{\injectivelim}[0]{\varinjlim}
\newcommand{\injects}[0]{\hookrightarrow}
\newcommand{\inner}[2]{{\left\langle {#1},~{#2} \right\rangle}}
\newcommand{\union}[0]{\cup}
\newcommand{\Union}[0]{\bigcup}
\newcommand{\intersect}[0]{\cap}
\newcommand{\Intersect}[0]{\bigcap}
\newcommand{\into}[0]{\to}
\newcommand{\inverselim}[0]{\varprojlim}
\newcommand{\inv}[0]{^{-1}}
\newcommand{\mfa}[0]{{\mathfrak{a}}}
\newcommand{\mfb}[0]{{\mathfrak{b}}}
\newcommand{\mfc}[0]{{\mathfrak{c}}}
\newcommand{\mff}[0]{{\mathfrak{f}}}
\newcommand{\mfi}[0]{{\mathfrak{I}}}
\newcommand{\mfm}[0]{{\mathfrak{m}}}
\newcommand{\mfn}[0]{{\mathfrak{n}}}
\newcommand{\mfp}[0]{{\mathfrak{p}}}
\newcommand{\mfq}[0]{{\mathfrak{q}}}
\newcommand{\mfr}[0]{{\mathfrak{r}}}
\newcommand{\lieb}[0]{{\mathfrak{b}}}
\newcommand{\liegl}[0]{{\mathfrak{gl}}}
\newcommand{\lieg}[0]{{\mathfrak{g}}}
\newcommand{\lieh}[0]{{\mathfrak{h}}}
\newcommand{\lien}[0]{{\mathfrak{n}}}
\newcommand{\liesl}[0]{{\mathfrak{sl}}}
\newcommand{\lieso}[0]{{\mathfrak{so}}}
\newcommand{\liesp}[0]{{\mathfrak{sp}}}
\newcommand{\lieu}[0]{{\mathfrak{u}}}
\newcommand{\Lie}[0]{\operatorname{Lie}}
\newcommand{\nilrad}[0]{{\mathfrak{N}}}
\newcommand{\jacobsonrad}[0]{{\mathfrak{J}}}
\newcommand{\mm}[0]{{\mathfrak{m}}}
\newcommand{\pr}[0]{{\operatorname{pr}}}
\newcommand{\mapsvia}[1]{\xrightarrow{#1}}
\newcommand{\injectsvia}[1]{\xhookrightarrow{#1}}
\newcommand{\mapstovia}[1]{\xmapsto{#1}}
\newcommand{\adjoint}[0]{\leftrightarrows}
\newcommand{\kx}[1]{k[x_1, \cdots, x_{#1}]}
\newcommand{\MM}[0]{{\mathcal{M}}}
\newcommand{\OO}[0]{{\mathcal{O}}}
\newcommand{\imaginarypart}[1]{{\mathcal{Im}({#1})}}
\newcommand{\mca}[0]{{\mathcal{A}}}
\newcommand{\mcb}[0]{{\mathcal{B}}}
\newcommand{\mcc}[0]{{\mathcal{C}}}
\newcommand{\mcd}[0]{{\mathcal{D}}}
\newcommand{\mce}[0]{{\mathcal{E}}}
\newcommand{\mcf}[0]{{\mathcal{F}}}
\newcommand{\mcg}[0]{{\mathcal{G}}}
\newcommand{\mch}[0]{{\mathcal{H}}}
\newcommand{\mci}[0]{{\mathcal{I}}}
\newcommand{\mcj}[0]{{\mathcal{J}}}
\newcommand{\mck}[0]{{\mathcal{K}}}
\newcommand{\mcl}[0]{{\mathcal{L}}}
\newcommand{\mcm}[0]{{\mathcal{M}}}
\newcommand{\mcp}[0]{{\mathcal{P}}}
\newcommand{\mcs}[0]{{\mathcal{S}}}
\newcommand{\mct}[0]{{\mathcal{T}}}
\newcommand{\mcu}[0]{{\mathcal{U}}}
\newcommand{\mcv}[0]{{\mathcal{V}}}
\newcommand{\mcx}[0]{{\mathcal{X}}}
\newcommand{\mcz}[0]{{\mathcal{Z}}}
\newcommand{\cl}[0]{\operatorname{cl}}
\newcommand{\trdeg}[0]{\operatorname{trdeg}}
\newcommand{\dist}[0]{\operatorname{dist}}
\newcommand{\Dist}[0]{\operatorname{Dist}}
\newcommand{\crit}[0]{\operatorname{crit}}
\newcommand{\diam}[0]{{\operatorname{diam}}}
\newcommand{\gal}[0]{\operatorname{Gal}}
\newcommand{\diff}[0]{\operatorname{Diff}}
\newcommand{\diag}[0]{\operatorname{diag}}
\newcommand{\soc}[0]{\operatorname{Soc}\,}
\newcommand{\hd}[0]{\operatorname{Head}\,}
\newcommand{\grad}[0]{\operatorname{grad}}
\newcommand{\hilb}[0]{\operatorname{Hilb}}
\newcommand{\minpoly}[0]{{\operatorname{minpoly}}}
\newcommand{\Hom}[0]{{\operatorname{Hom}}}
\newcommand{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\newcommand{\Map}[0]{{\operatorname{Map}}}
\newcommand{\multinomial}[1]{\left(\!\!{#1}\!\!\right)}
\newcommand{\nil}[0]{{\operatorname{nil}}}
\newcommand{\normalneq}{\mathrel{\reflectbox{$\trianglerightneq$}}}
\newcommand{\normal}[0]{{~\trianglelefteq~}}
\newcommand{\norm}[1]{{\left\lVert {#1} \right\rVert}}
\newcommand{\pnorm}[2]{{\left\lVert {#1} \right\rVert}_{#2}}
\newcommand{\notdivides}[0]{\nmid}
\newcommand{\onto}[0]{\twoheadhthtarrow}
\newcommand{\ord}[0]{{\operatorname{Ord}}}
\newcommand{\pic}[0]{{\operatorname{Pic}~}}
\newcommand{\projectivelim}[0]{\varprojlim}
\newcommand{\rad}[0]{{\operatorname{rad}~}}
\newcommand{\ralg}[0]{\operatorname{R-alg}}
\newcommand{\kalg}[0]{k\dash\operatorname{alg}}
\newcommand{\rank}[0]{\operatorname{rank}}
\newcommand{\realpart}[1]{{\mathcal{Re}({#1})}}
\newcommand{\Log}[0]{\operatorname{Log}}
\newcommand{\reg}[0]{\operatorname{Reg}}
\newcommand{\restrictionof}[2]{{\left.{#1}\right|_{#2}}}
\newcommand{\ro}[2]{{\left.{#1}\right|_{#2}}}
\newcommand{\rk}[0]{{\operatorname{rank}}}
\newcommand{\evalfrom}[0]{\Big|}
\newcommand{\rmod}[0]{{R\dash\operatorname{mod}}}
\newcommand{\Mod}[0]{{\operatorname{Mod}}}
\newcommand{\rotate}[2]{{\style{display: inline-block; transform: rotate(#1deg)}{#2}}}
\newcommand{\selfmap}[0]{{\circlearrowleft}}
\newcommand{\semidirect}[0]{\rtimes}
\newcommand{\sgn}[0]{\operatorname{sgn}}
\newcommand{\sign}[0]{\operatorname{sign}}
\newcommand{\spanof}[0]{{\operatorname{span}}}
\newcommand{\spec}[0]{\operatorname{Spec}\,}
\newcommand{\mspec}[0]{\operatorname{mSpec}~}
\newcommand{\stab}[0]{{\operatorname{Stab}}}
\newcommand{\stirlingfirst}[2]{\genfrac{[}{]}{0pt}{}{#1}{#2}}
\newcommand{\stirling}[2]{\genfrac\{\}{0pt}{}{#1}{#2}}
\newcommand{\strike}[1]{{\enclose{horizontalstrike}{#1}}}
\newcommand{\suchthat}[0]{{~\mathrel{\Big|}~}}
\newcommand{\st}[0]{{~\mathrel{\Big|}~}}
\newcommand{\supp}[0]{{\operatorname{supp}}}
\newcommand{\surjects}[0]{\twoheadrightarrow}
\newcommand{\sym}[0]{\operatorname{Sym}}
\newcommand{\tensor}[0]{\otimes}
\newcommand{\connectsum}[0]{\mathop{\Large \#}}
\newcommand{\theset}[1]{\left\{{#1}\right\}}
\newcommand{\ts}[1]{\left\{{#1}\right\}}
\newcommand{\gens}[1]{\left\langle{#1}\right\rangle}
\newcommand{\thevector}[1]{{\left[ {#1} \right]}}
\newcommand{\tv}[1]{{\left[ {#1} \right]}}
\newcommand{\too}[1]{{\xrightarrow{#1}}}
\newcommand{\transverse}[0]{\pitchfork}
\newcommand{\trianglerightneq}{\mathrel{\ooalign{\raisebox{-0.5ex}{\reflectbox{\rotatebox{90}{$\nshortmid$}}}\cr$\triangleright$\cr}\mkern-3mu}}
\newcommand{\tr}[0]{\operatorname{Tr}}
\newcommand{\uniformlyconverges}[0]{\rightrightarrows}
\newcommand{\abuts}[0]{\Rightarrow}
\newcommand{\covers}[0]{\rightrightarrows}
\newcommand{\units}[0]{^{\times}}
\newcommand{\nonzero}[0]{^{\bullet}}
\newcommand{\wait}[0]{{\,\cdot\,}}
\newcommand{\wt}[0]{{\operatorname{wt}}}
\renewcommand{\bar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\renewcommand{\div}[0]{\operatorname{Div}}
\newcommand{\Div}[0]{\operatorname{Div}}
\renewcommand{\hat}[1]{\widehat{#1}}
\renewcommand{\mid}[0]{\mathrel{\Big|}}
\renewcommand{\qed}[0]{\hfill\blacksquare}
\renewcommand{\too}[0]{\longrightarrow}
\renewcommand{\vector}[1]{\mathbf{#1}}
\let\oldexp\exp
\renewcommand{\exp}[1]{\oldexp\qty{#1}}
\let\oldperp\perp
\renewcommand{\perp}[0]{^\oldperp}
\newcommand*\dif{\mathop{}\!\operatorname{d}}
\newcommand{\ddt}{\tfrac{\dif}{\dif t}}
\newcommand{\ddx}{\tfrac{\dif}{\dif x}}

\DeclareMathOperator{\righttriplearrows} {{\; \tikz{ \foreach \y in {0, 0.1, 0.2} { \draw [-stealth] (0, \y) -- +(0.5, 0);}} \; }}

\renewcommand{\labelitemiii}{$\diamondsuit$}
\renewcommand{\labelitemiv}{$\diamondsuit$}

\hypertarget{prologue}{%
\section*{Prologue}\label{prologue}}
\addcontentsline{toc}{section}{Prologue}

\hypertarget{references}{%
\subsection{References}\label{references}}

\begin{itemize}
\item
  Carter's ``Finite Groups of Lie Type''\autocite{carter_1985}
\item
  Humphreys' ``Linear Algebraic Groups''\autocite{humphreys_2004}
\end{itemize}

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

\todo[inline]{Todo}

\newpage

\hypertarget{friday-august-21}{%
\section{Friday, August 21}\label{friday-august-21}}

\hypertarget{intro-and-definitions}{%
\subsection{Intro and Definitions}\label{intro-and-definitions}}

\begin{definition}[Affine Variety]

\begin{definition}[Affine Variety]

Let \(k=\mkern 1.5mu\overline{\mkern-1.5muk\mkern-1.5mu}\mkern 1.5mu\)
be algebraically closed
(e.g.~\(k = {\mathbb{C}}, \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}_p\mkern-1.5mu}\mkern 1.5mu\)).
A variety \(V\subseteq k^n\) is an \emph{affine \(k{\hbox{-}}\)variety}
iff \(V\) is the zero set of a collection of polynomials in
\(k[x_1, \cdots, x_n]\).

\end{definition}

\end{definition}

Here \({\mathbb{A}}^n\mathrel{\vcenter{:}}= k^n\) with the Zariski
topology, so the closed sets are varieties.

\begin{definition}[Affine Algebraic Group]

\begin{definition}[Affine Algebraic Group]

An \emph{affine algebraic \(k{\hbox{-}}\)group} is an affine variety
with the structure of a group, where the multiplication and inversion
maps
\begin{align*}   \mu: G\times G &\to G \\ \iota: G&\to G \end{align*}
are continuous.

\end{definition}

\end{definition}

\begin{example}

\begin{example}

\(G = {\mathbb{G}}_a \subseteq k\) the \emph{additive group} of \(k\) is
defined as \({\mathbb{G}}_a \mathrel{\vcenter{:}}=(k, +)\). We then have
a \emph{coordinate ring} \(k[{\mathbb{G}}_a] = k[x] / I = k[x]\).

\end{example}

\end{example}

\begin{example}

\begin{example}

\(G = \operatorname{GL}(n, k)\), which has coordinate ring
\(k[x_{ij}, T] / \left\langle{\det(x_{ij})\cdot T = 1}\right\rangle\).

\end{example}

\end{example}

\begin{example}

\begin{example}

Setting \(n=1\) above, we have
\({\mathbb{G}}_m \mathrel{\vcenter{:}}=\operatorname{GL}(1, k) = (k^{\times}, \cdot)\).
Here the coordinate ring is
\(k[x, T] / \left\langle{xT = 1}\right\rangle\).

\end{example}

\end{example}

\begin{example}

\begin{example}

\(G = {\text{SL}}(n, k) \leq \operatorname{GL}(n, k)\), which has
coordinate ring
\(k[G] = k[x_{ij}] / \left\langle{\det(x_{ij}) = 1}\right\rangle\).

\end{example}

\end{example}

\begin{definition}[Irreducible]

\begin{definition}[Irreducible]

A variety \(V\) is \emph{irreducible} iff \(V\) can not be written as
\(V = \cup_{i=1}^n V_i\) with each \(V_i \subseteq V\) a proper
subvariety.

\begin{figure}
\centering
\includegraphics{figures/Reducible_v_irreducible.png}
\caption{Reducible vs Irreducible}
\end{figure}

\end{definition}

\end{definition}

\begin{proposition}[?]

\begin{proposition}[?]

There exists a unique irreducible component of \(G\) containing the
identity \(e\). Notation: \(G^0\).

\end{proposition}

\end{proposition}

\begin{proposition}[?]

\begin{proposition}[?]

\(G\) is the union of translates of \(G^0\), i.e.~there is a
decomposition
\begin{align*}   G = {\coprod}_{g\in \Gamma} \, g\cdot G^0 ,\end{align*}
where we let \(G\) act on itself by left-translation and define
\(\Gamma\) to be a set of representatives of distinct orbits.

\end{proposition}

\end{proposition}

\begin{proposition}[?]

\begin{proposition}[?]

One can define solvable and nilpotent algebraic groups in the same way
as they are defined for finite groups, i.e.~as having a terminating
derived or lower central series respectively.

\end{proposition}

\end{proposition}

\hypertarget{jordan-chevalley-decomposition}{%
\subsection{Jordan-Chevalley
Decomposition}\label{jordan-chevalley-decomposition}}

\begin{proposition}[Existence and Uniqueness of Radical]

\begin{proposition}[Existence and Uniqueness of Radical]

There is a maximal connected normal solvable subgroup \(R(G)\), denoted
the \emph{radical of \(G\)}.

\begin{itemize}
\tightlist
\item
  \(\left\{{e}\right\} \subseteq R(G)\), so the radical exists.
\item
  If \(A, B \leq G\) are solvable then \(AB\) is again a solvable
  subgroup.
\end{itemize}

\end{proposition}

\end{proposition}

\begin{definition}[Unipotent]

\begin{definition}[Unipotent]

An element \(u\) is \emph{unipotent} \(\iff\) \(u = 1+n\) where \(n\) is
nilpotent \(\iff\) its the only eigenvalue is \(\lambda = 1\).

\end{definition}

\end{definition}

\begin{proposition}[JC Decomposition]

\begin{proposition}[JC Decomposition]

For any \(G\), there exists a closed embedding
\(G\hookrightarrow\operatorname{GL}(V) = \operatorname{GL}(n , k)\) and
for each \(x\in G\) a unique decomposition \(x=su\) where \(s\) is
semisimple (diagonalizable) and \(u\) is unipotent.

\end{proposition}

\end{proposition}

Define \(R_u(G)\) to be the subgroup of unipotent elements in \(R(G)\).
:::\{.definition title=``Semisimple and Reductive''\} \hfill Suppose
\(G\) is connected, so \(G = G^0\), and nontrivial, so
\(G\neq \left\{{e}\right\}\). Then

\begin{itemize}
\tightlist
\item
  \(G\) is semisimple iff \(R(G) = \left\{{e}\right\}\).
\item
  \(G\) is reductive iff \(R_u(G) = \left\{{e}\right\}\). :::
\end{itemize}

\begin{example}

\begin{example}

\(G = \operatorname{GL}(n, k)\), then \(R(G) = Z(G) = kI\) the scalar
matrices, and \(R_u(G) = \left\{{e}\right\}\). So \(G\) is reductive and
semisimple.

\end{example}

\end{example}

\begin{example}

\begin{example}

\(G = {\text{SL}}(n , k)\), then \(R(G) = \left\{{I}\right\}\).

\begin{exercise}

\begin{exercise}

Is this semisimple? Reductive? What is \(R_u(G)\)?

\end{exercise}

\end{exercise}

\end{example}

\end{example}

\begin{definition}[Torus]

\begin{definition}[Torus]

A \emph{torus} \(T\subseteq G\) in \(G\) an algebraic group is a
commutative algebraic subgroup consisting of semisimple elements.

\end{definition}

\end{definition}

\begin{example}

\begin{example}

Let
\begin{align*}   T \mathrel{\vcenter{:}}= \left\langle{ \begin{bmatrix} a_1 &  & \mathbf 0\\  & \ddots &  \\ \mathbf 0 &  & a_n \end{bmatrix} \subseteq \operatorname{GL}(n ,k) }\right\rangle .\end{align*}

\end{example}

\end{example}

\begin{remark}

\begin{remark}

Why are torii useful? For \(g = \mathrm{Lie}(G)\), we obtain a root
space decomposition
\begin{align*}   g =  \qty{\bigoplus_{\alpha \in \Phi_- }g_\alpha} \oplus  t \oplus \qty{\bigoplus_{\alpha \in \Phi_+ }g_\alpha}  .\end{align*}

When \(G\) is a simple algebraic group, there is a
classification/correspondence:
\begin{align*}   (G, T) \iff (\Phi, W) .\end{align*} where \(\Phi\) is
an irreducible root system and \(W\) is a Weyl group.

\end{remark}

\end{remark}

\hypertarget{monday-august-24}{%
\section{Monday, August 24}\label{monday-august-24}}

\hypertarget{review-and-general-setup}{%
\subsection{Review and General Setup}\label{review-and-general-setup}}

\begin{itemize}
\tightlist
\item
  \(k = \mkern 1.5mu\overline{\mkern-1.5muk\mkern-1.5mu}\mkern 1.5mu\)
  is algebraically closed
\item
  \(G\) is a reductive algebraic group
\item
  \(T\subseteq G\) is a \emph{maximal split torus}
\end{itemize}

\begin{quote}
Split: \(T\cong \bigoplus {\mathbb{G}}_m\).
\end{quote}

We'll associate to this a root system, not necessarily irreducible,
yielding a correspondence
\begin{align*}   (G, T) \iff (\Phi, W) \end{align*} with \(W\) a Weyl
group.

This will be accomplished by looking at
\({\mathfrak{g}}= \mathrm{Lie}(G)\). If \(G\) is simple, then
\({\mathfrak{g}}\) is ``simple'', and \(\Phi\) irreducible will
correspond to a Dynkin diagram.

There is this a 1-to-1 correspondence
\begin{align*}   G \text{ simple}/\sim \iff A_n, B_n, C_n, D_n, E_6, E_7, E_8, F_4, G_2 \end{align*}
where \(\sim\) denotes \emph{isogeny}.

Taking the Zariski tangent space at the identity ``linearizes'' an
algebraic group, yielding a Lie algebra.

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-24-14-09-33.png}
\caption{Image}
\end{figure}

We have the coordinate ring
\(k[G] = k[x_1, \cdots, x_n] / \mathcal{I}(G)\) where \(\mathcal{I}(G)\)
is the zero set. This is equal to \(\left\{{f:G\to k}\right\}\),

\hypertarget{the-associated-lie-algebra}{%
\subsection{The Associated Lie
Algebra}\label{the-associated-lie-algebra}}

\begin{definition}[The Lie Algebra of an Algebraic Group]

\begin{definition}[The Lie Algebra of an Algebraic Group]

Define \emph{left translation} is
\begin{align*}   \lambda_x: k[G] &\to k[G] \\ y &\mapsto f(x^{-1} y) .\end{align*}

Define \emph{derivations} as
\begin{align*}   \mathrm{Der} ~k[G] = \left\{{D: k[G] \to k[G] {~\mathrel{\Big|}~}D(fg) = D(f) g + f D(g) }\right\} .\end{align*}

We can then realize the Lie algebra as
\begin{align*}   {\mathfrak{g}}= \mathrm{Lie}(G) = \left\{{D\in \mathrm{Der} k[G] {~\mathrel{\Big|}~}\lambda_x \circ D = D\circ \lambda_x}\right\} ,\end{align*}
the left-invariant derivations.

\end{definition}

\end{definition}

\begin{example}

\begin{example}

\hfill

\begin{itemize}
\tightlist
\item
  \(G = \operatorname{GL}(n, k) \implies{\mathfrak{g}}= {\mathfrak{gl}}(n, k)\)
\item
  \(G = {\text{SL}}(n, k) \implies{\mathfrak{g}}= {\mathfrak{sl}}(n, k)\)
\end{itemize}

\end{example}

\end{example}

Let \(G\) be reductive and \(T\) be a split torus. Then \(T\) acts on
\({\mathfrak{g}}\) via an \emph{adjoint action}. (For
\(\operatorname{GL}_n, {\text{SL}}_n\), this is conjugation.)

There is a decomposition into eigenspaces for the action of \(T\),
\begin{align*}   {\mathfrak{g}}= \qty{\bigoplus_{\alpha\in \Phi} g_\alpha} \oplus t \end{align*}
where \(t = \mathrm{Lie}(T)\) and
\(g_\alpha \mathrel{\vcenter{:}}=\left\{{x\in {\mathfrak{g}}~{\text{s.t.}}~t.x = \alpha(t) x\,\, \forall t\in T}\right\}\)
with \(\alpha: T\to K^{\times}\) a rational function (a \emph{root}).

In general, take \(\alpha\in\hom_{\text{AlgGrp}}(T, {\mathbb{G}}_m)\).

\begin{example}

\begin{example}

Let \(G = \operatorname{GL}(n, k)\) and
\begin{align*}   T = \left\{{ \begin{bmatrix} a_1 & 0 & 0 \\ 0 & \ddots & 0 \\ 0 & 0 & a_n \end{bmatrix} ~{\text{s.t.}}~a_j\in k^{\times} }\right\} .\end{align*}

Then check the following action:

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-24-14-24-40.png}
\caption{Action}
\end{figure}

which indeed acts by a rational function.

Then
\begin{align*}   g_\alpha = {\operatorname{span}}\left\{{ \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 0\\ 0 & 0 & 0 \end{bmatrix} }\right\} = g_{(1, -1, 0)} .\end{align*}

For \({\mathfrak{g}}= {\mathfrak{gl}}(3, k)\), we have
\begin{align*}   {\mathfrak{g}}= t  &\oplus g_{(1, -1, 0)} \oplus g_{(-1, 1, 0)}  \\ &\oplus g_{(0, 1, -1)}  \oplus g_{(0, -1, 1)}  \\ &\oplus g_{(1, 0, -1)}  \oplus g_{(-1, 0, 1)}  .\end{align*}

\end{example}

\end{example}

\hypertarget{representations}{%
\subsection{Representations}\label{representations}}

Let \(\rho: G\to \operatorname{GL}(V)\) be a group homomorphisms, then
equivalently \(V\) is a (rational) \(G{\hbox{-}}\)module.

For \(T\subseteq G\), \(T\curvearrowright G\) semisimply, so we can
simultaneously diagonalize these operators to obtain a \emph{weight
space decomposition} \(V = \bigoplus_{\lambda \in X(T)} V_\lambda\),
where
\begin{align*}   V_\lambda &\mathrel{\vcenter{:}}=\left\{{v\in V~{\text{s.t.}}~t.v = \lambda(t)v\,\, \forall t\in T}\right\} \\\ X(T) &\mathrel{\vcenter{:}}=\hom(T, {\mathbb{G}}_m) .\end{align*}

\begin{example}

\begin{example}

Let \(G = \operatorname{GL}(n, k)\) and \(V\) the
\(n{\hbox{-}}\)dimensional natural representation as column vectors,
\begin{align*}   V = \left\{{{\left[ {v_1, \cdots, v_n} \right]} {~\mathrel{\Big|}~}v_j \in k}\right\} .\end{align*}

Then
\begin{align*}   T = \left\{{ \begin{bmatrix} a_1 & 0 & 0 \\ 0 & \ddots & 0\\ 0 & 0 & a_n \end{bmatrix} {~\mathrel{\Big|}~}a_j \in k^{\times} }\right\} .\end{align*}

Consider the basis vectors \(\mathbf{e}_j\), then
\begin{align*}   \begin{bmatrix} a_1 & 0 & 0 \\ 0 & \ddots & 0\\ 0 & 0 & a_n \end{bmatrix}  \begin{bmatrix} 0  \\ 1  \\ 0 \end{bmatrix} = a_j \begin{bmatrix} 0  \\ 1 \\ 0 \end{bmatrix} = a_1^0 a_2^0 \cdots a_j^0 \cdots a_n^0 \begin{bmatrix} 0  \\ 1 \\ 0 \end{bmatrix} .\end{align*}

Here the weights are of the form
\(\varepsilon_j\mathrel{\vcenter{:}}={\left[ {0, 0, \cdots, 1, \cdots, 0} \right]}\)
with a \(1\) in the \(j\)th spot, so we have
\begin{align*}   V = V_{\varepsilon_1} \oplus V_{\varepsilon_2} \oplus \cdots \oplus V_{{\varepsilon_n}} .\end{align*}

\end{example}

\end{example}

\begin{example}

\begin{example}

For \(V = {\mathbb{C}}\), we have \(t.v = (a_1^0 \cdots a_n^0)v\) and
\(V = V_{(0, 0, \cdots, 0)}\).

\end{example}

\end{example}

\hypertarget{classification}{%
\subsection{Classification}\label{classification}}

Let \(G\) be a simple algebraic group (ano closed, connected, normal
subgroups other than \(\left\{{e}\right\}, G\)) that is nonabelian that
is nonabelian.

\begin{example}

\begin{example}

Let \(G = {\text{SL}}(3, k)\). Then
\begin{align*}   T = \left\{{ t =  \begin{bmatrix} a_1 & 0 & 0 \\ 0 & a_1 a_2^{-1}  & 0\\ 0 & 0 & a_2^{-1}  \end{bmatrix} ~{\text{s.t.}}~ a_1, a_2\in k^{\times} }\right\} \end{align*}
and
\begin{align*}   t. \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\ \end{bmatrix} =  a_1^2 a_2^{-1}  \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\ \end{bmatrix} .\end{align*}
and \(\alpha_1 = (2, -1)\).

\todo[inline]{What is $\alpha_1$? Note that you can recover the Cartan something here?}

Then
\begin{align*}   {\mathfrak{g}}=  {\mathfrak{g}}_{(2, -1)} \oplus {\mathfrak{g}}_{(-2, 1)} \oplus {\mathfrak{g}}_{(-1, 2)} \oplus {\mathfrak{g}}_{(1, -2)} \oplus {\mathfrak{g}}_{(1, 1)} \oplus {\mathfrak{g}}_{(-1, -1)} .\end{align*}

Then \(\alpha_2 = (-1, 2)\) and \(\alpha_1 + \alpha_2 = ( 1, 1)\).

This gives the root space decomposition for \({\mathfrak{sl}}_3\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-24-14-49-31.png}
\caption{Image}
\end{figure}

Then the Weyl group will be generated by reflections through these
hyperplanes.

\end{example}

\end{example}

\hypertarget{wednesday-august-26}{%
\section{Wednesday, August 26}\label{wednesday-august-26}}

\hypertarget{review}{%
\subsection{Review}\label{review}}

\begin{itemize}
\tightlist
\item
  \(G\) a reductive algebraic group over \(k\)
\item
  \(T = \prod_{i=1}^n {\mathbb{G}}_m\) a maximal split torus
\item
  \({\mathfrak{g}}= \mathrm{Lie}(G)\)
\item
  There's an induced root space decomposition
  \({\mathfrak{g}}= t\oplus \bigoplus_{\alpha\in \Phi}{\mathfrak{g}}_\alpha\)
\item
  When \(G\) is simple, \(\Phi\) is an \emph{irreducible} root system

  \begin{itemize}
  \tightlist
  \item
    There is a classification of these by Dynkin diagrams
  \end{itemize}
\end{itemize}

\begin{example}

\begin{example}

\(A_n\) corresponds to \({\mathfrak{sl}}(n+1, k)\) (mnemonic: \(A_1\)
corresponds to \({\mathfrak{sl}}(2)\))

\end{example}

\end{example}

\begin{itemize}
\item
  We have representations \(\rho: G\to \operatorname{GL}(V)\),
  i.e.~\(V\) is a \(G{\hbox{-}}\)module
\item
  For \(T\subseteq G\), we have a weight space decomposition:
  \(V = \bigoplus_{\lambda \in X(T)} V_\lambda\) where
  \(X(T) = \hom(T, {\mathbb{G}}_m)\).

  \begin{quote}
  Note that \(X(T) \cong {\mathbb{Z}}^n\), the number of copies of
  \({\mathbb{G}}_m\) in \(T\).
  \end{quote}
\end{itemize}

\hypertarget{root-systems-and-weights}{%
\subsection{Root Systems and Weights}\label{root-systems-and-weights}}

\begin{example}

\begin{example}

Let \(\Phi = A_2\), then we have the following root system:

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-26-14-05-58.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

In general, we'll have
\(\Delta = \left\{{\alpha_1, \cdots, \alpha_n}\right\}\) a basis of
\emph{simple roots}.

\begin{remark}

\begin{remark}

Every root \(\alpha\in I\) can be expressed as either positive integer
linear combination (or negative) of simple roots.

\end{remark}

\end{remark}

For any \(\alpha\in \Phi\), let \(s_\alpha\) be the reflection across
\(H_\alpha\), the hyperplane orthogonal to \(\alpha\). Then define the
\emph{Weyl group}
\(W = \left\{{s_\alpha ~{\text{s.t.}}~\alpha\in \Phi}\right\}\).

\begin{example}

\begin{example}

Here the Weyl group is \(S_3\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-26-14-10-24.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\begin{remark}

\begin{remark}

\(W\) acts transitively on bases.

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

\(X(T) \subseteq {\mathbb{Z}}\Phi\), recalling that
\(X(T) = \hom(T, {\mathbb{G}}_m) = {\mathbb{Z}}^n\) for some \(n\).
Denote \({\mathbb{Z}}\Phi\) the \emph{root lattice} and \(X(T)\) the
\emph{weight lattice}.

\end{remark}

\end{remark}

\begin{example}

\begin{example}

Let \(G = {\mathfrak{sl}}(2, {\mathbb{C}})\) then
\(X(T) = {\mathbb{Z}}\omega\) where \(\omega = 1\),
\({\mathbb{Z}}\Phi = {\mathbb{Z}}\left\{{\alpha}\right\}\) Then there is
one weight \(\alpha\), and the root lattice \({\mathbb{Z}}\Phi\) is just
\(2{\mathbb{Z}}\). However, the weight lattice is
\({\mathbb{Z}}\omega = {\mathbb{Z}}\), and these are not equal in
general.

\end{example}

\end{example}

\begin{remark}

\begin{remark}

There is partial ordering on \(X(T)\) given by
\(\lambda \geq \mu \iff \lambda - \mu = \sum_{\alpha\in \Delta} n_\alpha \alpha\)
where \(n_\alpha \geq 0\). (We say \(\lambda\) \emph{dominates}
\(\mu\).)

\end{remark}

\end{remark}

\begin{definition}[Fundamental Dominant Weights]

\begin{definition}[Fundamental Dominant Weights]

We extend scalars for the weight lattice to obtain
\(E \mathrel{\vcenter{:}}= X(T) \otimes_{\mathbb{Z}}{\mathbb{R}}\cong {\mathbb{R}}^n\),
a Euclidean space with an inner product
\({\left\langle {{\,\cdot\,}},~{{\,\cdot\,}} \right\rangle}\).

For \(\alpha\in \Phi\), define its \emph{coroot}
\(\alpha^\vee\mathrel{\vcenter{:}}={2\alpha \over {\left\langle {\alpha},~{\alpha} \right\rangle}}\).
Define the \emph{simple coroots} as
\(\Delta^\vee\mathrel{\vcenter{:}}=\left\{{\alpha_i^\vee}\right\}_{i=1}^n\),
which has a dual basis
\(\Omega \mathrel{\vcenter{:}}=\left\{{\omega_i}\right\}_{i=1}^n\) the
\emph{fundamental weights}. These satisfy
\({\left\langle {\omega_i},~{\alpha_j^\vee} \right\rangle} = \delta_{ij}\).

\todo[inline]{What is the notation for fundamental weights? Definitely not $\Omega$ usually!}

\begin{quote}
Important because we can index irreducible representations by
fundamental weights.
\end{quote}

A weight \(\lambda\in X(T)\) is \emph{dominant} iff
\(\lambda \in {\mathbb{Z}}^{\geq 0} \Omega\),
i.e.~\(\lambda = \sum n_i \omega_i\) with
\(n_i \in {\mathbb{Z}}^{\geq 0}\).

\end{definition}

\end{definition}

If \(G\) is simply connected, then
\(X(T) = \bigoplus {\mathbb{Z}}\omega_i\).

\begin{quote}
See Jantzen for definition of simply-connected, \({\text{SL}}(n+1)\) is
simply connected but its adjoint \(PGL(n+1)\) is not simply connected.
\end{quote}

\hypertarget{complex-semisimple-lie-algebras}{%
\subsection{Complex Semisimple Lie
Algebras}\label{complex-semisimple-lie-algebras}}

When doing representation theory, we look at the Verma modules
\(Z(\lambda) = U({\mathfrak{g}}) \otimes_{U({\mathfrak{b}}^+)} \lambda \twoheadrightarrow L(\lambda)\).

\begin{theorem}[?]

\begin{theorem}[?]

\(L(\lambda)\) as a finite-dimensional
\(U({\mathfrak{g}}){\hbox{-}}\)module \(\iff\) \(\lambda\) is dominant,
i.e.~\(\lambda \in X(T)_+\).

\end{theorem}

\end{theorem}

Thus the representations are indexed by lattice points in a particular
region:

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-26-14-36-44.png}
\caption{Image}
\end{figure}

\textbf{Question 1}:

Suppose \(G\) is a simple (simply connected) algebraic group. How do you
parameterize \emph{irreducible} representations?

For \(\rho: G\\to \operatorname{GL}(V)\), \(V\) is a \emph{simple
module} (an \emph{irreducible representation}) iff the only proper
\(G{\hbox{-}}\)submodules of \(V\) are trivial.

\textbf{Answer 1}: They are also parameterized by \(X(T)_+\). We'll show
this using the induction functor
\(\operatorname{Ind}_B^G \lambda =H^0(G/B, \mathcal{L}(\lambda))\)
(sheaf cohomology of the flag variety with coefficients in some line
bundle).

\begin{quote}
We'll define what \(B\) is later, essentially upper-triangular matrices.
\end{quote}

\textbf{Question 2}: What are the dimensions of the irreducible
representations for \(G\)?

\textbf{Answer 2}: Over \(k={\mathbb{C}}\) using Weyl's dimension
formula.

For
\(k = \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}_p\mkern-1.5mu}\mkern 1.5mu\):
conjectured to be known for \(p\geq h\) (the \emph{Coxeter number}), but
by Williamson (2013) there are counterexamples. Current work being done!

\hypertarget{friday-august-28}{%
\section{Friday, August 28}\label{friday-august-28}}

\hypertarget{representation-theory}{%
\subsection{Representation Theory}\label{representation-theory}}

Review: let \({\mathfrak{g}}\) be a semisimple lie algebra
\(/{\mathbb{C}}\). There is a decomposition
\({\mathfrak{g}}= {\mathfrak{b}}^+ \oplus {\mathfrak{n}}^- = {\mathfrak{n}}^+ \oplus t\oplus {\mathfrak{n}}^-\),
where \(t\) is a torus. We associate \(U({\mathfrak{g}})\) the universal
enveloping algebra, and representations of \({\mathfrak{g}}\) correspond
with representations of \(U({\mathfrak{g}})\).

Let \(\lambda \in X(T)\) be a weight, then \(\lambda\) is a
\(U({\mathfrak{b}}^+){\hbox{-}}\)module. We can write
\(Z(\lambda) = U({\mathfrak{g}}) \otimes_{U({\mathfrak{b}}^+)} \lambda\).

\begin{remark}

\begin{remark}

There exists a unique maximal submodule of \(Z(\lambda)\), say
\(RZ(\lambda)\) where \(Z(\lambda)/RZ(\lambda) \cong L(\lambda)\) is an
irreducible representation of \({\mathfrak{g}}\).

\end{remark}

\end{remark}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(L = L(\lambda)\) be a finite-dimensional irreducible
representation for \({\mathfrak{g}}\). Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(L \cong Z(\lambda)/RZ(\lambda)\) for some \(\lambda\).
\item
  \(\lambda \in X(T)_+\) is a dominant integral weight.
\end{enumerate}

\end{theorem}

\end{theorem}

\hypertarget{induction}{%
\subsubsection{Induction}\label{induction}}

Let \({\mathfrak{g}}\) be an algebraic group \(/k\) with
\(k = \mkern 1.5mu\overline{\mkern-1.5muk\mkern-1.5mu}\mkern 1.5mu\),
and let \(H \leq G\). Let \(M\) be an \(H{\hbox{-}}\)module, we'll
eventually want to produce a \(G{\hbox{-}}\)modules.

Step 1: Make \(M\) into a \(G\times H\) where the first component
\((g, 1)\) acts trivially on \(M\).

Taking the coordinate algebra \(k[G]\), this is a
\((G-G){\hbox{-}}\)bimodule, and thus becomes a
\(G\times H{\hbox{-}}\)module. Let \(f\in k[G]\), so \(f:G\to K\), and
let \(y\in G\). The explicit action is
\begin{align*}   [(g, h) f] (y) \mathrel{\vcenter{:}}= f(g^{-1} y h) .\end{align*}

Note that we can identify \(H\cong 1\times H \leq G\times H\). We can
form \((M\otimes_k k[G])^H\), the \(H{\hbox{-}}\)fixed points.

\begin{exercise}

\begin{exercise}

Let \(N\) be an \(A{\hbox{-}}\)module and \(B{~\trianglelefteq~}A\),
then \(N^B\) is an \(A/B{\hbox{-}}\)module.

\begin{quote}
Hint: the action of \(B\) is trivial on \(N^B\). Here
\(N^B \mathrel{\vcenter{:}}=\left\{{n\in N ~{\text{s.t.}}~b.n = n\, \forall b\in B}\right\}\)
\end{quote}

\end{exercise}

\end{exercise}

\begin{definition}[Induction]

\begin{definition}[Induction]

The \emph{induced module} is defined as
\begin{align*}   \operatorname{Ind}_H^G(M) \mathrel{\vcenter{:}}=(M\otimes k[G])^H .\end{align*}

\end{definition}

\end{definition}

\hypertarget{properties-of-induction}{%
\subsubsection{Properties of Induction}\label{properties-of-induction}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(({\,\cdot\,}\otimes_k k[G]) = \hom_H(k, {\,\cdot\,}\otimes_k k[G])\)
  is only \emph{left-exact},
  i.e.~\begin{align*}       \qty{0\to A\to B\to C\to 0}\mapsto \qty{0\to FA \to FB \to FC \to \cdots}     .\end{align*}
\item
  By taking right-derived functors \(R^jF\), you can take cohomology.
\end{enumerate}

\begin{quote}
Note that in this category, we won't have enough projectives, but we
will have enough injectives.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  This functor commutes with direct sums and direct limits.
\item
  (\textbf{Important}) Frobenius Reciprocity: there is an adjoint,
  \emph{restriction}, satisfying
  \begin{align*}       \hom_G(N, \operatorname{Ind}_H^G M) = \hom_H(N\downarrow_H, M)     .\end{align*}
\item
  (Tensor Identity) If \(M\in {\operatorname{Mod}}(H)\) and additionally
  \(M \in {\operatorname{Mod}}(G)\), then
  \(\operatorname{Ind}_H^G = M \otimes_k \operatorname{Ind}_H^G k\).
\end{enumerate}

If \(V_1, V_2 \in {\operatorname{Mod}}(G)\) then
\(V_1 \otimes_k V_2 \in {\operatorname{Mod}}(G)\) with the action given
by \(g(v_1\otimes v_2) = gv_1 \otimes gv_2\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Another interpretation: we can write
  \begin{align*}       \operatorname{Ind}_H^G(M) = \left\{{f\in {\operatorname{Hom}}(G, M_a)     ~{\text{s.t.}}~     f(gh) = h^{-1} \cdot f(g)     \, \forall g\in G, h\in H}\right\} \qquad M_a = M \mathrel{\vcenter{:}}={\mathbb{A}}^{\dim M}     .\end{align*}
\end{enumerate}

\begin{quote}
I.e., equivariant wrt the \(H{\hbox{-}}\)action.
\end{quote}

Then \(G\) acts on \(\operatorname{Ind}_H^G M\) by left-translation:
\((gf)(y) = f(g^{-1} y)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  There is an evaluation map:
  \begin{align*}       \varepsilon: \operatorname{Ind}_H^G(M) &\to M \\      f&\mapsto f(1)     .\end{align*}
\end{enumerate}

This is an \(H{\hbox{-}}\)module morphism. Why? We can check
\begin{align*}   \varepsilon(h.f)  &\mathrel{\vcenter{:}}=(h.f)(a) \\ &= f(h^{-1} ) \\ &= hf(1) \\ &= h(\varepsilon(f)) .\end{align*}

We can write the isomorphism in Frobenius reciprocity explicitly:
\begin{align*}   \hom_G(N, \operatorname{Ind}_H^G M) &\xrightarrow{\cong} \hom_H(N, M) \\ \phi & \mapsto \varepsilon\circ \phi .\end{align*}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Transitivity of induction: for \(H\leq H' \leq G\), there is a natural
  transformation (?) of functors:
  \begin{align*}       \operatorname{Ind}_H^G({\,\cdot\,}) = \operatorname{Ind}_{H'}^G\qty{\operatorname{Ind}_H^{H'}({\,\cdot\,}) }     .\end{align*}
\end{enumerate}

\todo[inline]{Equality as a composition of functors?}

\hypertarget{classification-of-simple-ghbox-modules}{%
\subsection{\texorpdfstring{Classification of Simple
\(G{\hbox{-}}\)modules}{Classification of Simple G\{\textbackslash hbox\{-\}\}modules}}\label{classification-of-simple-ghbox-modules}}

Suppose \(G\) is a connected reductive algebraic group \(/k\) with
\(k = \mkern 1.5mu\overline{\mkern-1.5muk\mkern-1.5mu}\mkern 1.5mu\).

\begin{example}

\begin{example}

Let \(G = \operatorname{GL}(n, k)\). There is a decomposition:

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-28-14-39-50.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\textbf{Step 1}: Getting modules for \(U\).

Then there's a general fact: \(U^+ T U \hookrightarrow G\) is dense in
the Zariski topology for any reductive algebraic group. We can form

\begin{itemize}
\tightlist
\item
  \(B^+ \mathrel{\vcenter{:}}= T\rtimes U^+\), the \emph{positive
  borel},
\item
  \(B^- \mathrel{\vcenter{:}}= T\rtimes U\), the \emph{negative borel},
\end{itemize}

Suppose we have a \(U{\hbox{-}}\)module, i.e.~a representation
\(\rho: U \to \operatorname{GL}(V)\). We can find a basis such that
\(\rho(u)\) is upper triangular with ones on the diagonal. In this case,
there is a composition series with 1-dimensional quotients, and the
composition factors are all isomorphic to \(k\).

Moral: for unipotent groups, there are only trivial representations,
i.e.~the only simple \(U{\hbox{-}}\)modules are isomorphic to \(k\).

\textbf{Step 2}: Getting modules for \(B\).

Modules for \(B\) are solvable, in which case we can find a flag. In
this case, \(\rho(b)\) embeds into upper triangular matrices, where the
diagonal action may now not be trivial (i.e.~diagonal is now arbitrary).

Thus simple \(B{\hbox{-}}\)modules arise by taking
\(\lambda \in X(T) = \hom(T, {\mathbb{G}}_m) = \hom(T, \operatorname{GL}(1, k))\),
then letting \(u\) act trivially on \(\lambda\), i.e.~\(u.v = v\). Here
we have \(B \to B/U = T\), so any \(T{\hbox{-}}\)module can be pulled
back to a \(B{\hbox{-}}\)module.

\textbf{Step 3}: Getting modules for \(G\).

Let \(\lambda \in X(T)\), then
\(H^0(\lambda) = \operatorname{Ind}_B^G \lambda = \nabla(\lambda)\).

\hypertarget{monday-august-31}{%
\section{Monday, August 31}\label{monday-august-31}}

\hypertarget{review-of-representation-theory-of-modules}{%
\subsection{Review of Representation Theory of
Modules}\label{review-of-representation-theory-of-modules}}

Take \(R\) a ring, then consider \(M\) an \(R{\hbox{-}}\)module to be a
``vector space'' over \(M\). Note that \(M\) is an \(R{\hbox{-}}\)module
\(\iff\) there exists a ring morphism
\(\rho: R\to \hom_{\text{AbGrp}}(M, M)\).

Now let \(G\) be a group and consider \(G{\hbox{-}}\)modules \(M\). Then
a \(G{\hbox{-}}\)module will be defined by taking \(M/k\) a vector space
and a \(G{\hbox{-}}\)action on \(M\). This is equivalent to having a
group morphism \(\rho: G\to \operatorname{GL}(M)\).

For \(M\) a \(G{\hbox{-}}\)module, given a group action, define
\begin{align*}   \rho: G&\to \operatorname{GL}(M) \\ \rho(g)(m) &= g.m \end{align*}
where \(\rho(h): M\to M\).

Similarly, for \(\rho: G\to \operatorname{GL}(M)\) a group morphism,
define the group action \(g.m \mathrel{\vcenter{:}}=\rho(g)m\). Thus
representations of \(G\) and \(G{\hbox{-}}\)modules are equivalent.

\begin{definition}[?]

\begin{definition}[?]

Let \(M\) be a \(G{\hbox{-}}\)module.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(M\) is a \emph{simple} \(G{\hbox{-}}\)module (equivalently an
  \emph{irreducible representation}) \(\iff\) the only
  \(G{\hbox{-}}\)submodules (equiv. \(G{\hbox{-}}\)invariant subspaces)
  are \(0, M\).
\item
  \(M\) is \emph{indecomposable} \(\iff\) \(M\) can not be written as
  \(M = M_1 \oplus M_2\) with \(M_i < M\) proper submodules.
\end{enumerate}

\end{definition}

\end{definition}

\begin{example}

\begin{example}

For \(G = {\text{SL}}(n, {\mathbb{C}})\), there is a natural
\(n{\hbox{-}}\)dimensional representation \(M = V\), and this is
irreducible.

\end{example}

\end{example}

\todo[inline]{What is $V$?}

\begin{example}

\begin{example}

Let \(R = {\mathbb{Z}}\), so we're considering
\({\mathbb{Z}}{\hbox{-}}\)modules. For \(M={\mathbb{Z}}\), \(M\) is not
simple since \(2{\mathbb{Z}}< {\mathbb{Z}}\) is a proper submodule.
However \(M\) is indecomposable.

\end{example}

\end{example}

Recall from last time: we defined a functor
\(\operatorname{Ind}_H^G({\,\cdot\,}): H{\hbox{-}}\text{mod} \to G{\hbox{-}}\text{mod}\),
where \(\operatorname{Ind}_H^G = \qty{k[G] \otimes M}^H\), the
\(H{\hbox{-}}\)invariants. This functor is left-exact but not
right-exact, so we have cohomology \(R^j \operatorname{Ind}_H^G\) by
taking right-derived functors.

Goal: classify simple \(G{\hbox{-}}\)modules for \(G\) a reductive
connected algebraic group.

\begin{example}

\begin{example}

For \(G = \operatorname{GL}(n , k)\), we have a decomposition

\begin{figure}
\centering
\includegraphics{figures/image_2020-08-31-14-10-01.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

We have

\begin{itemize}
\tightlist
\item
  \(B = T\rtimes U\) the negative Borel,
\item
  \(B = T\rtimes U^+\) the Borel
\end{itemize}

For \(U{\hbox{-}}\)modules: \(k\) is the only simple
\(U{\hbox{-}}\)module. Importantly, if \(V\) is a \(U{\hbox{-}}\)module,
then the fixed points are never zero,
i.e.~\(V^U = \hom_{U{\hbox{-}}\text{Mod}}(k, V) \neq 0\).

For \(B{\hbox{-}}\)modules: let
\(X(T) \mathrel{\vcenter{:}}=\hom(T, {\mathbb{G}}_m) = \hom(T, \operatorname{GL}(1, k))\).
These are the simple representations for the torus \(T\). Thus
\(\lambda \in X(T)\) represents a simple \(T{\hbox{-}}\)module.

We have a map \(B \to B/U = T\), so we can pullback
\(T{\hbox{-}}\)representations to \(B{\hbox{-}}\)representations
(``inflation''), since we have a map \(T\to \operatorname{GL}(1, k)\)
and we can just compose. So \(\lambda\) is a 1-dimensional (simple)
\(B{\hbox{-}}\)module where \(U\) acts trivially.

Lee's theorem: all irreducible representations for \(B\) are
one-dimensional. Thus these are the simple \(B{\hbox{-}}\)modules.

For \(G{\hbox{-}}\)modules: define
\(\nabla(\lambda) \mathrel{\vcenter{:}}=\operatorname{Ind}_B^G(\lambda) = H^0(\lambda)\).

Questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  When does \(H^0(\lambda) = 0\)?
\item
  What is \(\dim_{k{\hbox{-}}\text{Vect}} H^0(\lambda)\)?
\item
  What are the composition factors of \(H^0(\lambda)\)?
\end{enumerate}

\begin{quote}
Known in characteristic zero, wildly open in positive characteristic.
\end{quote}

\begin{remark}

\begin{remark}

Another interpretation: look at the flag variety \(G/B\) and take global
sections, then \(H^0(\lambda) = H^0(G/B, \mathcal{L}(\lambda))\) where
\(\mathcal{L}\) is given by projecting the fiber product
\(G \times_B \lambda \twoheadrightarrow G/B\) onto the first factor.

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

\hfill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(H^0(k) = H^0({\left[ {0, \cdots, 0} \right]}) = k[G/B] = k\).
\item
  \(H^0(M) = M\) if \(M\) is a \(G{\hbox{-}}\)module.
\item
  A \(G{\hbox{-}}\)module \(M\) is \emph{semisimple} iff
  \(M = \bigoplus_{i\in I} M_i\) with each \(M_i\) are simple.
\item
  Can consider the largest semisimple submodule, the \emph{socle}
  \(\operatorname{Soc}\,_G(M)\).
\end{enumerate}

\end{remark}

\end{remark}

\begin{center}
\begin{tikzcd}
L_4 \ar[dr] & & L_5 \oplus L_7\ar[dl] \\
& \qty{L_1 \oplus L_2 \oplus L_3} = \operatorname{Soc}\,_G(M)) & \\
\end{tikzcd}
\end{center}

Goal: classify simple \(G{\hbox{-}}\)modules. Strategy: used dominant
highest weights.

\begin{quote}
As opposed to Verma modules, the irreducibles will be a dual situation
where they sit at the bottom of the module. Indicated by the notation
\(\nabla\) pointing down!
\end{quote}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\lambda \in X(T)\) with \(H^0(\lambda) \neq 0\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\dim H^0(\lambda)^{U^+} = 1\) and
  \(H^0(\lambda)^{U^+} = H^0(\lambda)_\lambda\).
\item
  Every weight of \(H^0(\lambda)\) satisfies
  \(w_u \lambda \leq \mu \leq \lambda\), where \(w_0\) is the longest
  Weyl group element and
  \(\alpha\leq \beta \iff \alpha-\beta \in {\mathbb{Z}}^{+}\Phi\).
\end{enumerate}

\begin{quote}
Note that in fact \(\ell(w_0) = {\left\lvert {\Phi^+} \right\rvert}\).
\end{quote}

\end{proposition}

\end{proposition}

\begin{example}

\begin{example}

Take \(A_2\) with simple reflections \(s_{\alpha_1}, s_{\alpha_2}\) and
\(\Delta = \left\{{\alpha_1, \alpha_2}\right\}\).

\begin{center}
\begin{tikzcd}
& 1\ar[ld] \ar[rd] & \\
s_{\alpha_1} \ar[d] & & s_{\alpha_2}\ar[d] \\
s_{\alpha_1}s_{\alpha_2}\ar[rd] & & s_{\alpha_2} s_{\alpha_1}\ar[ld] \\
& s_{\alpha_2} s_{\alpha_1}s_{\alpha_1} = s_{\alpha_1} s_{\alpha_2} s_{\alpha_1} = w_0 & 
\end{tikzcd}
\end{center}

\end{example}

\end{example}

\begin{proof}[(Sketch)]

\begin{proof}[(Sketch)]

We can write
\begin{align*}   H^0(\lambda) = \left\{{f\in k[G] ~{\text{s.t.}}~f(gb) = \lambda(b)^{-1} f(g) \, b\in B, g\in G}\right\} .\end{align*}

Suppose \(f\in H^0(\lambda)^{U^+}\) and \(u_+ \in U^+, t\in T, u\in U\).
Then
\begin{align*}   \qty{ u_+^{-1} f} (tu)  &= f(tu) \\ &= \lambda(t)^{-1} f(1) .\end{align*}
On the other hand,
\begin{align*}   \qty{ u_+^{-1} f} (tu)  &= f(u_+ t u) .\end{align*}

So by density, \(f(1)\) is determined by \(f(u_+ t u)\) and
\(\dim H^0(\lambda)^{U^+} \leq 1\). But since this can't be zero, the
dimension must be equal to 1.

\end{proof}

\end{proof}

\begin{proposition}[?]

\begin{proposition}[?]

Let \begin{align*}   \varepsilon: H^0(\lambda) \to \lambda \end{align*}
be the evaluation morphism.

This is a morphism of \(B{\hbox{-}}\)modules, and in particular is a
morphism of \(T{\hbox{-}}\)modules. Thus the image of a weight
\(\mu \neq \lambda\) is zero, so \(\varepsilon\) is injective.

\end{proposition}

\end{proposition}

\begin{proof}

\begin{proof}

We have
\begin{align*}   f(u_+ t u) = \lambda(t)^{-1} f(1) = \lambda(t)^{-1} \varepsilon(f) .\end{align*}

Suppose \(f\in H^0(\lambda)^{U^+}\) and \(\varepsilon(f) = 0\). Then
\(f(u_+ t u) = 0\), and by density \(f\equiv 0\), showing injectivity.

Therefore \(H^0(\lambda)^{U^+}\subset H^0(\lambda)_\lambda\). Suppose
\(\mu\) is maximal among weights in \(H^0(\lambda)\). Then
\begin{align*}   H^0(\lambda)_{\mu} \subseteq H^0(\lambda)^{U^+} \end{align*}
because \(U^+\) raises weights.

But \(H^0(\lambda)^{U^+} \subseteq H^0(\lambda)_\lambda\) implies
\(\mu = \lambda\). Thus the maximal weight in \(H^0(\lambda)\) is
\(\lambda\).

\begin{quote}
Recall the situation in lie algebras:
\(g_\alpha v \in V_{\lambda + \alpha}\) when \(v\\in V_{\lambda}\).
\end{quote}

Since \(\lambda\) is maximal, any other weight \(\mu\) satisfies
\(\mu \leq \lambda\). Thus
\begin{align*}   H^0(\lambda)_\lambda \subseteq H^0(\lambda)^{U^+} \subseteq H^0(\lambda)_\lambda ,\end{align*}
forcing these to be equal and finishing part 1.

\end{proof}

\end{proof}

\hypertarget{friday-september-04}{%
\section{Friday, September 04}\label{friday-september-04}}

Some concepts used in the proof of other theorems: Let \(G\) be a
reductive algebraic group and \({\mathfrak{g}}\) its lie algebra. There
is an associative algebra \(U({\mathfrak{g}})\) which reflects the
representation theory of \(G\).

Fact: \({\mathfrak{g}}{\hbox{-}}\)mod
\(\equiv U({\mathfrak{g}}){\hbox{-}}\)modules which are unitary,
i.e.~\(1.m = m\).

We can write a basis
\begin{align*}   {\mathfrak{g}}= \left\langle{e_\alpha, h_i, f_\beta ~{\text{s.t.}}~\alpha\in\Phi^+,\, \beta\in\Phi^-,\, i = 1,2,\cdots,n}\right\rangle ,\end{align*}
the \emph{Chevalley basis}. It turns out that the structure constants
are all in \({\mathbb{Z}}\).

\begin{example}

\begin{example}

Take \({\mathfrak{g}}= {\mathfrak{sl}}(2, k)\), then
\begin{align*}   e = \begin{bmatrix} 0 & 0 \\ 1 & 0 \end{bmatrix} \quad  f = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix} \quad h = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} .\end{align*}

\end{example}

\end{example}

We want to form a \({\mathbb{Z}}{\hbox{-}}\)lattice in
\(U({\mathfrak{g}})\), denoted
\begin{align*}   U({\mathfrak{g}})_{\mathbb{Z}} = \left\langle{ e_\alpha^{[n]} = {e_\alpha^n \over n!},\, f_\beta^{[n]} = {f_\beta^n \over n!}, {h_i \choose m} }\right\rangle .\end{align*}

We then form the \emph{distribution algebra} (or \emph{hyperalgebra} in
earlier literature) as
\(\mathrm{Dist})G) \mathrel{\vcenter{:}}= U({\mathfrak{g}})_{\mathbb{Z}}\otimes_{\mathbb{Z}}k\)
for \(k\) any field (e.g.~\(\operatorname{char}~(k) = p\)).

\begin{theorem}[?]

\begin{theorem}[?]

\(G{\hbox{-}}\)modules \(\equiv \mathrm{Dist}(G){\hbox{-}}\)modules
which are

\begin{itemize}
\tightlist
\item
  \emph{Weight modules}
\item
  \emph{Locally finite}: \(\dim \mathrm{Dist}(G).m < \infty\) for all
  \(m\in M\).
\end{itemize}

\end{theorem}

\end{theorem}

\begin{remark}

\begin{remark}

In characteristic zero, \(\mathrm{Dist}(G) = U({\mathfrak{g}})\). Thus
there is a correspondence
\begin{align*}   \left\{{\substack{G{\hbox{-}}\text{modules}}}\right\} \iff \left\{{\substack{U({\mathfrak{g}}){\hbox{-}}\text{modules}}}\right\}  .\end{align*}

If \(\operatorname{char}~(k) = p\),
e.g.~\(k = \mkern 1.5mu\overline{\mkern-1.5mu\mathbb{F}\mkern-1.5mu}\mkern 1.5mu_p\),
and if the Frobenius map \(F:G\to G\) satisfies
\(G_1\mathrel{\vcenter{:}}=\ker F\) (thinking of \(G_1\) as a group
scheme), then \(\mathrm{Dist}(G_1) < \mathrm{Dist}(G)\) is a proper
submodule. In this case, \({\mathfrak{g}}\subseteq \mathrm{Dist}(G_1)\)
is a finite dimensional Hopf algebra, and
\(k[G_1] = \mathrm{Dist}(G_1)^\vee\). Importantly, the lie algebra does
\emph{not} generate \(\mathrm{Dist}(G)\) if
\(k = \mkern 1.5mu\overline{\mkern-1.5mu\mathbb{F}\mkern-1.5mu}\mkern 1.5mu_p\).

\end{remark}

\end{remark}

\begin{example}

\begin{example}

Take \(G = {\mathbb{G}}_a\), then
\(\mathrm{Dist}({\mathbb{G}}_a) = \left\langle{T^k ~{\text{s.t.}}~k=0,1,\cdots}\right\rangle\)
is an infinite dimensional algebra. In this case,
\(T^k T^\ell = {k+\ell \choose \ell}T^{k+\ell}\). For
\(k={\mathbb{C}}\),
\(\mathrm{Dist}({\mathbb{G}}_a) = \left\langle{T^1}\right\rangle\) has
one generator.

In the case
\(k = \mkern 1.5mu\overline{\mkern-1.5mu\mathbb{F}\mkern-1.5mu}\mkern 1.5mu_p\),
we have
\(\mathrm{Dist}(\qty{{\mathbb{G}}_a}_1) = \left\langle{T^k ~{\text{s.t.}}~0\leq k \leq p-1}\right\rangle\).

Note that taking duals yields a truncated polynomial algebra:
\(k[\qty{{\mathbb{G}}_a}_1] = k[x] / \left\langle{x^p}\right\rangle\).

\end{example}

\end{example}

\hypertarget{review-1}{%
\subsection{Review}\label{review-1}}

Recall that
\(H^0(\lambda) \mathrel{\vcenter{:}}=\operatorname{Ind}_B^G \lambda\).
Proved in last (missed) class: :::\{.remark\} Let
\(H^0(\lambda) \neq 0\). Then

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(\dim H^0(\lambda)_\lambda = 1\) where
  \(H^0(\lambda) = H^0(\lambda)^{U^+}\).
\item
  Each weight \(\mu\) of \(H^0(\lambda)\) satisfies
  \(w_0 \lambda \leq \mu \leq \lambda\), where \(w_0\) is the longest
  Weyl group element. :::
\end{enumerate}

\begin{remark}

\begin{remark}

Let \(H^0(\lambda)_\lambda \neq 0\), then
\(L(\lambda) = \operatorname{Soc}\,_G H^0(\lambda)\) is simple.

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

If \(\mu\) is a weight of \(L(\lambda)\), then
\(w_0 \lambda \leq \mu \leq \lambda\), \(\dim L(\lambda)_\lambda = 1\),
and \(L(\lambda)_\lambda = L(\lambda)^{U+}\).

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

Any simple \(G{\hbox{-}}\)module is isomorphic to \(L(\lambda)\) where
\(H^0(\lambda) \neq 0\).

\end{remark}

\end{remark}

Goal: We now want to classify simple \(G{\hbox{-}}\)modules. So we need
an iff criterion for when \(H^0(\lambda) \neq 0\).

We look at the set of dominant weights
\begin{align*}   X(T)_+  &= \left\{{\lambda \in X(T) ~{\text{s.t.}}~{\left\langle {\lambda},~{\alpha^\vee} \right\rangle}\geq 0 \forall \alpha\in\Delta}\right\} &= \left\{{\lambda \in X(T) ~{\text{s.t.}}~\lambda = \sum_{i=1}^\ell n_i w_i,\, n_i \geq 0}\right\} .\end{align*}

\begin{theorem}[?]

\begin{theorem}[?]

TFAE:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(H^0(\lambda) \neq 0\).
\item
  \(\lambda \in X(T)_+\), i.e.~\(\lambda\) is a dominant weight.
\end{enumerate}

\end{theorem}

\end{theorem}

\begin{proof}

\begin{proof}

\(1\implies 2\): Suppose (1), then consider a simple reflection
\(s_\alpha\) for some \(\alpha \in \Delta\). We know
\(H^0(\lambda)_\lambda \neq 0\), thus
\(H^0(\lambda)_{s_\alpha \lambda} \neq 0\). Therefore
\begin{align*}   s_\alpha \lambda = \lambda - {\left\langle {\lambda},~{\alpha^\vee} \right\rangle}\alpha \leq \lambda \\ \implies 0 \leq {\left\langle {\lambda},~{\alpha^\vee} \right\rangle}\alpha \\ \implies {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \geq 0 \qquad \forall \alpha\in \Delta .\end{align*}

\(2\implies 1\): For a detailed proof, see Jantzen 2.6 in Part II.

\begin{itemize}
\item
  Let \(\lambda \in X(T)_+\), then (by the intro lie algebras course)
  there exists an \(L(\lambda)\): a simple finite dimensional
  \(U({\mathfrak{g}}){\hbox{-}}\)module over \({\mathbb{C}}\).
\item
  \(L(\lambda)\) has an integral basis which is compatible with
  \(U({\mathfrak{g}})_{\mathbb{Z}}\) (Kostant's
  \({\mathbb{Z}}{\hbox{-}}\)form).
\item
  Thus we can base change to get
  \(\tilde L(\lambda) \mathrel{\vcenter{:}}= L(\lambda) \otimes_{\mathbb{Z}}k\),
  which is a \(\mathrm{Dist}(G){\hbox{-}}\)module. Note that
  \(\tilde L(\lambda)\) still has highest weight \(\lambda\), so
  consider \(\hom_B(\tilde L(\lambda), \lambda) \neq 0\).
\item
  Apply frobenius reciprocity:
  \(\hom_B(\tilde L(\lambda), \lambda) = \hom_G(\tilde L(\lambda), \operatorname{Ind}_B^G \lambda) = \hom_G(\tilde L(\lambda), H^0(\lambda))\).
  But then \(H^0(\lambda) \neq 0\) (since otherwise this would imply the
  original hom was zero).
\end{itemize}

\end{proof}

\end{proof}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(G\) be a reductive connected algebraic group over \(k\). Then
there exists a 1-to-1 correspondence between dominant weights and
irreducible \(G{\hbox{-}}\)representations:
\begin{align*}   \left\{{\substack{\text{Dominant weights: } X(T)_+}}\right\} \iff \left\{{\substack{\text{Irreducible representations: }\left\{{L(\lambda) ~{\text{s.t.}}~\lambda \in X(T)_+}\right\} }}\right\} .\end{align*}

\end{theorem}

\end{theorem}

\hypertarget{characters-of-ghbox-modules}{%
\subsection{\texorpdfstring{Characters of
\(G{\hbox{-}}\)modules}{Characters of G\{\textbackslash hbox\{-\}\}modules}}\label{characters-of-ghbox-modules}}

Let \(G\) be reductive, so (importantly) it has a maximal torus \(T\).
Let \(M\in G{\hbox{-}}\mathrm{mod}\), so (importantly)
\(M\in T{\hbox{-}}\mathrm{mod}\).

Then there is a weight space decomposition
\(M = \bigoplus_{\lambda \in X(T)} M_\lambda\). We then write the
character of \(M\) as
\begin{align*}   \operatorname{char}~M \mathrel{\vcenter{:}}=\sum_{\lambda \in X(T)} \qty{\dim M_\lambda} e^{\lambda} \in {\mathbb{Z}}[X(T)] .\end{align*}

Next time: more characters, and Weyl's dimension formula.

\hypertarget{wednesday-september-09}{%
\section{Wednesday, September 09}\label{wednesday-september-09}}

Todo

\hypertarget{wednesday-september-16}{%
\section{Wednesday, September 16}\label{wednesday-september-16}}

\hypertarget{group-schemes}{%
\subsection{Group Schemes}\label{group-schemes}}

\begin{definition}[Representable Functors]

\begin{definition}[Representable Functors]

Let \(F:: k{\hbox{-}}\operatorname{alg}\to {\text{Set}}\) be a functor,
then \(F\) is \textbf{representable} iff \(F(R)\) corresponds to
``solutions to equations in \(R\)''.

\end{definition}

\end{definition}

\begin{example}

\begin{example}

Let \(F({\,\cdot\,}) = {\text{SL}}(2, {\,\cdot\,})\), then the
corresponding equations are \(\det (x_{ij}) = 1\).

\end{example}

\end{example}

If \(F\) is representable, there is a correspondence
\(F(R) \cong \hom_R(A, R)\). In the above example,
\begin{align*}A = k[x_{11}, x_{12}, x_{21}, x_{22}] / \left\langle{x_{11} x_{22} - x_{12}x_{21}}\right\rangle,\end{align*}
which is exactly the coordinate algebra.

\begin{definition}[Affine Group Scheme]

\begin{definition}[Affine Group Scheme]

An \emph{affine group scheme} is a representable functor
\(F:k{\hbox{-}}\operatorname{alg}\to{\text{Groups}}\).

\end{definition}

\end{definition}

Suppose \(G\) is an affine group scheme, and let \(A = k[G]\) be the
representing object. Then there is a correspondence
\begin{align*}   G{\hbox{-}}\text{modules} \iff k[G]^\vee{\hbox{-}}\text{modules} .\end{align*}

For \(G\) reductive, the RHS is equivalent to
\(\operatorname{Dist}(G){\hbox{-}}\)modules.

\begin{definition}[Finite Group Schemes]

\begin{definition}[Finite Group Schemes]

\(G\) is a \textbf{finite} group scheme iff \(k[G]\) is finite
dimensional.

\end{definition}

\end{definition}

If \(G\) is finite, then \(A^\vee\cong k[G]^\vee\) is a cocommutative
Hopf algebras. Thus representations for \emph{finite} group schemes are
equivalent to representations for finite-dimensional cocommutative Hopf
algebras.

\begin{quote}
On group scheme side: see reduction, spectral sequences, conceptual
arguments. On the algebra side: have bases, underlying vector space, can
do concrete computations. Can take
\(\operatorname{Spec}\,\qty{k[G]}^\vee\) to recover a group scheme.
\end{quote}

\hypertarget{hopf-algebras}{%
\subsection{Hopf Algebras}\label{hopf-algebras}}

For \(A\) a \(k{\hbox{-}}\operatorname{alg}\), we have a multiplication
and a unit, which can be defined in terms of diagrams. To categorically
reverse arrows, we can ask for a comultiplication and a counit.
\begin{align*}   \Delta: A &\to A^{\otimes 2} \\ \\ \epsilon: A &\to k  .\end{align*}

We'll want another map, an \emph{antipode}
\begin{align*}   s: A\to A .\end{align*}

The comultiplication should satisfy

\begin{center}
\begin{tikzcd}
A^{\otimes 3} & \ar[l, "1\otimes A"] A^{\otimes 2} \\
A^{\otimes 2}\ar[u, "\Delta \otimes 1"] & \ar[l, "\Delta"]\ar[u, "\Delta"] A
\end{tikzcd}
\end{center}

The counit should satisfy

\begin{center}
\begin{tikzcd}
k\otimes\ar[d, "\cong"] A & \ar[l, "{\varepsilon\otimes 1}"] A^{\otimes 2}\\
A\ar[r, "\cong"] & A\ar[u, "\Delta"]
\end{tikzcd}
\end{center}

And the antipode should satisfy

\begin{center}
\begin{tikzcd}
A & A\ar[l, "{m(s\otimes 1)}"] \\
A\ar[u] & A\ar[l, "\varepsilon"] \ar[u, "\Delta"]
\end{tikzcd}
\end{center}

\hypertarget{module-constructions}{%
\subsubsection{Module Constructions}\label{module-constructions}}

Let \(A\) be a Hopf algebra.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For \(A{\hbox{-}}\)modules \(M, N\), we can form the
  \(A{\hbox{-}}\)module \(M\otimes_k N\) with
  \begin{align*}       \Delta(a) &= \sum a_i \otimes a_j \\ \\     a(m\otimes n) &= \sum a_1 m \otimes a_2 n     .\end{align*}
\item
  If \(M\) is finite-dimensional over \(A\), then
  \(M^\vee= \hom_k(M, k) \ni f\) is an \(A{\hbox{-}}\)module, and we can
  define \((af)(x) \mathrel{\vcenter{:}}= f(s(a)x)\) for
  \(a\in A, x\in M\).
\end{enumerate}

\begin{example}

\begin{example}

\(A = kG\) the group algebra on a group is a Hopf algebra:
\begin{align*}   \Delta: A &\to A^{\otimes 2} \\ g &\mapsto g\otimes g .\end{align*}

The module action is diagonal, namely \(g(m\otimes n) = gm \otimes gn\).
The antipode is given by \(s(g) = g^{-1}\), and the unit is
\(\varepsilon(g) = 1\) for all \(g\in G\).

\end{example}

\end{example}

\begin{example}

\begin{example}

Let \(A = U({\mathfrak{g}})\), the universal enveloping algebra for
\({\mathfrak{g}}\) a Lie algebra. Recall that
\({\mathfrak{g}}{\hbox{-}}\)modules are equivalent to
\(U({\mathfrak{g}}){\hbox{-}}\)modules (unitary representations, some
big associative algebra). Then \(A\) is a Hopf algebra, with
\(\Delta(\ell) = \ell\otimes 1 + 1\otimes\ell\) for
\(\ell \in {\mathfrak{g}}\). The unit is \(\varepsilon(\ell) = 0\), and
the antipode is \(s(\ell) = -\ell\).

\end{example}

\end{example}

\begin{example}

\begin{example}

Take the additive group \({\mathbb{G}}_a\), then
\(A = k[{\mathbb{G}}_a] \cong k[x]\) is a commutative Hopf algebra with
\(\Delta(x) = x\otimes 1 + 1\otimes x\),
\(\varepsilon(x) = 0, s(x) = -x\).

\end{example}

\end{example}

\begin{example}

\begin{example}

For \({\mathbb{G}}_m\), we have
\(A = k[{\mathbb{G}}_m] \cong k[x, x^{-1}], \varepsilon(x) = 1, s(x) = x^{-1}\).

\end{example}

\end{example}

\hypertarget{frobenius-kernels}{%
\subsection{Frobenius Kernels}\label{frobenius-kernels}}

Let \(G\) be an algebraic group (scheme) over \(k\), where
\(\operatorname{char}~(k) = p\). Let \(F:G\to G\) be the Frobenius,
where
e.g.~\begin{align*}   F:\operatorname{GL}(n, {\,\cdot\,}) &\to \operatorname{GL}(n, {\,\cdot\,})\\ (x_{ij}) & \mapsto (x_{ij}^p) .\end{align*}

Then \(F\) is a map of group schemes.

\begin{definition}[Frobenius Kernels]

\begin{definition}[Frobenius Kernels]

\(G_r \mathrel{\vcenter{:}}=\ker F^r\), where
\(F^r \mathrel{\vcenter{:}}= F\circ F \circ \cdots \circ F\) is the
\(r{\hbox{-}}\)fold composition of the Frobenius.

This yields a nesting
\(G_1 {~\trianglelefteq~}G_2 {~\trianglelefteq~}G_3 \cdots \leq G\).

\end{definition}

\end{definition}

Recall that
\begin{align*}   \operatorname{Dist}(G) = \left\langle{ {x_\alpha^n \over n!}, {y_\beta^m \over m!}, {H_i \choose k} }\right\rangle .\end{align*}

We get a chain of finite dimensional algebras
\begin{align*}   \operatorname{Dist}(G_1) \leq \operatorname{Dist}(G_2) \leq \cdots \leq \operatorname{Dist}(G) \end{align*}
where
\begin{align*}   \operatorname{Dist}(G_1) = \left\langle{ {x_\alpha^n \over n!}, {y_\beta^m \over m!}, {H_i \choose k} ~{\text{s.t.}}~0\leq n,m,k \leq p-1 }\right\rangle ,\end{align*}

where in general \(\operatorname{Dist}(G_\ell)\) goes up to
\(p^{\ell} - 1\). Recall that \(G_r\) representations were equivalent to
\(\operatorname{Dist}(G_r)\) representations.

Some basic questions (Curtis, Steinberg, 1960s):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What are the simple modules for Frobenius kernels? I.e., what are the
  irreducible representations for \(G_r\)?
\item
  How are the representations for \(G_r\) related to those for \(G\)?
\end{enumerate}

\begin{quote}
It turns out the representations for \(G_r\) will lift to
representations to \(G\). Use ``twisted tensor product'' (Steinberg).
\end{quote}

\begin{remark}

\begin{remark}

It turns out that \(G_1\) is special.
\begin{align*}   \operatorname{Dist}(G_1) \cong u({\mathfrak{g}}) \mathrel{\vcenter{:}}= U({\mathfrak{g}}) / \left\langle{x^p - x^{[p]}}\right\rangle ,\end{align*}
where \({\mathfrak{g}}= \mathrm{Lie}(G)\) is a \emph{restricted lie
algebra} (N. Jacobson). Note that for \(D\in {\mathfrak{g}}\) a
derivation, we define
\(D^{[p]} \mathrel{\vcenter{:}}= D\circ \cdots \circ D\) is the
\(p{\hbox{-}}\)fold composition.

\(G_1{\hbox{-}}\)modules are equivalent to
\({\mathfrak{g}}{\hbox{-}}\)modules which are \emph{restricted} in the
sense that
\begin{align*}   \rho: g &\to {\mathfrak{gl}}(V) \\ x^{[p]} &\mapsto \rho(x)^p .\end{align*}

\end{remark}

\end{remark}

\hypertarget{friday-september-18}{%
\section{Friday, September 18}\label{friday-september-18}}

\hypertarget{frobenius-kernels-1}{%
\subsection{Frobenius Kernels}\label{frobenius-kernels-1}}

Let \(\operatorname{char}~(k) p > 0\) and let \(G\) be an algebraic
group scheme. We have a Frobenius map \(F:G\to G\) given by
\(F((x_{ij})) = (x_{ij}^p)\), which we can iterate to get \(F^r\) for
\(r\in {\mathbb{N}}\). Setting \(G_r = \ker F^r\) the \(r\)th Frobenius
kernel, we get a normal series of group schemes
\begin{align*}   G_1 {~\trianglelefteq~}G_2 {~\trianglelefteq~}\cdots {~\trianglelefteq~}G .\end{align*}

There is an associated chain of finite dimensional Hopf algebras
\begin{align*}   \operatorname{Dist}(G_1) \leq \operatorname{Dist}(G_2) \leq \cdots \leq \operatorname{Dist}(G) .\end{align*}

Then \(k[G]^\vee= \operatorname{Dist}(G_r)\), and we get an equivalence
of representations for \(G_r\) to representations for
\(\operatorname{Dist}(G_r)\).

A special case will be when \(G\) is a reductive algebraic group scheme.
We'll start by finding a basis for \(\operatorname{Dist}(G_r)\).

Recall the PBW theorem: we have a basis for \({\mathfrak{g}}\) given by
\begin{align*}   \left\{{x_\alpha ~{\text{s.t.}}~\alpha\in \Phi^+ }\right\} &\text{ Positive root vectors} \\ \left\{{h_i ~{\text{s.t.}}~i=1,\cdots, n}\right\} &\text{ A basis for } t \\ \left\{{x_\alpha ~{\text{s.t.}}~\alpha\in \Phi^- }\right\} &\text{ Negative root vectors} \\ .\end{align*}

We can then obtain a basis for \(U({\mathfrak{g}})\):
\begin{align*}   U({\mathfrak{g}}) = \left\langle{ \prod_{\alpha\in\Phi^+} x_\alpha^{n(\alpha)} \prod_{i=1}^n h_i^{k_i} \prod_{\alpha\in\Phi^+} x_{-\alpha}^{m(\alpha)}  }\right\rangle .\end{align*}

We can similarly obtain a basis for the distribution algebra
\begin{align*}   \operatorname{Dist}(G) = \left\langle{  \prod_{\alpha\in\Phi^+} { x_{\alpha}^{n(\alpha)} \over n!}  \prod_{i=1}^n {h_i \choose k_i}  \prod_{\alpha\in\Phi^+} { x_{-\alpha}^{n(\alpha)} \over n!}  }\right\rangle ,\end{align*}
and we can similar get \(\operatorname{Dist}(G_r)\) by restricting to
\(0\leq n(\alpha), k_i, m(\alpha) \leq p^r - 1\). Above the \(k_i\) are
allowed to be any integers. This yields a triangular decomposition
\begin{align*}   \operatorname{Dist}(G_r) = \operatorname{Dist}(U_r^+) \operatorname{Dist}(T_r) \operatorname{Dist}(U_r^-) ,\end{align*}
where we'll denote the first two terms \(\operatorname{Dist}(B_r^+)\)
and the last two as \(\operatorname{Dist}(B_r)\).

\hypertarget{induced-and-coinduced-modules}{%
\subsection{Induced and Coinduced
Modules}\label{induced-and-coinduced-modules}}

Goal: Classify simple \(G_r{\hbox{-}}\)modules. We know the
classification of simple \(G{\hbox{-}}\)modules, so we'll follow similar
reasoning. We started by realizing
\(L(\lambda) \hookrightarrow\operatorname{Ind}_B^G \lambda\) as a
submodule (the socle) of some ``universal'' module.

Let \(M\) be a \(B_r{\hbox{-}}\)module, we can then define
\begin{align*}   \operatorname{Ind}_{B_r}^{G_r}M = \qty{k[G_r] \otimes M }^{B_r} ,\end{align*}
where we're now taking the \(B_r{\hbox{-}}\)invariants. We get a
decomposition as vector spaces,
\begin{align*}   k[G_r] = k[U_r^+] \otimes_k k[B_r] \end{align*} and
thus an isomorphism
\begin{align*}   \operatorname{Ind}_{B_r}^{G_r}M = \qty{k[G_r] \otimes M }^{B_r}  \cong k[U_r^+] \otimes\qty{ k[B_r] \otimes M}^{B_r} \cong k[U_r^+] \otimes M \end{align*}
since
\(k[B_r]\otimes M \cong \operatorname{Ind}_{B_r}^{B_r} M \cong M\).

We then define
\begin{align*}   \operatorname{Coind}_{B_r}^{G_r} = \operatorname{Dist}(G_r) \otimes_{\operatorname{Dist}(B_r)} \otimes M ,\end{align*}
which is an analog of
\(U({\mathfrak{g}})\otimes_{U({\mathfrak{b}})} M\).

We have
\(\operatorname{Dist}(U_r^+) \otimes\operatorname{Dist}(B_r) \cong \operatorname{Dist}(G_r)\),
so

\begin{align*}   \operatorname{Coind}_{B_r}^{G_r} = \operatorname{Dist}(G_r) \otimes_{\operatorname{Dist}(B_r)} \otimes M \cong \operatorname{Dist}(U_r^+) \otimes_k \operatorname{Dist}(B_r) \otimes_{\operatorname{Dist}(B_r)} M  \cong \operatorname{Dist}(U_r^+) \otimes_k M ,\end{align*}
which we'll define as the \textbf{coinduced module}.

We can compute the dimension:
\begin{align*}   \dim \operatorname{Ind}_{B_r}^{G_r} M = \dim \operatorname{Coind}_{B_r}^{G_r} M = \qty{\dim M} p^{r{\left\lvert {\Phi^+} \right\rvert}} .\end{align*}

\begin{quote}
Open: don't know how to compute composition factors.
\end{quote}

\begin{proposition}[?]

\begin{proposition}[?]

\hfill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \begin{align*}\operatorname{Coind}_{B_r}^{G_r} M \equiv \operatorname{Ind}_{B_r}^{G_r} M\otimes 2(p^r - 1)\rho,\end{align*}
  where the last term is a one-dimensional \(B_r{\hbox{-}}\)module and
  \(\rho\) is the \emph{Weyl weight}.
\item
  \begin{align*}\operatorname{Coind}_{B_r^+}^{G_r} M \cong \operatorname{Ind}_{B_r^+}^{G_r} M \otimes-2\qty{p^r-1}\rho\end{align*}
\end{enumerate}

where
\begin{align*}   \rho = {1\over 2}\sum_{\alpha\in\Phi^+} \alpha = \sum_{i=1}^n w_i .\end{align*}

\end{proposition}

\end{proposition}

\begin{proof}[Sketch for (1)]

\begin{proof}[Sketch for (1)]

Since the tensor product satisfies a universal property, we have a map

\begin{center}
\begin{tikzcd}
M \ar[rd, "B_r"]\ar[rr] & & \operatorname{Dist}(G_r)\otimes_{\operatorname{Dist}(B_r)} M\ar[dl, "\exists \psi", dotted] \\
& N = M\operatorname{Ind}_{B_r}^{G_r} \otimes 2(p^r-1)\rho &
\end{tikzcd}
\end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  We need to find a \(B_r\) morphism \(f:M\to N\).
\item
  We need to show that \(f\) generates \(N\) as a
  \(G_r{\hbox{-}}\)module.
\end{enumerate}

Note that if (1) and (2) hold, then \(\psi\) is surjective, but since
\(\dim \operatorname{Coind}_{B_r}^{G_r} M= \dim N\) this forces \(\psi\)
to be an isomorphism.

We can write
\begin{align*}   \operatorname{Ind}_{B_r}^{G_r} M\otimes 2(p^r-1) \rho &= \qty{ k[G_r] \otimes M \otimes 2(p^r-1) \rho  }^{B_r} \\ &\cong \hom_{B_r}\qty{\operatorname{Dist}(G_r), M\otimes 2(p^r-1)\rho } .\end{align*}

Let \(g_m(x) \mathrel{\vcenter{:}}= m\otimes 2(p^r-1)\rho\) for any
\(x =\prod_{\alpha\in\Phi^+} {x_\alpha^{p^r-1} \over \qty{p^r-1}! }\),
and \(g_m(x) = 0\) for any other \(x\).

Now define \(f(m) = g_m\), and check that \(\operatorname{im}({f})\)
generates \(N\).

\end{proof}

\end{proof}

\hypertarget{verma-modules}{%
\subsection{Verma Modules}\label{verma-modules}}

Recall that
\(W(\lambda) \mathrel{\vcenter{:}}= U({\mathfrak{g}}) \otimes_{U({\mathfrak{b}}^+)} \lambda\)
were the \emph{Verma modules} for lie algebras.

Let \(\lambda \in X(T)\), we have \(T_r \leq T\) and restriction yields
a map \(X(T) \to X(T_r)\). Given a weight \(\lambda\), we can write it
\(p{\hbox{-}}\)adically as
\begin{align*}   \lambda = \lambda_0 + \lambda_1 p + \lambda_2 p^2 + \cdots + \lambda_{r-1} + \cdots .\end{align*}

This yields an exact sequence
\begin{align*}   0 \to p^r X(T) \to X(T) \to X(T_r) \to 0 ,\end{align*}

and thus \(X(T) / p^r X(T) \cong X(T_r)\).

Let \(\lambda \in X(T_r)\), then \(\lambda\) becomes a
\(B_r{\hbox{-}}\)module by letting \(U_r\) act trivially, since we have
\begin{align*}   \cdots U_r \to B_r \twoheadrightarrow T_r \to 0 .\end{align*}

Set \(Z(r) = \operatorname{Coind}_{B_r}^{G_r} \lambda\), and set
\(Z(r)' = \operatorname{Ind}_{B_r}^{G_r} \lambda\). Then
\(\dim Z_r(\lambda) = \dim Z_r'(\lambda) = p^{r{\left\lvert {\Phi^+} \right\rvert}}\).
We'll then think of

\begin{itemize}
\tightlist
\item
  \(\operatorname{Coind}\twoheadrightarrow L_r(\lambda)\) being in the
  head,
\item
  \(L_r(\lambda) \hookrightarrow\operatorname{Ind}\) being the socle.
\end{itemize}

\begin{quote}
Note that the dimensions aren't known, nor are the projective covers or
injective hulls.
\end{quote}

We have a form of translation invariance, namely
\begin{align*}   Z_r(\lambda + p^r\nu) = Z_r(\lambda) \qquad &\forall \nu \in X(T) \\ Z_r'(\lambda + p^r\nu) = Z_r'(\lambda) \qquad &\forall \nu \in X(T) .\end{align*}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\lambda \in X(T)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(Z_r(\lambda){\downarrow}_{B_r}\) is the projective cover of
  \(\lambda\) and the injective hull of \(\lambda - 2(p^r-1)\rho\).
\item
  \(Z_r'(\lambda){\downarrow}_{B_r^+}\) is the injective hull of
  \(\lambda\) and the projective hull of \(\lambda - 2(p^r-1)\rho\).
\end{enumerate}

\end{proposition}

\end{proposition}

\hypertarget{monday-september-21}{%
\section{Monday, September 21}\label{monday-september-21}}

Let \(G\) be a reductive algebraic group scheme,
\(k=\mkern 1.5mu\overline{\mkern-1.5mu\mathbb{F}\mkern-1.5mu}\mkern 1.5mu_p\)
with \(p>0\), equipped with the Frobenius map \(F:G\to G\) with \(F^r\)
its \(r{\hbox{-}}\)fold composition. We defined \emph{Frobenius kernels}
\(G_r \mathrel{\vcenter{:}}=\ker F^r\), which are in correspondence with
the cocommutative Hopf algebras \(\operatorname{Dist}(G_r)\).

Goal: We want to classify simple \(G_r{\hbox{-}}\)modules, and to do
this we'll use socles.

We have a maximal torus \(T\subseteq G\) and thus \(T_r \subseteq G_r\)
after acting by Frobenius. This yields a SES
\begin{align*}   0 \to p_r X(T) \to X(T) \to X(T)/p^r X(T) = X(T_r) \to 0 .\end{align*}

How to think about this: take \(\lambda \in X(T_r)\), then we can write
\(\lambda = \lambda + p^r \sigma\) in \(X(T_r)\) for some other weight
\(\sigma \in X(T)\). We'll define the ``baby Verma modules''
\begin{align*}   Z_r(\lambda) \mathrel{\vcenter{:}}=\operatorname{Coind}_{B_r^+}^{G_r} \lambda \\ Z_r'(\lambda) \mathrel{\vcenter{:}}=\operatorname{Ind}_{B_r^+}^{G_r} \lambda ,\end{align*}

and we have
\(\dim Z_r(\lambda) = \dim Z_r'(\lambda) = p^{r {\left\lvert {\Phi^+} \right\rvert}}\).

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\lambda\in X(T)\) be a weight.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(Z_r(\lambda)\downarrow_{B_r}\) is the \emph{projective cover} of
  \(\lambda\) and the \emph{injective hull} of
  \(\lambda - 2 (p^r-1) \rho\).
\item
  \(Z_r'(\lambda)\downarrow_{B_r^+}\) is the \emph{injective hull} of
  \(\lambda\) and the \emph{projective cover} of
  \(\lambda - 2 (p^r-1) \rho\).
\end{enumerate}

\end{proposition}

\end{proposition}

\begin{quote}
Note the latter are \(T_r{\hbox{-}}\)modules, so we let \(U^+\) act
trivially.
\end{quote}

\begin{proof}[of 1]

\begin{proof}[of 1]

What we need to do:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show \(Z_r(\lambda)\downarrow_{B_r}\) is projective.
\item
  Show \(Z_r(\lambda)\) is the smallest projective module such that
  \(Z_r(\lambda) \twoheadrightarrow\lambda\).
\end{enumerate}

For (1), we can write
\begin{align*} \operatorname{Dist}(G_r) = \operatorname{Dist}(U_r^+) \operatorname{Dist}(B_r) = \operatorname{Dist}(B_r^+) \operatorname{Dist}(U_r), ,\end{align*}
and so
\begin{align*}   Z_r(\lambda)  &= \operatorname{Coind}_{B_r^+}^{G_r} \lambda \\ &= \qty{\operatorname{dist}(G_r) \otimes_{\operatorname{Dist}(B_r)} \lambda} \downarrow_{B_r^+} \\ &= \operatorname{Dist}(U_r^+)\otimes\lambda \\ &= \operatorname{Dist}(B_r^+) \otimes_{\operatorname{Dist}(T_r)} \lambda \\ &= \operatorname{Coind}_{T_r}^{B_r^+} \lambda .\end{align*}

Why is this projective? Look at cohomology, suffices to show that higher
Exts vanish. So consider
\begin{align*}   \operatorname{Ext}_{B_r^+}^n(\operatorname{Coind}_{T_r}^{B_r^+}, M)  &= \operatorname{Ext}_{T_r}^n (\lambda, M) \qquad\text{by Frobenius reciprocity} \\ &= 0 \qquad \text{for } n \geq 0 ,\end{align*}
since representations for \(T_r\) are completely reducible, and we've
used the fact that \(\operatorname{Coind}_{T_r}^{B_r^+}({\,\cdot\,})\)
is exact.

\begin{quote}
Note: general algebra fact that higher exts vanish for projective
modules.
\end{quote}

For (2), we can write
\begin{align*}   \hom_{B_r^+}(Z_r(\lambda), \mu) &= \hom_{B_r^+}(\operatorname{Coind}_{T_r}^{B_r^+} \lambda, \mu) \\ &= \hom_{T_r} (\lambda, \mu) \qquad\text{by Frobenius reciprocity} \\ &= \begin{cases} k \& \lambda = \mu \\ 0 \& \text{else}. \end{cases} \end{align*}

Thus
\(Z_r(\lambda) / {\operatorname{rad}~}Z_r(\lambda) \downarrow{B_r^+} = \lambda\).

If we now write \(A= \operatorname{Dist}(B_r^+)\) and
\({\mathfrak{g}}= {\mathfrak{n}}^+ \oplus t \oplus {\mathfrak{n}}\) with
\({\mathfrak{b}}^+ \mathrel{\vcenter{:}}={\mathfrak{n}}^+ \oplus t\),
\begin{align*} \sum_S \qty{\dim P(S)} \qty{\dim(S)} \\ &= \sum_{\lambda \in X(T_r)} \qty{\dim Z_r(\lambda)} \qty{\dim \lambda} \\ &= \sum_{\lambda \in X(T_r)} p^{r{\left\lvert {\Phi^+} \right\rvert}} \cdot 1 \\ &= {\left\lvert {X(T_r)} \right\rvert} p^{r{\left\lvert {\Phi^+} \right\rvert}} \\ &= p^{rn} p^{r{\left\lvert {\Phi^+} \right\rvert}} \qquad n = \dim t\\ &= p^{r \dim {\mathfrak{b}}^+} \\ &= \dim A \end{align*}

\end{proof}

\end{proof}

\hypertarget{simple-ghbox-modules}{%
\subsection{\texorpdfstring{Simple
\(G{\hbox{-}}\)modules}{Simple G\{\textbackslash hbox\{-\}\}modules}}\label{simple-ghbox-modules}}

We know that after taking fixed points, \(Z_r(\lambda)^{U_r}\) and
\(Z_r'(\lambda)^{U_r^+}\) are one-dimensional, and thus
\begin{align*}   Z_r(\lambda) / {\operatorname{rad}~}Z_r(\lambda) \cong L_r(\lambda) \qquad \operatorname{Soc}\,_{G_r} Z_r'(\lambda) = L_r(\lambda) \end{align*}
following the same argument considering \(H_0(\lambda)\).

For any \(\lambda \in X(T_r)\) we have
\(0\neq L_r = \operatorname{Soc}\,_{G_r} Z_r'(\lambda)\). By the
one-dimensionality above, we know
\begin{align*}   L_r(\mu) = L_r(\lambda) \iff \lambda = \mu \in X(T_r) .\end{align*}

Letting \(N\) be a simple \(G_r{\hbox{-}}\)module, we can consider it as
a \(B_r{\hbox{-}}\)module, and the simple \(B_r{\hbox{-}}\)modules are
one dimensional and obtained from simple \(T_r{\hbox{-}}\)modules. We
then know that for some \(\lambda \in X(T_r)\),
\begin{align*}   0 \neq \hom_{B_r}(N, \lambda) \\ &= \hom_{G_r}(N, \operatorname{Ind}_{B_r}^{G_r} \lambda) ,\end{align*}
which implies that
\(N\hookrightarrow\operatorname{Ind}_{B_r}^{G_r} \lambda = Z_r'(\lambda)\)
as a submodule, and thus \(N = L_r(\lambda)\).

\begin{theorem}[Main Theorem]

\begin{theorem}[Main Theorem]

Let \(\Lambda\) be a set of representatives of
\(XX(T) / p^r X(T) \cong X(T_r)\). Then there exists a one-to-one
correspondence
\begin{align*}   \Lambda \iff \left\{{L_r(\lambda) \lambda \in \Lambda}\right\} ,\end{align*}
where the RHS are simple \(G_r{\hbox{-}}\)modules.

\end{theorem}

\end{theorem}

How to think about this: \textbf{restricted regions}. Choose dominant
weights as representatives
\begin{align*}   X_r(T)  &= \left\{{\lambda \in X(T)_+ ~{\text{s.t.}}~0\leq {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} < p^r\, \forall \alpha\in \Delta }\right\} \\ &= \left\{{\lambda \in X(T)_+ ~{\text{s.t.}}~\lambda = \sum_{i=1}^\ell n_i w_i,\, 0\leq n_j \leq p^r-1\, \forall j}\right\} \\ .\end{align*}

Pictures:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-21-14-43-23.png}
\caption{Root systems, chambers formed by dominant weights}
\end{figure}

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-21-14-43-56.png}
\caption{Restricted regions}
\end{figure}

Some facts:

If \(\lambda \in X(T)_+\), then \(L(\lambda)\) is a simple
\(G{\hbox{-}}\)module.

\textbf{Question 1}: What happens when we restrict
\(L(\lambda)\downarrow_{G_r}\)?

\textbf{Answer}: This remains irreducible over \(G_r\) iff
\(\lambda \in X_r(T)\), i.e.~if
\(L(\lambda)\downarrow_{G} \cong L_r(\lambda)\) when
\(\lambda \in X_r(T)\).

\textbf{Question 2}: Given \(L(\lambda)\) for \(\lambda \in X(T)_+\),
can we express \(L(\lambda)\) in terms of simple
\(G_r{\hbox{-}}\)modules?

\textbf{Answer}: Yes, can be formulated in terms of \emph{Steinberg's
twisted tensor product}.

\hypertarget{friday-september-25}{%
\section{Friday, September 25}\label{friday-september-25}}

\hypertarget{review-and-proposition}{%
\subsection{Review and Proposition}\label{review-and-proposition}}

From last time: Steinberg's tensor product.

Let \(G\) be a reductive algebraic group scheme over \(k\) with
\(\operatorname{char}~(k) > 0\). We have a Frobenius \(F:G\to G\), we
iterate to obtain \(F^r\) and examine the Frobenius kernels
\(G_r\mathrel{\vcenter{:}}=\ker F^r\).

If we have a representation \(\rho: G\to \operatorname{GL}(M)\), we can
``twist'' by \(F^r\) to obtain
\(\rho^{(r)}: G \to \operatorname{GL}(M^{(r)})\). We have

Here \(M^{(r)}\) has the same underlying vector space as \(M\), but a
new module structure coming from \(\rho^{(r)}\). Note that \(G_r\) acts
trivially on \(M^{(r)}\).

\begin{itemize}
\tightlist
\item
  \(\left\{{L(\lambda) ~{\text{s.t.}}~\lambda \in X(T)_+}\right\}\) are
  the simple \(G{\hbox{-}}\)modules,
\item
  \(\left\{{L_r(\lambda) ~{\text{s.t.}}~\lambda \in X_r(T)_+}\right\}\)
  are the simple \(G_r{\hbox{-}}\)modules,
\end{itemize}

Note that \(L(\lambda)\downarrow_{G_r}\) is semisimple, equal to
\(L_r(\lambda)\) for \(\lambda \in X_r(T)\).

\begin{quote}
1960's, Curtis and Steinberg.
\end{quote}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\lambda \in X_r(T)\) and \(\mu \in X(T)_+\). Then
\begin{align*}   L(\lambda + p^r \mu) \cong L(\lambda) \otimes L(\mu)^{(r)} .\end{align*}

\end{proposition}

\end{proposition}

Recall that socle formula: letting \(M\) be a \(G{\hbox{-}}\)module, we
have an isomorphism of \(G{\hbox{-}}\)modules:
\begin{align*}  \operatorname{Soc}\,_{G_r} \cong \bigoplus_{\lambda \in X_r(T)} L(\lambda) \otimes\hom_{G_r}(L(\lambda), M) .\end{align*}

\hypertarget{proof}{%
\subsection{Proof}\label{proof}}

\begin{proof}

\begin{proof}

Let \(M = L(\lambda + p^r \mu)\). Then from the socle formula, only one
summand is nonzero, and thus \(\hom_{G_r}(L(\lambda), M)\) must be
simple. Then there exists a \(\tilde \lambda \in X_r(T)\) and a
\(\tilde \mu \in X(T)_+\) such that
\begin{align*}   M = L(\tilde \lambda) \otimes L(\tilde\mu)^{(r)} .\end{align*}

We now compare highest weights:
\begin{align*}   \lambda + p^r \mu = \tilde \lambda + p^r \tilde \mu \implies \lambda = \tilde \lambda {\quad \text{and} \quad} \mu = \tilde \mu .\end{align*}

\end{proof}

\end{proof}

\begin{theorem}[Steinberg]

\begin{theorem}[Steinberg]

Let \(\lambda \in X(T)_+\), with a \(p{\hbox{-}}\)adic expansion
\begin{align*}   \lambda = \lambda_0 + \lambda_1 p + \cdots + \lambda_m p^m .\end{align*}
where \(\lambda_j \in X_1(T)\) for all \(j\). Then
\begin{align*}   L(\lambda) = L(\lambda_0) \otimes\bigotimes_{j=1}^m L(\lambda_j)^{(j)} .\end{align*}

\end{theorem}

\end{theorem}

\begin{corollary}[?]

\begin{corollary}[?]

In order to know \(\dim L(\lambda)\) for \(\lambda \in X(T)_+\), it is
enough to know \(\dim L_1(\mu)\) for \(\mu \in X_1(T)\). Schematic:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-25-14-13-47.png}
\caption{Image}
\end{figure}

\end{corollary}

\end{corollary}

\hypertarget{some-history}{%
\subsection{Some History}\label{some-history}}

Recall that simplie \(G_1{\hbox{-}}\)modules correspond to simple
\(\operatorname{Dist}(G_1){\hbox{-}}\)modules, and
\(\operatorname{Dist}(G_1) \cong U({\mathfrak{g}})\).

\begin{itemize}
\item
  1980: Lusztig proved conjecture: \(\operatorname{char}~L(\lambda)\)
  for \(\lambda \in X_1(T)\) is given by KL polynomials, shown for
  \(p \geq 2(h-1)\).
\item
  Kato showed for \(p> h\), where \(h\) is the \emph{Coxeter number}
  satisfying
  \(h = {\left\langle {\rho},~{\alpha_i ^\vee} \right\rangle} + 1\)
  where \(\alpha_i^\vee\) is the highest short root.
\item
  1990's: A relation to representations of quantum groups \(U_q\) and
  affine lie algebras \(\widehat{\mathfrak{g}}\):

  \begin{center}
  \begin{tikzcd}
  \mod u({\mathfrak{g}}) & \ar[l] \mod U_q({\mathfrak{g}}) \ar[r, "\cong"] & \mod\widehat{\mathfrak{g}}
  \end{tikzcd}
  \end{center}

  The first map is due to Andersen-Jantzen-Soergel for \(p\gg 0\) with
  no effective lower bounds, and the equivalence is due to
  Kazhdan-Lusztig, where the L conjecture holds for
  \(\widehat{\mathfrak{g}}\).
\item
  2000's: Fiebig showed the L conjecture holds for \(p>N\) where \(N\)
  is an effective (but large) lower bound.
\item
  2013: Geordie Williamson shows L conjecture is false, with infinitely
  many counterexamples, and no lower bounds that are linear in \(h\).
\end{itemize}

\begin{quote}
See Donkin's Tilting Module conjecture: expected that characters may
come from \(p{\hbox{-}}\)KL polynomials instead.
\end{quote}

\begin{example}

\begin{example}

Let \(G= {\text{SL}}(2)\), so \(\dim T =1\). Here the restricted region
of weights is given by \(X_!(T) = \left\{{0,1,\cdots, p-1}\right\}\).
Then \(H^0(\lambda) = S^\lambda(V)\) for
\(\lambda \in X(T)_+ = {\mathbb{Z}}_{\geq 0}\) and
\(L(\lambda) \subseteq H^0(\lambda)\).

\begin{theorem}[?]

\begin{theorem}[?]

\begin{align*}   L(\lambda) =  H^0(\lambda) {\quad \text{for} \quad} \lambda \in X_1(T) .\end{align*}

\end{theorem}

\end{theorem}

\begin{theorem}[?]

\begin{theorem}[?]

\begin{align*}   \dim L(\lambda) = \lambda + 1 {\quad \text{for} \quad} \lambda \in X_1(T) .\end{align*}

\end{theorem}

\end{theorem}

Take \(p=3\). Then \(\dim L(0) = 1\), \(\dim L(1) = 2\) (the natural
representation), and \(\dim L(2) = 3\) (the adjoint representation).
Then for \(p=4\), we have to use the twisted tensor product formula.
Taking the 3-adic expansion \(4 = 1\cdot 3^0 + 1\cdot 3^1\), we have
\begin{align*}   L(4) = L(1) \otimes L(1)^{(1)} .\end{align*}

Since \(\dim L(1) = 2\), we get \(\dim L(4) = 4\).

Similarly, considering \(7 = 1\cdot 3^0 + 2\cdot 3^1\), we get
\begin{align*}   L(7) \cong L(1) \otimes L(2)^{(1)} \end{align*} and so
\(\dim L(7) = 6\).

Take \(p=5\), then

\begin{itemize}
\tightlist
\item
  \(\dim L(0) = 1\)
\item
  \(\dim L(1) = 2\)
\item
  \(\dim L(2) = 3\)
\item
  \(\dim L(3) = 4\)
\item
  \(\dim L(4) = 5\)
\end{itemize}

What is \(H^0(5)\)? We know \(L(5)\) is a submodule, and we can write
the character
\begin{align*}   \operatorname{char}~H^0(5) = e^5 + e^3 + e^1 + e^{-1} + e^{-3} + e^{-5} .\end{align*}

We know \(\operatorname{char}~(L(1)) = e^1 + e^{-1}\) and
\(L(5) = L(1)^{(1)}\), so we can write
\(\operatorname{char}~L() = e^{5} + e^{-5}\). By quotienting, we have
\(\operatorname{char}~H^0(5) - \operatorname{char}~L(5) = e^3 + e^1 + e^{-1} +e^{-3} = \operatorname{char}~L(3)\).
Thus the composition factors of \(H^0(5)\) are \(L(5)\) and \(L(3)\).

These correspond to an action of the affine Weyl group:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-25-14-45-28.png}
\caption{Image}
\end{figure}

There is a \textbf{strong linkage principle} which describes the
possible composition factors of \(H^0(\lambda)\).

We can thus find the socle/head structure:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-25-14-47-44.png}
\caption{Image}
\end{figure}

Thus \(\operatorname{Ext}_G^1(L(5), L(3)) \cong k\).

\end{example}

\end{example}

\begin{quote}
Note that in other types, we don't know the characters of the
irreducibles in the restricted region, so we don't necessarily know the
composition factors.
\end{quote}

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-25-14-51-40.png}
\caption{Image}
\end{figure}

\hypertarget{monday-september-28}{%
\section{Monday, September 28}\label{monday-september-28}}

\hypertarget{kempfs-theorem}{%
\subsection{Kempf's Theorem}\label{kempfs-theorem}}

Next topic: Kempf's Vanishing Theorem. Proof in Jantzen's book involving
ampleness for sheaves.

Setup:

We have

\begin{center}
\begin{tikzcd}
G & \text{a reductive algebraic group over } k = \mkern 1.5mu\overline{\mkern-1.5muk\mkern-1.5mu}\mkern 1.5mu \\
B\ar[u, "\subseteq"] & \text{the Borel subgroup} \\
T\ar[u, "\subseteq"] & \text{its maximal torus}
\end{tikzcd}
\end{center}

along with the weights \(X(T)\).

We can consider derived functors of induction, yielding
\(R^n \operatorname{Ind}_B^G \lambda = \mathcal{H}^n(G/B, \mathcal{L}(\lambda)) \mathrel{\vcenter{:}}= H^n(\lambda)\)
where \(\mathcal{L}(\lambda)\) is a line bundle and \(G/B\) is the flag
variety.

Recall that

\begin{itemize}
\tightlist
\item
  \(H^0(\lambda) = \operatorname{Ind}_B^G(\lambda)\),
\item
  \(\lambda \not\in X(T)_+ \implies H^0(\lambda) = 0\)
\item
  \(\lambda \in X(T)_+ \implies L(\lambda) = \operatorname{Soc}\,_G H^0(\lambda) \neq 0\).
\end{itemize}

\begin{theorem}[Kempf]

\begin{theorem}[Kempf]

If \(\lambda \in X(T)_+\) a dominant weight, then \(H^n(\lambda) = 0\)
for \(n> 0\).

\end{theorem}

\end{theorem}

\begin{remark}

\begin{remark}

In \(\operatorname{char}~(k) = 0\), \(H^n(\lambda)\) is known by the
Bott-Borel-Weil theorem. In positive characteristic, this is not know:
the characters \(\operatorname{char}~H^n (\lambda)\) is known, and it's
not even known if or when they vanish. Wide open problem!

\begin{quote}
Could be a nice answer when \(p>h\) the Coxeter number.
\end{quote}

\end{remark}

\end{remark}

\hypertarget{good-filtrations-and-weyl-filtrations}{%
\subsection{Good Filtrations and Weyl
Filtrations}\label{good-filtrations-and-weyl-filtrations}}

We define two classes of distinguished modules for
\(\lambda \in X(T)_+\):

\begin{itemize}
\tightlist
\item
  \(\nabla(\lambda) \mathrel{\vcenter{:}}= H^0(\lambda) = \operatorname{Ind}_B^G \lambda\)
  the costandard/induced modules.
\item
  \(\Delta(\lambda) = V(\lambda) \mathrel{\vcenter{:}}= H^0(-w_0 \lambda) = \operatorname{Ind}_B^G \lambda\)
  the standard/Weyl modules

  \begin{itemize}
  \tightlist
  \item
    Here \(w_0\) is the longest element in the Weyl group
  \end{itemize}
\end{itemize}

We have
\begin{align*}   L(\lambda) &\hookrightarrow\nabla(\lambda) \Delta(\lambda) &\twoheadrightarrow L(\lambda) .\end{align*}

We define the category \(\text{Rat}{\hbox{-}}G\) of rational
\(G{\hbox{-}}\)modules. This is a \emph{highest weight category} (as is
e.g.~Category \({\mathcal{O}}\)).

\begin{definition}[Good Filtrations]

\begin{definition}[Good Filtrations]

An (possibly infinite) ascending chain of \(G{\hbox{-}}\)modules
\begin{align*}   0 \leq V_0 \subseteq V_1 \subseteq V_2 \subseteq \cdots \subseteq V \end{align*}
is a \textbf{good filtration} of \(V\) iff

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(V = \cup_{i\geq 0} V_i\)
\item
  \(V_i/V_{i-1} \cong H^0(\lambda_i)\) for some
  \(\lambda_i \in X(T)_+\).
\end{enumerate}

\begin{quote}
In characteristic zero, the \(H^0\) are irreducible and this recovers a
composition series. Since we don't have semisimplicity in this category,
this is the next best thing.
\end{quote}

\end{definition}

\end{definition}

\begin{definition}[Weyl Filtration]

\begin{definition}[Weyl Filtration]

With the same conditions of a good filtration, a chain is a \textbf{Weyl
filtration} on \(V\) iff

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(V = \cup_{i\geq 0} V_i\)
\item
  \(V_i/V_{i-1} \cong V(\lambda_i)\) for some \(\lambda_i \in X(T)_+\).
\end{enumerate}

\begin{quote}
I.e. the different is now that the quotients are standard modules.
\end{quote}

\end{definition}

\end{definition}

\begin{definition}[Tilting Modules]

\begin{definition}[Tilting Modules]

\(V\) is a \textbf{tilting module} iff \(V\) has both a good filtration
and a Weyl filtration.

\end{definition}

\end{definition}

\begin{theorem}[Ringel, 1990s]

\begin{theorem}[Ringel, 1990s]

Let \(\lambda \in X(T)_+\) be a dominant weight. Then there is a unique
indecomposable highest weight tilting module \(T(\lambda)\) with highest
weight \(\lambda\).

\end{theorem}

\end{theorem}

\begin{example}

\begin{example}

We have the following situation for type \(A_2\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-14-18-03.png}
\caption{Image}
\end{figure}

And thus a decomposition:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-14-18-46.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

The picture to keep in mind is the following: 4 types of modules, all
indexed by dominant weights:

\begin{center}
\begin{tikzcd}
& H^0(\lambda) & \\
L(\lambda) \ar[ur, hookrightarrow] & & T(\lambda)\arrow[ul, twoheadrightarrow]\\
& V(\lambda) \arrow[ul, twoheadrightarrow] \ar[ur, hookrightarrow]
\end{tikzcd}
\end{center}

\hypertarget{cohomological-criteria-for-good-filtrations}{%
\subsection{Cohomological Criteria for Good
Filtrations}\label{cohomological-criteria-for-good-filtrations}}

We'll take cohomology in the following way: let \(G\) be an algebraic
group scheme, and define
\begin{align*}   H^n(G, M) \mathrel{\vcenter{:}}= \mathrm{Ext} G^n(k, M) \end{align*}

where to compute \(\operatorname{Ext}_G^n(M, N)\) we take an injective
resolution \(N \hookrightarrow I_*\), apply \(\hom_G(M, {\,\cdot\,})\),
and take kernels mod images.

Letting \(\lambda \in {\mathbb{Z}}\Phi\) be integral, so
\(\lambda_{\alpha \in \Delta} = \sum n_\alpha \alpha\), define the
\textbf{height}
\begin{align*}   \text{ht}(\lambda) = \sum_{\alpha\in\Delta} n_\alpha .\end{align*}

\begin{lemma}[?]

\begin{lemma}[?]

There exists an injective resolution of \(B{\hbox{-}}\)modules
\begin{align*}   0\to k\to I_0 \to I_1 \to \cdots \end{align*} where

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(I_0\) is the injective hull of \(k\),
\item
  All weights of \(I_j\), say \(\mu\) satisfy \(\text{ht}(\mu) \geq j\).
\end{enumerate}

\end{lemma}

\end{lemma}

\begin{align*}   k[u] \text{ an injective $B{\hbox{-}}$module} \\ k\hookrightarrow\operatorname{Ind}_T^B k \mathrel{\vcenter{:}}= I_0 = k[u] .\end{align*}

We thus get a diagram of the form

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-14-32-38.png}
\caption{Image}
\end{figure}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(H\leq G\), then there exists a spectral sequence
\begin{align*}   E^{i, j}_2 = \operatorname{Ext}_G^i(N, R^j \operatorname{Ind}_H^G M) \implies \operatorname{Ext}_H^{i+j}(N, M) \end{align*}
for \(N\in {\operatorname{Mod}}(G), M\in {\operatorname{Mod}}(H)\).

\end{proposition}

\end{proposition}

\begin{example}

\begin{example}

Let \(H=B\) and take \(G=G\) itself, and let \(N = k\) the trivial
module and \(M\in {\operatorname{Mod}}(G)\) be any rational
\(G{\hbox{-}}\)module. We have
\begin{align*}   E_2^{i, j} = \operatorname{Ext}^{i}_B(k, R^j \operatorname{Ind}_B^G M) \implies \operatorname{Ext}^{i+j}_B(k, M) .\end{align*}

Observations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\item
  \(R^0 \operatorname{Ind}_B^G k = \operatorname{Ind}_B^G k = k\).
\item
  The tensor identity works here,
  i.e.~\(R^j \operatorname{Ind}_B^G M = \qty{R^j \operatorname{Ind}_B^G k} \otimes M\).
\item
  \(R^j \operatorname{Ind}_B^G k = 0\) for \(j> 0\) since we have a
  dominant weight.
\end{enumerate}

The spectral sequence thus collapses on \(E_2\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-14-41-33.png}
\caption{Image}
\end{figure}

Thus
\begin{align*}   E_2^{i, 0} = \operatorname{Ext}^i_B(k, M) = H^i(B, M) .\end{align*}

\end{example}

\end{example}

\begin{corollary}[?]

\begin{corollary}[?]

Let \(G \supseteq P \supseteq B\) where \(P\) is a \emph{parabolic}
subalgebra and let \(M\) be a rational \(G{\hbox{-}}\)module. Then
\(H^n(G, M) = H^n(P, M) = H^n(B, M)\) for all \(n \geq 0\).

\end{corollary}

\end{corollary}

\begin{example}

\begin{example}

Fix a Dynkin diagram and take a subset \(J\subseteq \Delta\).

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-14-47-01.png}
\caption{i}
\end{figure}

Then \(L_j\rtimes U_j = P_J = P\), and we have a decomposition like

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-28-15-13-36.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(M\in {\operatorname{Mod}}(P)\) with \(P\supseteq B\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  If \(\dim M < \infty\) then \(\dim H^n(P, M) < \infty\) for all \(n\).
\item
  If \(H^j(P, M) \neq 0\) then there exists \(\lambda\) a weight of
  \(M\) with \(-\lambda \in {\mathbb{N}}\Phi^+\) and
  \(\text{ht}(-\lambda) \geq j\).
\end{enumerate}

\end{proposition}

\end{proposition}

\hypertarget{wednesday-september-30}{%
\section{Wednesday, September 30}\label{wednesday-september-30}}

Recall that we had a dominant weight \(\lambda \in X(T)_+\) with

\begin{center}
\begin{tikzcd}
& V(\lambda)\ar[dl, "\twoheadrightarrow"]\ar[dr, "\hookrightarrow"] & \\
L(\lambda)\ar[dr, "\hookrightarrow"] & &T(\lambda)\ar[dl, "\twoheadrightarrow"] \\
& H^0(\lambda) &
\end{tikzcd}
\end{center}

where we have a module with both a \emph{good} and a \emph{Weyl}
filtration.

If \(B\subseteq P \subseteq G\) with \(P\) parabolic and
\(M\in {\operatorname{Mod}}(G)\), we have a ``transfer theorem'': maps
\begin{align*}   H^n(G; M) \xrightarrow{\operatorname{Res}} H^n(P; M) \xrightarrow{\operatorname{Res}} H^n(B; M) \end{align*}
induced by restrictions which are isomorphisms.

\begin{proposition}[?]

\begin{proposition}[?]

Let \(M\in {\operatorname{Mod}}(P)\) with \(P\supseteq B\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  If \(\dim M < \infty\) then \(\dim H^n(P; M) < \infty\).
\item
  If \(H^j(P; M) \neq 0\) then there exists a weight \(\lambda\) of
  \(M\) such that \(-\lambda \in {\mathbb{N}}\Phi^+\) and
  \(\text{ht}(-\lambda) \geq j\).
\end{enumerate}

\end{proposition}

\end{proposition}

\begin{quote}
Part (a) is proved in the book, we won't show it here.
\end{quote}

\begin{proof}[of part b]

\begin{proof}[of part b]

Suppose \(H^j(P; M) \neq 0\), then we have an injective resolution
\(I_*\) for \(k\). Tensoring with \(M\) yields an injective resolution
for \(M\),
\begin{align*}   0 \to M \to I_0\otimes M \to I_1 \otimes M \to \cdots .\end{align*}
Since \(H^j(B; M) \neq 0\), we know that the cocycles
\(\hom_B(k, I_j\otimes M) \neq 0\) and thus
\(\hom_T(k, I_j\otimes M) \neq 0\).

So there exists a weight \(-\lambda\) of \(I_j\) with
\(\text{ht}(-\lambda) \geq j\), and we know \(\lambda\) is a weight of
\(M\) applying the previous lemma: namely we know that \(\lambda\) is
invariant under the torus action, so there is a weight \(-\lambda\) such
that \(-\lambda + \lambda = 0\).

\end{proof}

\end{proof}

\todo[inline]{? Why the last part?}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(\lambda, \mu \in X(T)_+\), then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The cohomology in the tensor product is zero, except in one special
  case:
  \begin{align*}       H^i(G, H^0(\lambda) \otimes H^0(\mu))     =     \begin{cases}     0 & i>0 \\     k & i=0, \lambda = -w_0\mu     \end{cases}     .\end{align*}
\item
  There are only extensions in one specific situation:
  \begin{align*}       \operatorname{Ext}_G^i(V(\mu), H^0(\lambda)) =      \begin{cases}     0 & i> 0 \\     k & i=0, \lambda = \mu     \end{cases}     .\end{align*}
\end{enumerate}

\end{theorem}

\end{theorem}

The following is an important calculation!

\begin{proof}

\begin{proof}

Step 1: We'll use Frobenius reciprocity twice. We can write the term of
interest in two ways:
\begin{align*}   H^i(G, H^0(\lambda) \otimes H^0(\mu)) = H^i(B, H^0(\lambda) \otimes\mu) \\ \\ H^i(G, H^0(\lambda) \otimes H^0(\mu)) = H^i(G, \lambda \otimes H^0(\mu)) .\end{align*}

Thus there exists a weight \(\nu\) of \(H^0(\lambda)\) and \(\nu'\) of
\(H^0(\mu)\) such that
\begin{align*}   \mu + \nu, \lambda + \nu' \in - {\mathbb{N}}\Phi^+ \quad \text{ht}(\mu+\nu), \text{ht}(\lambda + \nu') \leq -i .\end{align*}

Since \(w_0\lambda\) (resp. \(w_0\mu\)) is the lowest of weight of
\(H_0(\lambda)\) (resp. \(H_0(\mu)\)), it follows that
\begin{align*}   \mu + w_0 \lambda, \lambda + w_0\mu \in -{\mathbb{N}}\Phi^+ .\end{align*}

Since \(w_0^2 = \text{id}\), we can write
\(\lambda + w_0\mu = w_0(\mu + w_0 \lambda)\). We know that the LHS is
in \(-{\mathbb{N}}\Phi^+\), and the term in parentheses on the RHS is
also in \(-{\mathbb{N}}\Phi^+\). Applying \(w_0\) interchanges
\(\Phi^\pm\), so the RHS is in \({\mathbb{N}}\Phi^+\). But
\({\mathbb{N}}\Phi^+ \cap-{\mathbb{N}}\Phi^+ = \left\{{0}\right\}\),
forcing \(\lambda + w_0 \mu = 0\) and thus \(\lambda = -w_0 \mu\).

Since the height of zero is zero, we have
\begin{align*}   0 = \text{ht}(\lambda + w_0 \mu) \leq \text{ht}(\lambda + \nu') \leq -i \implies i=0 .\end{align*}
This shows cohomological vanishing for \(i>0\), the first case in the
theorem statement.

For the remaining case, we can check that
\(H^0(\lambda)^{U} = H^0(\lambda)_{w_0 \lambda}\), and so
\begin{align*}   \qty{H^0(\lambda) \otimes-w_0 \lambda}^{U^+} = k .\end{align*}
This shows that \(H^0(B; H^0(\lambda) \otimes-w_0\lambda ) \cong k\),
since
\begin{align*}   \qty{H^0(\lambda) \otimes-w_0 \lambda}^B = \qty{ \qty{H^0(\lambda) \otimes-w_0 \lambda }^U }^T .\end{align*}

\end{proof}

\end{proof}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\lambda, \mu \in X(T)_+\) with \(\lambda \not> \mu\). Then we can
calculate the \(i\)th ext by computing the \(i-1\)st: for \(i>0\),
\begin{align*}   \operatorname{Ext}^i_G(L(\lambda), L(\mu)) \cong \operatorname{Ext}^{i-1}_G(L(\lambda), H^0(\mu) / \operatorname{Soc}\,_G(H^0(\mu))) .\end{align*}

\end{proposition}

\end{proposition}

\begin{remark}

\begin{remark}

We showed this in a special case. Let \(i=1\) with
\(\lambda \not> \mu\), then
\begin{align*}   \operatorname{Ext}_G^1(L(\lambda), L(\mu)) \cong {\operatorname{Hom}}_G(L(\lambda), H^0(\mu) / \operatorname{Soc}\,_G(H^0(\mu))) .\end{align*}
Thus it suffices to understand only the previous layer:

\begin{figure}
\centering
\includegraphics{figures/image_2020-09-30-14-25-09.png}
\caption{Image}
\end{figure}

\end{remark}

\end{remark}

\begin{proof}

\begin{proof}

Consider the SES
\begin{align*}   0 \to L(\mu) \to H^0(\mu) \to H^0(\mu) / \operatorname{Soc}\,_G(H^0(\mu)) \to 0 \end{align*}
which yields a LES in homology by applying
\(\hom_G(L(\lambda), {\,\cdot\,})\). To obtain the statement, it
suffices to show \(\operatorname{Ext}_G^1(L(\lambda), H^0(\mu)) = 0\)
for \(i>0\), since this is the middle column in the LES.

We can write
\begin{align*}   \operatorname{Ext}_G^i(L(\lambda), H^0(\mu)) = H^i(G, L(\lambda)^\vee\otimes H^0(\mu)) \quad\text{taking duals} \\ = H^i(B, L(\lambda)^\vee\otimes\mu) \quad\text{by Frobenius reciprocity} ,\end{align*}
so we can obtain a weight \(\sigma\) of \(L(\lambda)^\vee\otimes\mu\)
such that \(\sigma \in - {\mathbb{N}}\Phi^+\) and
\(\text{ht}(-\sigma) \geq i > 0\) by applying the previous lemma. So
\(\sigma = \nu + \mu\) for \(\nu\) some weight of \(L(\lambda)^\vee\).

By rearranging, we find that \(\sigma \in {\mathbb{N}}\Phi^-\). Letting
\(\lambda\) be the lowest weight of \(L(\lambda)^\vee\), we find
\(\sigma \geq -\lambda + \mu\) (since this can only lower the weight).

But then \(-\lambda + \mu \in {\mathbb{N}}\Phi^-\), implying
\(-\mu + \lambda \in {\mathbb{N}}\Phi^-\), and the LHS here is equal to
\(\lambda - \mu\). This precisely says \(\lambda > \mu\), which
contradicts the assumption that \(\lambda\) did not dominate \(\mu\). It
may also be the case that \(\lambda = \mu\), which is handled
separately.

\end{proof}

\end{proof}

We now want criteria for when we can find the following types of lifts:

\begin{center}
\begin{tikzcd}
 & V \\
L(\lambda) \ar[ur, "\hookrightarrow"] \ar[r, "\hookrightarrow"] & H^0(\lambda) \ar[u, dotted, "\hookrightarrow"]
\end{tikzcd}
\end{center}

\begin{lemma}[Important!]

\begin{lemma}[Important!]

Let \(V\) be a \(G{\hbox{-}}\)module with
\(0\neq \hom_G(L(\lambda), V)\). If

\begin{itemize}
\item
  \(\hom(L(\mu), V) = 0\),
\item
  \(\operatorname{Ext}_G^1(V(\mu), V) = 0\) for all \(\mu \in X(T)_+\)
  with \(\mu < \lambda\),
\end{itemize}

then \(V\) contains a submodule isomorphic to \(H^0(\lambda)\) and such
a lift/extension exists.

\end{lemma}

\end{lemma}

\begin{remark}

\begin{remark}

The ext criterion will be the most important. The idea is to quotient
and continue applying it.

\end{remark}

\end{remark}

\begin{proof}

\begin{proof}

Consider the SES
\begin{align*}   0 \to L(\lambda) \hookrightarrow V \to V/L(\lambda) \to 0 \end{align*}
as well as
\begin{align*}   0 \to L(\lambda) \to H^0(\lambda) \to H^0(\lambda)/L(\lambda) \to 0 .\end{align*}

Now want to applying the LES in cohomology by applying
\(\hom_G({\,\cdot\,}, V)\), we get a LES of homs over \(G\):
\begin{align*}   0 &\to {\operatorname{Hom}}(H^0(\lambda)/L(\lambda), V) \to {\operatorname{Hom}}(H^0(\lambda) , V) \to {\operatorname{Hom}}(L(\lambda), V)  \\ &\to \operatorname{Ext}^1(H^0(\lambda)/L(\lambda), V) \to \cdots .\end{align*}
Thus it suffices to show this \(\operatorname{Ext}^1\) is zero.

Strategy: show all of the composition factors of
\(H^0(\lambda)/L(\lambda)\) are zero These are all of the form
\(L(\mu)\) for \(\mu < \lambda\), so it now suffices to just show that
\(\operatorname{Ext}_G^1(L(\mu), V) = 0\) when \(\mu < \lambda\).

Observe that we have
\begin{align*}   0 \to N \to V(\mu) \to L(\mu) \to 0 \end{align*} where
\(N\) are \(L(\sigma)\) composition factors for \(\sigma < \mu\). So
apply \(\hom({\,\cdot\,}, V)\):
\begin{align*}   0  &\to {\operatorname{Hom}}(L(\mu), V) \to {\operatorname{Hom}}(V(\mu), V) \to {\operatorname{Hom}}(N, V) \\ &\to \operatorname{Ext}^1(L(\mu), V) \to \operatorname{Ext}^1(V(\mu), V) \to \cdots .\end{align*}

But we have \({\operatorname{Hom}}(N, V) =0\) and
\(\operatorname{Ext}^1(V(\mu), V) = 0\), which \emph{squeezes} and
forces \(\operatorname{Ext}^1(L(\mu), V) = 0\).

\end{proof}

\end{proof}

Next time: state and prove a cohomological criterion (Donkin, Scott,
proved independently) for a \(G{\hbox{-}}\)module to admit a good
filtration. More about when tensor products of induced modules have good
filtrations.

\hypertarget{friday-october-02}{%
\section{Friday, October 02}\label{friday-october-02}}

Recall that \emph{good filtration} is a chain
\(\left\{{0}\right\} \subseteq V_1 \subseteq \cdots \subseteq V\)
satisfying \(V = \cup V_i\) and \(V_i/V_{i-1} \cong H^0(\lambda_i)\) for
\(\lambda_i\) some weight of \(V\).

\begin{lemma}[?]

\begin{lemma}[?]

Let \(V\) be a \(G{\hbox{-}}\)module and \(\lambda \in X(T)_+\) with
\(\hom_G(L(\lambda), V)\). If \(\hom_G(L(\mu), V) = 0\) for any
\(\mu < \lambda\) and \(\operatorname{Ext}_G^1(V(\mu), V) = 0\) for
\emph{all} \(\mu \in X(T)_+\), then \(V\) contains a submodule
isomorphic to \(H^0(\lambda)\).

\end{lemma}

\end{lemma}

That is, we have a lift of the following form:

\begin{center}
\begin{tikzcd}
L(\lambda) \ar[d, hook] \ar[r, hook] & V \\
H^0(\lambda) \ar[ru, hook, dotted, "\exists"]
\end{tikzcd}
\end{center}

\begin{theorem}[Cohomological Condition for Good Filtrations]

\begin{theorem}[Cohomological Condition for Good Filtrations]

Let \(V\) be a \(G{\hbox{-}}\)module.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(V\) admits a good filtration, then the number of factors
  isomorphic to \(H^0(\lambda)\), denoted \([V: H^0(\lambda)]\), is
  equal to \(\dim \hom_G(V(\lambda), V)\).
\end{enumerate}

\begin{quote}
Analog of Jordan-Holder. Note that \(H^0(\lambda)\) may not by
irreducible, but changing the filtration can not change the number of
composition factors.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Suppose \(\hom_G(V(\lambda), V)<\infty\), then TFAE:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(V\) admits a good filtration.
\item
  \(\operatorname{Ext}^i_G(V(\lambda), V) = 0\) for all
  \(\lambda \in X(T)_+\) and all \(i>0\).
\item
  \(\operatorname{Ext}^1_G(V(\lambda), V) = 0\) for all
  \(\lambda \in X(T)_+\).
\end{itemize}

\begin{quote}
Much like measuring projectivity: can check all exts, or just the first.
\end{quote}

\end{theorem}

\end{theorem}

\begin{proof}[Part a]

\begin{proof}[Part a]

Suppose \(V\) has a good filtration. Idea: induct on the filtration.

Suppose \(V = H^0(\lambda_1)\), then
\begin{align*}   [V: H^0(\mu) ] =  \begin{cases} 0 & \mu \neq \lambda_1 \\ 1 & \mu = \lambda_1 \end{cases} = \dim \hom_G(V(\lambda_1), V) ,\end{align*}
since we know the dimensions of these hom spaces from a previous result.

Suppose now that we have
\begin{align*}   0 \to H^0(\mu_1) \to V H^0(\mu_2) \to 0 .\end{align*}
Applying \(F \mathrel{\vcenter{:}}=\hom_G(V(\lambda), {\,\cdot\,})\), we
find that \(\operatorname{Ext}^1_G\) vanishes. So this leads a SES, and
the dimensions are thus additive. The result follows since \(F\) is
additive.

\end{proof}

\end{proof}

\begin{proof}[Part b]

\begin{proof}[Part b]

\(1\implies 2\): Use the fact that
\(\operatorname{Ext}^i_G(V(\lambda), H^0(\mu)) = 0\) for all \(i>0\) and
all \(\mu\).

\(2\implies 3\): Clear!

\(3\implies 1\): Choose a total ordering of weights
\(\lambda_0, \lambda_1, \cdots \in X(T)\) such that if
\(\lambda_i < \lambda_j\) then \(i<j\). Since \(V\neq 0\), there exists
a dominant weight \(\lambda \in X(T)_+\) such that
\(\hom_G(V(\lambda), V) \neq 0\), so choose \(i\) minimally in this
order to produce such a \(\lambda_i\). Idea: use this to start a
filtration.

Then \(\hom(L(\lambda_i), V) \neq 0\), and we have
\begin{align*}   V(\lambda_i) \twoheadrightarrow L(\lambda_i) \hookrightarrow V .\end{align*}

We know that
\begin{align*}   \hom_G(V(\mu), V) = 0 \quad \forall \mu < \lambda_i \\ \hom_G(L(\mu), V) = 0 \quad \forall \mu < \lambda_i \\ \operatorname{Ext}_G^1(L(\mu), V) = 0 \quad \forall \mu \in X(T)_+ \text{ by assumption} .\end{align*}

So the following map must be an injection, since there is no socle:

\begin{center}
\begin{tikzcd}
          & L(\lambda_i) \ar[r, hook] \ar[d, hook] & V \\
0 \ar[r]  & H^0(\lambda_i) \ar[ur, hook] &
\end{tikzcd}
\end{center}

Set \(V_1 = H^0(\lambda_i)\), so \(V_1 \subseteq V\). We then have a SES
\begin{align*}   0 \to V_1 \to V \to V/V_1 \to 0  .\end{align*}

Applying \(\hom(V(\lambda), {\,\cdot\,})\) we obtain

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-02-14-26-17.png}
\caption{Cancellation in LES}
\end{figure}

Now iterate this process to obtain a chain
\(V_1 \subseteq V_2 \subseteq \cdots \subseteq V\), and set
\(V' \mathrel{\vcenter{:}}=\cup_{i>0} V_i\). Then
\(\dim \hom_G(V(\lambda), V') = \dim \hom_G( V(\lambda), V )\) since
\(\dim \hom_G(V(\lambda), V) < \infty\). But then taking the SES
\begin{align*}   0\to V' \to V \to V/V' \to 0 \end{align*} and applying
\({\operatorname{Hom}}(V(\lambda), {\,\cdot\,})\), we have
\({\operatorname{Hom}}(V(\lambda), V/V') = 0\) and we get an isomorphism
of homs. But then \(\hom(V(\lambda), V/V') = 0\) for all
\(\lambda \in X(T)_+\), forcing \(V/V'=0\) and \(V=V'\).

\end{proof}

\end{proof}

\begin{corollary}[?]

\begin{corollary}[?]

Let \(0\to V_1 \to V \to V_2 \to 0\) be a SES of \(G{\hbox{-}}\)modules
with \(\dim \hom_G(V(\lambda), V_2) < \infty\) for all
\(\lambda \in X(T)_+\). If \(V_1, V\) have good filtrations, then
\(V_2\) also has a good filtration.

\end{corollary}

\end{corollary}

Note: this is likely difficult to prove without cohomology! But here we
can apply the ext criterion.

\begin{proof}

\begin{proof}

Let \(\lambda \in X(T)_+\), then

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-02-14-34-18.png}
\caption{Image}
\end{figure}

\end{proof}

\end{proof}

For \(\lambda \in X(T)_+\), let \(I(\lambda)\) be the injective hull of
\(L(\lambda)\), so we have
\begin{align*}   0 \to L(\lambda) \hookrightarrow I(\lambda) .\end{align*}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(\lambda \in X(T)_+\) and \(I(\lambda)\) be the injective hull of
\(L(\lambda)\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(I(\lambda)\) has a good filtration.
\item
  The multiplicity \([I(\lambda): H^0(\mu)]\) is equal to
  \([H^0(\mu): L(\lambda)]\), the composition factor multiplicity.
\end{enumerate}

\begin{quote}
Brauer-Humphreys Reciprocity. Same idea as in category
\({\mathcal{O}}\): multiplicity of Vermas equals multiplicity of
irreducibles.
\end{quote}

\end{theorem}

\end{theorem}

\begin{proof}[of a]

\begin{proof}[of a]

How to check that it has a good filtration? The cohomological criterion!
So consider \(\operatorname{Ext}^1_G( V(\sigma), I(\lambda) )\) for all
\(\sigma \in X(T)_+\). We want to show it's zero, but this follows
because \(I(\lambda)\) is injective.

\end{proof}

\end{proof}

\begin{proof}[of b]

\begin{proof}[of b]

By the previous result, we have
\begin{align*}   [I(\lambda): H^0(\mu) ]  &= \dim \hom_G(V(\mu), I(\lambda)) \\ &= [V(\mu): L(\lambda) ] .\end{align*}
Why does this second equality hold? The functor
\(\hom_G({\,\cdot\,}, I(\lambda))\) is exact, and
\(\hom_G(L(\mu), I(\lambda)) = \delta_{\lambda, \mu}\). If
\(\lambda = \mu\) there's only one morphism, since
\(L(\lambda) \hookrightarrow I(\lambda)\) and
\(\operatorname{Soc}\,_G I(\lambda) = L(\lambda)\). This means that they
have the same character,
\(\operatorname{char}~H^0(\lambda) = \operatorname{char}~V(\lambda)\),
and this implies that they have the same composition factors.

\end{proof}

\end{proof}

\begin{theorem}[Cohomological Criterion for Weyl Filtrations]

\begin{theorem}[Cohomological Criterion for Weyl Filtrations]

Let \(V\) be a \(G{\hbox{-}}\)module.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  If \(V\) admits a Weyl filtration, then
  \begin{align*}     [V: V(\lambda)] = \dim \hom_G (V, H^0(\lambda))     \end{align*}
\item
  Suppose that \(\dim \hom_G(V(\lambda), H^0(\lambda)) < \infty\) for
  all \(\lambda \in X(T)_+\). Then TFAE
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(V\) has a Weyl filtration.
\item
  \(\operatorname{Ext}^i_G(V, H^0(\lambda)) = 0\) for all
  \(\lambda \in X(T)_+\) and \(i>0\).
\item
  \(\operatorname{Ext}^1_G(V, H^0(\lambda)) = 0\) for all
  \(\lambda \in X(T)_+\).
\end{itemize}

\end{theorem}

\end{theorem}

\hypertarget{monday-october-05}{%
\section{Monday, October 05}\label{monday-october-05}}

Crelle 1988 (CPS: Cline Parshall Scott)

Let HWC denote a highest weight category.

\begin{example}

\begin{example}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  BGG Category \({\mathcal{O}}\)
\item
  \(\operatorname{Rat}(G)\) for \(G\) a reductive algebraic group
\item
  \(\operatorname{Perv}_W(G/B) \cong {\mathcal{O}}_0\)
\end{enumerate}

\end{example}

\end{example}

See

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Donkin: On generalized Schur algebras
\item
  Irving: BGG algebras
\end{enumerate}

There is a equivalence between HWC and QHA (quasi-hereditary algebras).

\begin{remark}

\begin{remark}

Key Points

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(L(\lambda) = \operatorname{Soc}\,_G \nabla(\lambda)\) and
  \(\nabla(\lambda) = A(\lambda)\).
\item
  All composition factors of \(\nabla(\lambda)\) satisfy
  \(\mu \leq \lambda\)
\item
  We have cohomological vanishing:
  \begin{align*}     \operatorname{Ext}_G^i(\Delta(\lambda), \nabla(\mu)) =      \begin{cases}     0 & i >0 \\     0 & i=0, \lambda \neq \mu \\     k & i=0. \lambda = 0     \end{cases}     \end{align*}
\end{enumerate}

\end{remark}

\end{remark}

Interval finite poset: we'll have a cone \(\Lambda\) of positive
weights:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-05-14-14-30.png}
\caption{Image}
\end{figure}

\begin{quote}
See handout!
\end{quote}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(G ,G'\) be rational \(G{\hbox{-}}\)modules admitting good
filtrations. Then the tensor product \(V\otimes V'\) also admits a good
filtration.

\end{theorem}

\end{theorem}

\begin{itemize}
\tightlist
\item
  First proofs:

  \begin{itemize}
  \tightlist
  \item
    JP Wong, Type A
  \item
    Donkin, all but characteristic 2 and \(E_7, E_8\).
  \item
    O. Mathieu, general proof using algebraic geometry
  \end{itemize}
\end{itemize}

\begin{example}

\begin{example}

Let \(G = {\text{SL}}(n, k)\) and take the natural representation
\(V = H^0(w_1)\). Then \(V^{\otimes d}\) has a good filtration.

\end{example}

\end{example}

\begin{theorem}[?]

\begin{theorem}[?]

Let \(J\subset \Delta\) be a subset of simple roots. If
\(V \in {\operatorname{Mod}}(G)\) has a good filtration and \(L_J\) is a
Levi factor, then \(V{\downarrow_{L_J}}\) has a good filtration.

\end{theorem}

\end{theorem}

\begin{theorem}[?]

\begin{theorem}[?]

Let \({\mathfrak{g}}= \operatorname{Lie}(G)\) and \(p\) be a \emph{good
prime} (doesn't divide any of the coefficients of the highest weight).
Then the symmetric algebra \(S({\mathfrak{g}})\) has a good filtration.

\end{theorem}

\end{theorem}

\begin{remark}

\begin{remark}

For \(p\geq 3(h-1)\), the exterior algebra \(\Lambda({\mathfrak{g}})\)
also admits a good filtration. Question: Is this true for all primes
\(p\)? Or potentially for all \emph{good} primes \(p\)?

\end{remark}

\end{remark}

\hypertarget{polynomial-representation-theory}{%
\subsection{Polynomial Representation
Theory}\label{polynomial-representation-theory}}

Let \(G = \operatorname{GL}(n, k)\), then a module for \(G\) is
\textbf{polynomial} iff the weights
\(\lambda = (\lambda_1, \cdots, \lambda_n)\) satisfy
\(\lambda_j \geq 0\) for all \(j\).

\begin{example}

\begin{example}

For \(V\) the natural representation, the weights are the unit vectors
\(\varepsilon_1, \cdots, \varepsilon_n\), so \(V\) is a polynomial
representation. Then \(V^{\otimes d}\) is again polynomial by a previous
remark.

\end{example}

\end{example}

\begin{remark}

\begin{remark}

Note that the adjoint representation
\({\mathfrak{g}}\cong V\otimes V^\vee\) is not a polynomial
representation.

\end{remark}

\end{remark}

\begin{theorem}[?]

\begin{theorem}[?]

There is an equivalence
\begin{align*}   \mathrm{Poly}(G) \cong \bigoplus_{j\geq 0} {\operatorname{Mod}}(S(n, d)) ,\end{align*}
where this Schur algebra \(S(n, d)\) is given by
\(\operatorname{End}_{\Sigma_d}(V^{\otimes d})\) where \(\Sigma_d\) is
the symmetric group of \(d\) letters.

The theorem is that \({\operatorname{Mod}}(S(n, d))\) is a QHA, and thus
a highest weight category.

\end{theorem}

\end{theorem}

\begin{remark}

\begin{remark}

This is a finite-dimensional algebra, so we should be able to calculate
the dimensions, index by highest weights, write the standard/costandard
modules, etc. There is a correspondence
\begin{align*}  \left\{{\substack{\text{Simple modules for }S(n, d)}}\right\} \iff \left\{{\substack{\Lambda^+(n, d) \text{ partitions of $d$ with at most $n$ parts}}}\right\} .\end{align*}

We can compute
\begin{align*}   \dim S(n, d) = {n^2 + d - 1 \choose n^2 - 1} ,\end{align*}
and simple modules correspond to \(L(\lambda)\) for
\(\operatorname{GL}_n\) where \(\lambda\) is a polynomial
representation.

\end{remark}

\end{remark}

\begin{theorem}[?]

\begin{theorem}[?]

\(S(n, d)\) is semisimple if and only if

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(k = {\mathbb{C}}\) or characteristic zero, or
\item
  \(d < p\).
\end{enumerate}

\begin{quote}
For latter condition, see Maschke's theorem
\end{quote}

\end{theorem}

\end{theorem}

\begin{example}

\begin{example}

Consider \(S(2, 3)\) for \(p=2\), so \(G = \operatorname{GL}(2)\). Then
\begin{align*}   \dim S(2, 3) = {4+3-1 \choose 3} = {6\choose 3} = 20 .\end{align*}

The only admissible partitions are thus

\begin{itemize}
\tightlist
\item
  \((3)\), and
\item
  \((2, 1)\).
\end{itemize}

Then \(L(2, 1) = L("w")\) as an \({\text{SL}}(2){\hbox{-}}\)module, so
\begin{align*} \dim L(2, 1) = 2 \end{align*} Then \(L(3, 0) = L("3w")\)
as an \({\text{SL}}(2){\hbox{-}}\)module. We can compute
\begin{align*}   L(3) = L(1, 0)^{(1)} \otimes L(1, 0) ,\end{align*} and
since each is 2-dimensional, we get \(\dim L(3) = 4^2 + 2^2 = 20\).

Note that the sum of the squares of the dimensions of the irreducibles
are equal to the total dimension, which shows this module is semisimple.
But this contradicts the theorem! So it turns out there is a third
condition, namely this exact case.

\end{example}

\end{example}

Next time: look at structure of injective modules, then the theory of
Bott-Borel-Weil for higher sheaf cohomology.

\hypertarget{wednesday-october-07}{%
\section{Wednesday, October 07}\label{wednesday-october-07}}

\hypertarget{schur-algebras}{%
\subsection{Schur Algebras}\label{schur-algebras}}

Let \(G = \operatorname{GL}(n, k)\), then polynomial representations of
\(G\) are equivalent to \(S(n, d)\) modules for all \(d\geq 0\), where
we can note that
\(S(n, d) = \operatorname{End}_{\Sigma_d}(V^{\otimes d})\). We'll have a
correspondence
\begin{align*}   \left\{{\substack{L(\lambda) \text{ simple modules for } S(n,d)}}\right\} \iff \Lambda^+(n, d) \text{, partitions of $d$ with at most $n$ parts} ,\end{align*}

\begin{example}

\begin{example}

\begin{quote}
Good example, can see all filtrations at work, tilting modules, etc.
\end{quote}

Consider \(S(3, 3)\) for \(p=3\), we then have the partitions
\(\Lambda^+(3, 3) = \left\{{(3), (2, 1), (1,1,1)}\right\}\). We can
think of these in the \(\varepsilon\) basis as
\((3) = (3,0,0), (2,1) = (2,1,0)\). Since
\({\text{SL}}(3, k) \subset \operatorname{GL}(3, k)\), we can find the
\(SL(3, k)\) weights by taking successive differences to yield
\((3, 0), (1, 1), (0, 0)\) with the corresponding picture

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-00-10.png}
\caption{Image}
\end{figure}

We can compute

\begin{itemize}
\tightlist
\item
  \(L(1,1,1) = H^0(1,1,1)\)
\item
  \(L(2, 1) = H^0(2, 1)\)
\item
  \(L(3) = H^0(3)\)
\end{itemize}

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-02-04.png}
\caption{Image}
\end{figure}

We have a form of Brauer reciprocity:
\begin{align*}   [I(\lambda): H^0(\mu)] = [H^0(\mu) : L(\lambda) ]  .\end{align*}

We can now compute the injective hulls:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-05-28.png}
\caption{Image}
\end{figure}

What are the tilting modules? We can use the fact that
\(L(1^3) = V(1^3)\). It has a good filtration and a Weyl filtration and
thus must be the tilting module for \(L(1^3)\).

Using the following fact:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-07-57.png}
\caption{Image}
\end{figure}

We can compute the following:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-10-44.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\hypertarget{simplicity-of-h0lambda}{%
\subsection{\texorpdfstring{Simplicity of
\(H^0(\lambda)\)}{Simplicity of H\^{}0(\textbackslash lambda)}}\label{simplicity-of-h0lambda}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(k = {\mathbb{C}}\) implies \(L(\lambda) = H^0(\lambda)\) for all
  \(\lambda \in X(T)_+\)
\item
  \(k= \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}\mkern-1.5mu}\mkern 1.5mu_p\)
  implies \(L(\lambda) = H^0(\lambda)\) if
  \({\left\langle {\lambda},~{\alpha_0^\vee} \right\rangle} \leq 1\)
  where \(\alpha_0\) is the highest short root.
\end{enumerate}

Such \(\lambda\) are referred to as \emph{minuscule weights}.

\begin{example}

\begin{example}

For type \(A_n\), we have \(\alpha_0 = \sum_{i=1}^n \alpha_i\). For type
\(G_2\), we have \(\alpha_0^\vee= 2\alpha_1^\vee+ 3\alpha_2^\vee\).

\end{example}

\end{example}

\begin{example}

\begin{example}

In type \(A_n\), set \(\lambda = \sum_{j=1}^n c_j w_j\) where
\(c_j \geq 0\). Then
\({\left\langle {\lambda},~{\alpha_0^\vee} \right\rangle} = \sum c_j \leq 1\),
so \(\lambda\) is minuscule iff \(\lambda = 0\) or \(\lambda = w_j\) for
some \(j\).

\end{example}

\end{example}

\begin{remark}

\begin{remark}

Quick timeline:

\begin{itemize}
\tightlist
\item
  2015, Cantrell lectures by Dick Gross at UGA
\item
  Fall 2015: email to Dan Nakano from Skip Garibaldi, conjecture from
  Gross without a proof
\end{itemize}

\begin{proposition}[Gross]

\begin{proposition}[Gross]

The simple module is equal to the induced module, so
\(L(\lambda) = H^0(\lambda)\), for all \(p\) iff \(\lambda\) is
minuscule, or if \(L(\lambda) = {\mathfrak{g}}\) for \(\Phi = E_8\).

\end{proposition}

\end{proposition}

\begin{itemize}
\tightlist
\item
  Proved by Garibaldi-Nakano-Guralnick, appeared in Journal of Algebra
\end{itemize}

\end{remark}

\end{remark}

\hypertarget{bott-borel-weil-theorem}{%
\subsection{Bott-Borel-Weil Theorem}\label{bott-borel-weil-theorem}}

We can consider the higher right-derived functors of \(\lambda\), given
by \(H^i(\lambda) = R^i \operatorname{Ind}_B^G \lambda\) for
\(\lambda \in X(T)\). You can think of this as the higher sheaf
cohomology of the flag variety,
\(\mathcal{H}^i(G/B, \mathcal{L}(\lambda))\).

We have \textbf{Kempf Vanishing}: \(H^i(\lambda) = 0\) for all \(i>0\)
when \(\lambda \in X(T)_+\) is dominant (although other things may
happen for non-dominant weights). There is a correspondence
\((G, T) \iff (W, \Phi)\), and since \(W\) is generated by simple
reflections, we can write any \(w\in W\) as \(w=\prod s_{\alpha_i}\). A
\emph{reduced expression} is one in which the length can not be
shortened, and any two reduced expressions necessarily have the same
length (number of simple reflections).

\begin{example}

\begin{example}

For \(\Phi = A_2\), we have
\(w_0 = s_{\alpha_1} s_{\alpha_2} s_{\alpha_1} = s_{\alpha_2} s_{\alpha_1} s_{\alpha_2}\).

\end{example}

\end{example}

\hypertarget{dot-action-on-weights}{%
\subsubsection{Dot Action on Weights}\label{dot-action-on-weights}}

We can let \(W\) act on \(X(T)\) by reflections by the formula
\(s_\alpha \lambda = \lambda - {\left\langle {\lambda},~{\alpha^\vee} \right\rangle}\alpha\).
We then shift the action by setting
\(s_\alpha \cdot \lambda = w(\lambda+\rho)-\rho\) where
\(\rho = {1\over 2} \sum_{\alpha\in \Phi^+} \alpha = \sum_{j=1}^n w_j\).

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-33-00.png}
\caption{Image}
\end{figure}

\begin{theorem}[Bott-Borel-Weil]

\begin{theorem}[Bott-Borel-Weil]

Let \(G\) be a reductive algebraic group and \(k={\mathbb{C}}\). For
\(\lambda \in X(T)_+\), we can describe the sheaf cohomology:
\begin{align*}   \mathcal{H}^i(w\cdot \lambda) = \begin{cases} H^0(\lambda) & i=\ell(w) \\ 0 & \text{otherwise} \end{cases} .\end{align*}

Moreover, if \(\lambda \not\in X(T)_+\) and
\({\left\langle {\lambda+\rho},~{\alpha^\vee} \right\rangle} \geq 0\)
for all \(\alpha \in \Delta\), then
\(\mathcal{H}^i(w\cdot \lambda) = 0\) for all \(w\in W\).

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-41-58.png}
\caption{Image}
\end{figure}

\end{theorem}

\end{theorem}

Wide open in characteristic \(p\), can say some things. We'll prove this
in characteristic zero.

Recall that \(k={\mathbb{C}}\) and \(H^0(\lambda) = L(\lambda)\). We'll
want to reduce to \({\text{SL}}(2, {\mathbb{C}})\) parabolics. For
\(\alpha\in\Delta\), let \(P_\alpha\) be the associated parabolic
\(P_\alpha = L_\alpha \rtimes U_\alpha\), which is parabolic of type
\(A_1\).

Idea: \(\alpha\) generates an \({\text{SL}}_2\) subgroup (the Levi
factor), like the Borel but sticks out in one dimension:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-07-14-47-17.png}
\caption{Image}
\end{figure}

Then
\begin{align*}  s_\alpha \cdot \lambda = s_\alpha(\lambda + \rho) - \rho \\ = \lambda + \rho - {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle}\alpha - \rho \\ = \lambda - {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle}\alpha .\end{align*}

Next time: proof of Bott-Borel-Weil and its generalization to
\(k = \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}\mkern-1.5mu}\mkern 1.5mu_p\).
For \(B\subset P_\alpha \subset G\), we'll have a spectral sequence
\begin{align*}   E_2^{i, j} = R^i \operatorname{Ind}_{P_\alpha}^G R^j \operatorname{Ind}_B^{P_\alpha}  \Rightarrow R^{i+j} \operatorname{Ind}_B^G  \lambda = H^{i+j}(\lambda) .\end{align*}

\hypertarget{friday-october-09}{%
\section{Friday, October 09}\label{friday-october-09}}

Last time: Bott-Borel-Weil. Stated for characteristic zero, working
toward a generalization.

Let \(\Delta\) be the set of simple roots, and \(\alpha\in \Delta\). We
can form a Levi decomposition
\(P_\alpha \mathrel{\vcenter{:}}= L_\alpha \rtimes U_\alpha\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-09-13-58-02.png}
\caption{Image}
\end{figure}

We have \(B \subseteq P_\alpha \subseteq G\). The dot action is given by
the following: Let \(W\) be the Weyl group, then \(W\) acts on \(X(T)\)
by \(w\cdot \lambda = w(\lambda + \rho) - \rho\), where
\begin{align*}   \rho = {1\over 2} \sum_{\alpha\in \Phi^+} \alpha = \sum_{i=1}^n w_n .\end{align*}

We obtained a formula
\begin{align*}   S_\alpha \cdot \lambda = \lambda - {\left\langle {\lambda  + \rho},~{\alpha^\vee} \right\rangle} \alpha .\end{align*}

\hypertarget{bott-borel-weil-theory}{%
\subsection{Bott-Borel-Weil Theory}\label{bott-borel-weil-theory}}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\alpha\in\Delta\) be simple and \(\lambda \in X(T)\) be an
arbitrary weight. Then

\begin{itemize}
\item
  \(U_\alpha\) acts trivially on
  \(\operatorname{Ind}_B^{P_\alpha} \lambda\).
\item
  (Kempf's Vanishing for \(P_\alpha\)) If
  \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = r \geq 0\),
  then
  \begin{align*}       R^i \operatorname{Ind}_B^{P_\alpha} \lambda = 0 \qquad \text{for } i \geq 0     ,\end{align*}
  and \(\dim \operatorname{Ind}_B^{P_\alpha}\lambda = r + 1\).
\item
  If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = -1\),
  then \(R^i \operatorname{Ind}_B^{P_\alpha} \lambda = 0\) for all
  \(i\).
\item
  If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \leq -2\),
  then

  \begin{itemize}
  \item
    \(R^i \operatorname{Ind}_B^{P_\alpha} \lambda = 0\) for
    \(i \neq 1\), and
  \item
    \(\dim R^1 \operatorname{Ind}_B^{P_\alpha} \lambda = r+1\)
  \end{itemize}
\end{itemize}

Note: we have
\begin{align*}   \operatorname{Ind}_B^{P_\alpha} \lambda = S^r(V) \qquad &\text{when } {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = r \geq 0 \\ R^1 \operatorname{Ind}_B^{P_\alpha} = S^r(V)^\vee\qquad&\text{where $V$ is a 2-dim representation and } {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \leq -2 \\ &\text{and } r = {\left\lvert {{\left\langle {\lambda},~{\alpha^\vee} \right\rangle}} \right\rvert} - 1 .\end{align*}

\end{proposition}

\end{proposition}

This gives us an analog of \(A_1\) or \({\text{SL}}_2\) theory. Also
note that we have Serre duality:
\begin{align*}   H^1(\lambda) = H^0( - (\lambda + 2\rho) )^\vee .\end{align*}

\begin{corollary}[?]

\begin{corollary}[?]

Let \(\alpha\in \Delta\) and \(\lambda\in X(T)\), and suppose
\(\lambda\) is dominant with respect to \(\alpha\),
i.e.~\({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \geq 0\).

\begin{itemize}
\item
  If \(\operatorname{char}~(k) = 0\) then
  \(\operatorname{Ind}_B^{P_\alpha}\lambda = R^1 \operatorname{Ind}_B^{P_\alpha} s_\alpha \cdot \lambda\)
\item
  If \(\operatorname{char}~(k) = p\) and if there exists an \(s, m\)
  with \(0<s<p\) and
  \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = sp^m - 1\)
  (Steinberg weights), then
  \begin{align*}       \operatorname{Ind}_B^{P_\alpha} \lambda = R^1 \operatorname{Ind}_B^{P_\alpha} s_\alpha \cdot \lambda     .\end{align*}
\end{itemize}

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-09-14-14-39.png}
\caption{O}
\end{figure}

\end{corollary}

\end{corollary}

The proof of this will use a Grothendieck-type spectral sequence of the
form
\begin{align*}   E_2^{i, j} = R^i \operatorname{Ind}_{P_\alpha}^G \qty{ R^j \operatorname{Ind}_B^{P_\alpha} \lambda} \Rightarrow R^{i+j} \operatorname{Ind}_B^G \lambda .\end{align*}

We'll have a version of \emph{Grothendieck vanishing}:
\begin{align*}   R^j \operatorname{Ind}_B^{P_\alpha} \lambda = 0 \qquad\text{for } j > \dim P_\alpha/B = 1 .\end{align*}

So the resulting spectral sequence will only be supported on the first
two lines, and \(E_3 = E_\infty\). Note the differential will be of
bidegree \({\partial}_r \leadsto (r, 1-r)\), and \(E_2\) will look like
the following,

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-09-14-30-47.png}
\caption{Image}
\end{figure}

Recall that
\(R^i \operatorname{Ind}_B^G \lambda \mathrel{\vcenter{:}}= H^i(\lambda)\)

\begin{proposition}[?]

\begin{proposition}[?]

Let \(\alpha\in\Delta\) and \(\lambda \in X(T)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = -1\),
  then \(H^{\,\cdot\,}(\lambda) = 0\).
\item
  If \({\left\langle {\lambda},~{ \alpha^\vee} \right\rangle} \geq 0\),
  then \(H^i(\lambda) = R^i \operatorname{Ind}_B^{P_\alpha} \lambda\)
  for all \(i\geq 0\).
\item
  If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \leq -2\),
  then
  \begin{align*}       H^i(\lambda) = R^{i-1} \operatorname{Ind}_{P_\alpha}^G \qty{ R^1 \operatorname{Ind}_B^{P_\alpha} \lambda } \qquad \forall i     .\end{align*}
\item
  Suppose
  \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \geq 0\). If
  \(\operatorname{char}~(k) = 0\), or \(\operatorname{char}~(k) = p> 0\)
  and
  \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = sp^n - 1\),
  then
  \begin{align*}         H^i(\lambda) = H^{i+1}(s_\alpha\cdot \lambda)       .\end{align*}
\end{enumerate}

\end{proposition}

\end{proposition}

\begin{proof}[of a]

\begin{proof}[of a]

If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = -1\), then
\(R^{\,\cdot\,}\operatorname{Ind}_B^{P_\alpha} \lambda = 0\). But this
is what appears as the ``coefficients'' in the spectral sequence, so
\(E_2^{{\,\cdot\,}, {\,\cdot\,}} = 0\) and this
\(R^{\,\cdot\,}\operatorname{Ind}_B^{P_\alpha} = 0\).

\end{proof}

\end{proof}

\begin{proof}[of b]

\begin{proof}[of b]

If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = 0\), then
\(R^j \operatorname{Ind}_B^{P_\alpha} \lambda = 0\) for all \(j>0\).
Thus only the bottom line survives, and the spectral sequence
degenerates on page 2. Thus
\(E_2^{1, 0} = R^i \operatorname{Ind}_B^G \lambda\), where the LHS is
equal to
\(R^i \operatorname{Ind}_{P_\alpha}^G \qty{\operatorname{Ind}_B^{P_\alpha} \lambda }\).

\end{proof}

\end{proof}

\begin{proof}[of c]

\begin{proof}[of c]

If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} = -2\), then
\(R^i \operatorname{Ind}_B^{P_\alpha} \lambda = 0\) for \(i\neq 1\), so
only \(i=1\) survives Then
\begin{align*} R^{i-1} \operatorname{Ind}_{P_\alpha}^G \qty{ \operatorname{Ind}_B^{PP_\alpha} \alpha} = R^i \operatorname{Ind}_B^G \lambda ,\end{align*}
so there is some dimension shifting.

\end{proof}

\end{proof}

\begin{proof}[of d]

\begin{proof}[of d]

If \({\left\langle {\lambda},~{\alpha^\vee} \right\rangle} \geq 0\),
then by (b),
\begin{align*}   H^i(\lambda)  &= R^i \operatorname{Ind}_{P_\alpha}^G \qty{ \operatorname{Ind}_B^{P_\alpha} \lambda } && \text{by c}\\ &= R^i \operatorname{Ind}_{P_\alpha}^G \qty{ R^1 \operatorname{Ind}_B^{P_\alpha} s_\alpha\cdot \lambda } && \text{by corollary}\\ &= H^{i+1}(s_\alpha\cdot \lambda) .\end{align*}

We can then check that
\begin{align*}   s_\alpha \cdot \lambda &= \lambda - {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle}\alpha \\ &= \lambda - \qty{ {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} + 1 }\alpha && \text{using } {\left\langle {\rho},~{\alpha^\vee} \right\rangle} = 1 \\ \\ \implies  {\left\langle {s_\alpha \cdot \lambda},~{\alpha^\vee} \right\rangle} &= {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} - \qty{ {\left\langle {\lambda},~{\alpha^\vee} \right\rangle}+1 }{\left\langle {\alpha},~{\alpha^\vee} \right\rangle} \\ &= {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} - \qty{ {\left\langle {\lambda},~{\alpha^\vee} \right\rangle}+1 }2 \\ &= -{\left\langle {\lambda},~{\alpha^\vee} \right\rangle} - 2 \\ &\leq -2 .\end{align*}

\end{proof}

\end{proof}

Now define
\begin{align*}   \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{{\mathbb{Z}}}  &\mathrel{\vcenter{:}}= \left\{{ \lambda \in X(T) ~{\text{s.t.}}~0 \leq {\left\langle {\lambda+\rho},~{\beta^\vee} \right\rangle} \,\forall \beta \in \Phi^+ }\right\} \qquad\text{ if } \operatorname{char}~(k) = 0 \\ &\mathrel{\vcenter{:}}= \left\{{ \lambda \in X(T) ~{\text{s.t.}}~0 \leq {\left\langle {\lambda+\rho},~{\beta^\vee} \right\rangle} \leq \operatorname{char}~(k) \,\forall \beta \in \Phi^+ }\right\} \qquad\text{if } \operatorname{char}~(k) = p .\end{align*}

Idea:

\includegraphics{figures/image_2020-10-09-14-45-08.png}
\includegraphics{figures/image_2020-10-09-14-45-20.png}

\begin{theorem}[Bott-Borel-Weil Generalization, due to Andersen]

\begin{theorem}[Bott-Borel-Weil Generalization, due to Andersen]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  If
  \(\lambda \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\)
  and \(\lambda \not\in X(T)_+\), then \(H^0(w\cdot \lambda) = 0\).
\item
  If
  \(\lambda \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\cap X(T)_+\),
  then for all \(w\in W\),
  \begin{align*}       H^i(w\cdot \lambda) =      \begin{cases}     H^0(\lambda) & i= \ell(w) \\     0 & \text{otherwise}     \end{cases}     .\end{align*}
\end{enumerate}

\end{theorem}

\end{theorem}

Note that this covers everything in the \(\operatorname{char}~(k) = 0\)
case, but only gives the following hexagon in the
\(\operatorname{char}~(k) = p\) case:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-09-14-48-41.png}
\caption{Image}
\end{figure}

\begin{remark}

\begin{remark}

\textbf{Open Problem}: Determine \(\operatorname{char}~H^i(\lambda)\)
for \(\lambda\in X(T)\) in characteristic \(p>0\).

Andersen provided necessary an sufficient conditions for
\(H^1(\lambda) \neq 0\) and computed
\(\operatorname{Soc}\,_G H^1(\lambda)\).

\end{remark}

\end{remark}

\hypertarget{monday-october-12}{%
\section{Monday, October 12}\label{monday-october-12}}

\hypertarget{proof-of-bott-borel-weil}{%
\subsection{Proof of Bott-Borel-Weil}\label{proof-of-bott-borel-weil}}

Recall the Bott-Borel-Weil theorem: in characteristic zero, we're
looking at the closure of the region containing the fundamental region
\(C_{\mathbb{Z}}\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-12-13-58-45.png}
\caption{Image}
\end{figure}

\begin{theorem}[due to Aandersen]

\begin{theorem}[due to Aandersen]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  If
  \(\lambda \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\)
  and \(\lambda \not\in X(T)_+\) then \(H^0(w\circ \lambda) = 0\).
\item
  If
  \(\lambda\in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\cap X(T)_+\)
  then for all \(w\in W\), we have
  \begin{align*}       H^i(w\cdot \lambda) =      \begin{cases}     H^0(\lambda)& i = \ell(w) \\     0 & \text{otherwise}     \end{cases}     .\end{align*}
\end{enumerate}

\end{theorem}

\end{theorem}

\begin{proof}[of a]

\begin{proof}[of a]

For (a): we use induction on \(\ell(w)\). For \(\ell(w) = 0\), we have
\(w = \text{id}\). Let
\(\lambda \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\)
and \(\lambda\not\in X(T)_+\). Then
\begin{align*}   0  &\leq {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} \\ &= {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} + 1 \\ \implies {\left\langle {\lambda},~{\alpha^\vee} \right\rangle} &= -1 .\end{align*}
Applying the previous proposition, we get \(H^0(\lambda) = 0\).

\end{proof}

\end{proof}

\begin{proof}[of b]

\begin{proof}[of b]

For the base case \(w=\text{id}\), this follows from Kempf vanishing.
Assuming the result holds for any word of length \(l<\ell(w)\), if
\(\ell(w) > 0\), there exists some simple reflection \(s_\alpha\) for
\(\alpha\in\Delta\) such that \(\ell(s_\alpha w) = \ell(w) - 1\).
Moreover, \(w^{-1}(\alpha) \in -\Phi^+\), so set
\(\beta = -w^{-1}(\alpha) \in \Phi^+\). We can the make the following
computation:
\begin{align*}   {\left\langle {(s_\alpha w) \cdot \lambda},~{\alpha^\vee} \right\rangle} &= {\left\langle {(s_\alpha w)(\lambda+\rho) - \rho},~{\alpha^\vee} \right\rangle}  \\ &= {\left\langle {(s_\alpha w)(\lambda+\rho)},~{\alpha^\vee} \right\rangle} - 1 \\ &= {\left\langle {w(\lambda+\rho)},~{s_\alpha \alpha^\vee} \right\rangle} - 1 \\ &= - {\left\langle {w(\lambda+\rho)},~{\alpha^\vee} \right\rangle} - 1  \\ &= {\left\langle {\lambda + \rho},~{-w^{-1}\alpha^\vee} \right\rangle} - 1 \\ &= {\left\langle {\lambda + \rho},~{\beta^\vee} \right\rangle} - 1 \\ &\geq -1 \end{align*}
and
\({\left\langle {(s_\alpha w)\cdot \lambda},~{ \alpha^\vee} \right\rangle} < \rho\)
since
\(\lambda\in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\).
Note that we've used the fact that the inner product is
\(W{\hbox{-}}\)invariant.\\

Now if
\({\left\langle {(s_\alpha w)\cdot \lambda},~{ \alpha^\vee} \right\rangle} \geq 0\),
we can apply the prior proposition part (d). Here we use the fact that
\(\operatorname{Ind}_B^{P_\alpha}(s_\alpha w)\lambda\) is simple.
Applying the inductive hypothesis yields
\begin{align*}   H^i(s_\alpha - \lambda) = H^{i+1}(w\cdot \lambda) .\end{align*}

Now if
\({\left\langle {s_\alpha w \cdot \lambda},~{\alpha^\vee} \right\rangle} = -1\),
then
\begin{align*}   -1 &= {\left\langle {\lambda + \rho},~{\beta^\vee} \right\rangle} - 1 \\ \implies {\left\langle {\lambda + \rho},~{\beta^\vee} \right\rangle} &= 0 \\ \implies {\left\langle {\lambda},~{\beta^\vee} \right\rangle} &= 0 \\ & \cdots .\end{align*}

\todo[inline]{Missing computation}

Then applying (a) yields \(H^1(w\cdot \lambda) = 0\).

\end{proof}

\end{proof}

\hypertarget{serre-duality-and-grothendieck-vanishing}{%
\subsection{Serre Duality and Grothendieck
Vanishing}\label{serre-duality-and-grothendieck-vanishing}}

Let \(P\) be a parabolic subgroup,
i.e.~\(P_J = P \mathrel{\vcenter{:}}= L_J \rtimes U_J\) for some
\(J\subseteq \Delta\). Set
\(n(P) = {\left\lvert {\Phi^+} \right\rvert} - {\left\lvert {\Phi^+_J} \right\rvert}\).

\begin{example}

\begin{example}

Let \(\Phi = A_4\), which has ten simple roots:

\begin{itemize}
\tightlist
\item
  \(\alpha_i, 1\leq i \leq 4\)
\item
  \(\alpha_i + \alpha_{i+1}\), \(i=1,2,3\).
\item
  \(\alpha_1 + \alpha_2 +\alpha_3\), \(\alpha_2 + \alpha_3 + \alpha_4\)
\item
  \(\sum_{i=1}^4 \alpha_i\).
\end{itemize}

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-12-14-21-20.png}
\caption{Image}
\end{figure}

Then \(n(P) = 10 - 3 = 7\).

\end{example}

\end{example}

\begin{theorem}[Grothendieck Vanishing]

\begin{theorem}[Grothendieck Vanishing]

\begin{align*}   R^i \operatorname{Ind}_P^G M = 0 \qquad \text{for } i > n(P) .\end{align*}

\end{theorem}

\end{theorem}

\begin{theorem}[Serre Duality]

\begin{theorem}[Serre Duality]

\begin{align*}   \qty{ R^i \operatorname{Ind}_B^G M }^\vee\cong R^{n(P) -i} \operatorname{Ind}_P^G M^\vee\otimes(-2\rho_P) .\end{align*}
where
\begin{align*} \rho_p \mathrel{\vcenter{:}}={1\over 2}\sum_{\beta \in \Phi^+ \setminus\Phi_J} \beta \end{align*}

\end{theorem}

\end{theorem}

\begin{example}

\begin{example}

Take \(B = P\) and \(M = \lambda\). Then \(\lambda ^\vee= -\lambda\), so
\begin{align*}   \qty{ R^i \operatorname{Ind}_B^G \lambda }^\vee\cong R^{{\left\lvert {\Phi^+} \right\rvert} -i} \operatorname{Ind}_P^G (- \lambda) ^\vee\otimes(-2\rho) .\end{align*}
From this we can conclude
\begin{align*}   H^i(\lambda) = H^{n-i} (-\lambda - 2\rho)^\vee ,\end{align*}
where \(n = {\left\lvert {\Phi^+} \right\rvert}\).

\end{example}

\end{example}

\begin{corollary}[?]

\begin{corollary}[?]

Let
\(\lambda \in X(T)_+ \cap\mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\)
be a dominant weight. Then

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  The irreducible representations are given by
  \(L(\lambda) = H^0(\lambda)\).
\item
  \(\operatorname{Ext}_G^1(L(\lambda), L(\mu)) = 0\) for all
  \(\lambda, \mu\) in
  \(\mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\).
\item
  If \(\operatorname{char}~(k) = 0\), so
  \(X(T)_+ \subset \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\),
  then all \(G{\hbox{-}}\)modules are completely reducible.
\end{enumerate}

\end{corollary}

\end{corollary}

\begin{proof}[of a]

\begin{proof}[of a]

Note that the longest element takes positive roots to negative roots, so
\(w_0 \rho = - \rho\), and moreover
\(-w_0(\mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}) = \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\).
We also have
\begin{align*} w_0 \cdot ( w_0 \lambda)  &= w_0 (-w_0 \lambda + \rho) - \rho \\ &= -\lambda + w_0 \rho - \rho \\ &= -\lambda - 2\rho .\end{align*}
By Serre duality, if we take the Weyl module we obtain
\begin{align*} V(-w_0 \lambda)  &\mathrel{\vcenter{:}}= H^0(\lambda)^\vee\\ &= H^n(-\lambda - 2\rho) \\ &= H^n(w_0 \cdot (-w_0 \lambda)) \\ &= H^n(-w_0 \lambda) \qquad\text{by Bott-Borel-Weil} ,\end{align*}
where we've used that
\(\ell(w_0) = {\left\lvert {\Phi^+} \right\rvert}\). We know that
\(L(-w_0 \lambda) \subseteq \operatorname{Soc}\,H^0(-w_0 \lambda) = V(-w_0 \lambda) \twoheadrightarrow L(-w_0 \lambda)\),
where the last term is contained in the head. But this means that this
splits, so by indecomposability we must have
\(L(-w_0 \lambda) = H^0(-w_0 \lambda) = V(-w_0 \lambda)\). So we can
conclude
\begin{align*}   L(\mu) = H^0(\mu) = V(\mu) \qquad \forall \mu \in X(T)_+ \cap\mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}} .\end{align*}

\end{proof}

\end{proof}

\begin{proof}[of b and c]

\begin{proof}[of b and c]

Suppose \(\operatorname{Ext}_G^1(L(\lambda), L(\mu)) \neq 0\), then
\(L(\lambda)\) is in \(H^0(\mu) / \operatorname{Soc}\,_G H^0(\mu) = 0\)
and \(L(\mu)\) is in
\(H^0(\lambda) / \operatorname{Soc}\,_G H^0(\lambda) = 0\), but this
forces \(\operatorname{Ext}_G^1(L(\lambda), L(\mu)) = 0\).\\

Part (c) follows from part (b).

\end{proof}

\end{proof}

\hypertarget{weyls-character-formula}{%
\subsection{Weyl's Character Formula}\label{weyls-character-formula}}

Problem: Determine \(\operatorname{char}~H^0 \lambda\) for
\(\lambda \in X(T)_+\).

Solution: Let
\(A(\lambda) = \sum_{w\in W} \operatorname{sgn}(w) e^{w\lambda} \in {\mathbb{Z}}[X(T)]\),
where we sum over the usual Weyl group and not the affine Weyl groups,
taken as a formal sum in the group algebra on the weight lattice. We can
then state Weyl's character formula:
\begin{align*}   \operatorname{char}~H^0(\lambda) = {A(\lambda + \rho) \over A(\rho)} \qquad \text{for }\lambda \in X(T)_+ .\end{align*}
This is a formal sum, so it's surprising that the bottom term even
divides the top. But there is a great deal of cancellation, we'll see
this in examples such as \(\operatorname{GL}_3\).

\hypertarget{formal-characters}{%
\subsubsection{Formal Characters}\label{formal-characters}}

Let \(M\) be a \(T{\hbox{-}}\)module, then define the \emph{character}
\begin{align*}   \operatorname{char}~M\mathrel{\vcenter{:}}=\sum_{\mu\in X(T)} \qty{\dim M_\mu} e^\mu \quad \in {\mathbb{Z}}[X(T)] .\end{align*}

We then define the \emph{Euler characteristic}
\begin{align*}   \chi(M) \mathrel{\vcenter{:}}=\sum_{i\geq 0} (-1)^i \operatorname{char}~H^i(M) .\end{align*}
Note that by Grothendieck vanishing, \(H^i(M) = 0\) for
\(i > {\left\lvert {\Phi^+} \right\rvert} = \dim(G/B)\), so this is a
finite sum. In fact, if \(M\) is a \(G{\hbox{-}}\)module, then this is
\(W{\hbox{-}}\)invariant and thus in fact
\(\chi(M) \in {\mathbb{Z}}[X(T)]^W\).

\hypertarget{wednesday-october-14}{%
\section{Wednesday, October 14}\label{wednesday-october-14}}

Today:

\begin{itemize}
\item
  Weyl's character formula
\item
  Strong linkage
\item
  Translation functors
\end{itemize}

Recall that we defined
\begin{align*}   \operatorname{char}~(M) &\mathrel{\vcenter{:}}=\sum_{\mu \in X(T)} \qty{\dim M_\mu} e^{\mu} \in {\mathbb{Z}}[X(T)]\\ \chi(M) &\mathrel{\vcenter{:}}=\sum_{i\geq 0} (-1)^i \operatorname{char}~H^i(M) \in {\mathbb{Z}}[X(T)]^W .\end{align*}

where \(H^i(M) = R^i \operatorname{Ind}_B^G M\), and \(H^i(M) =0\) for
\(i> G/B = {\left\lvert {\Phi^+} \right\rvert}\).

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-14-14-03-12.png}
\caption{Image}
\end{figure}

Note that the Euler characteristic is additive on SESs: if
\(0\to A\to B\to C\to 0\) then \(\chi(B) = \chi(A) + \chi(B)\). It is
also multiplicative wrt the tensor product:
\(\chi(A\otimes B) \chi(A) \chi(B)\).

\todo[inline]{Because ?}

\begin{remark}

\begin{remark}

If \(\lambda \in X(T)_+\), then
\(\chi(\lambda) = \operatorname{char}~H^0(\lambda) = \operatorname{char}~(V(0))\).

\end{remark}

\end{remark}

\begin{proposition}[?]

\begin{proposition}[?]

\hfill

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The set
  \(\left\{{\operatorname{char}~L(\lambda) ~{\text{s.t.}}~\lambda\in X(T)_+}\right\}\)
  is a basis for \({\mathbb{Z}}[X(T)]^W\).
\item
  If \(\lambda \in X(T)\) and
  \(\sum a_\mu e^\mu \in {\mathbb{Z}}[X(T)]^W\), then there is a
  formula:
  \begin{align*}       \chi(\lambda) \qty{ \sum_\mu a_\mu e^\mu } = \sum_\mu a_\mu \chi(\lambda + \mu)     .\end{align*}
\end{enumerate}

\end{proposition}

\end{proposition}

\begin{proof}[of 1]

\begin{proof}[of 1]

Let
\begin{align*} \operatorname{Sym}(\mu) \mathrel{\vcenter{:}}=\sum_{\nu \in W\mu} e^\nu \end{align*}
be the sum over the \(W\) orbit of \(\mu\). This is clearly
\(W{\hbox{-}}\)invariant, so
\(\operatorname{Sym}(\mu) \in {\mathbb{Z}}[X(T)]^W\). Since every
\(\nu \in X(T)\) is \(W{\hbox{-}}\)conjugate to \(\mu\) (which is
dominant), the set
\(\left\{{\operatorname{Sym}(\mu) ~{\text{s.t.}}~\mu \in X(T)_+}\right\}\)
is a basis for \({\mathbb{Z}}[X(T)]^W\), since this set is linearly
independent.

\begin{quote}
Why: conjugate to a unique weight.
\end{quote}

Let \(\lambda \in X(T)_+\), then

\begin{align*} \operatorname{char}~L(\lambda) = \operatorname{Sym}(\lambda) + \sum_{\substack{\mu < \lambda \\ \mu \in X(T)_+} } a_\mu \operatorname{Sym}(\mu) .\end{align*}
Thus the transition matrix is unipotent and upper-triangular, thus
\(\left\{{\operatorname{char}~L(\lambda) ~{\text{s.t.}}~\lambda \in X(T)_+}\right\}\)
is a basis for \({\mathbb{Z}}[X(T)]^W\).

\end{proof}

\end{proof}

\begin{proof}[of 2]

\begin{proof}[of 2]

Since \(\left\{{L(\lambda) ~{\text{s.t.}}~\lambda\in X(T)_+}\right\}\)
forms a basis for \({\mathbb{Z}}[X(T)]^W\), there is some
\(G{\hbox{-}}\)module \(V\) such that
\(\sum a_\mu e^\mu = \pm \operatorname{char}~V\). We can consider a
composition series of \(V\otimes\lambda\), where the factor
\(\left\{{\mu \otimes\lambda}\right\}\) appears \(a_\mu = \dim V_\mu\)
times. We now compute in two different ways:
\begin{align*}   \chi(V\otimes\lambda)  &= \operatorname{char}~(V) \chi(\lambda)  && \text{using the formula from earlier} \\ &= \chi(\lambda) \qty{ \sum_\mu a_\mu e^\mu } .\end{align*}

On the other hand,
\begin{align*}   \chi(V\otimes\lambda) &= \sum a_\mu \chi(\lambda + \mu) .\end{align*}

\end{proof}

\end{proof}

\begin{remark}

\begin{remark}

The formula used above was
\begin{align*}   R^i \operatorname{Ind}_B^G (V\otimes\lambda) = V\otimes R^i \operatorname{Ind}_B^G(\lambda) .\end{align*}

\end{remark}

\end{remark}

\hypertarget{weyls-character-formula-1}{%
\subsection{Weyl's Character Formula}\label{weyls-character-formula-1}}

For any \(\alpha\in\Delta\) and \(\lambda \in X(T)\) with
\({\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} \geq 0\).
We have an analog of Serre duality:
\begin{align*}   \operatorname{char}~\operatorname{Ind}_B^{P_\alpha} \lambda = \operatorname{char}~R^i \operatorname{Ind}_B^{P_\alpha} s_\alpha \cdot \lambda ,\end{align*}
i.e.~the induced module coincides with the Weyl module.

By definition of the dot action, we have
\begin{align*}   s_\alpha \cdot \lambda = s_\alpha(\lambda + \rho) - \rho .\end{align*}

As in previous calculations, we have

\begin{align*}   {\left\langle {s_\alpha\cdot\lambda},~{\alpha^\vee} \right\rangle} = -{\left\langle {\lambda+\rho},~{\alpha^\vee} \right\rangle} - 1 \leq - 1 .\end{align*}

As in the analysis of Bott-Borel-Weil, we have
\begin{align*}   H^i(s_\alpha \cdot\lambda) &= H^i( R^1 \operatorname{Ind}_B^{P_\alpha} s_\alpha\cdot\lambda ) \\ H^i(\lambda) &= H^i( \operatorname{Ind}_B^{P_\alpha}\lambda ) ,\end{align*}
since the spectral sequence collapses. Note that the two things
appearing on the RHS have the same Euler characteristics.

We can thus define define a modified Euler characteristic
\begin{align*}   \phi(N) = \sum_{i\geq 0} (-1)^i \operatorname{char}~R^i \operatorname{Ind}_{P_\alpha}^G(N) .\end{align*}

and obtain \(\chi(\lambda) = -\chi(s_\alpha \cdot \lambda)\). The same
argument works for
\({\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} < 0\).

\begin{remark}[Very Important Fact]

\begin{remark}[Very Important Fact]

\begin{align*}   \lambda \in X(T) \implies \chi(\lambda) = -\chi(s_\alpha \cdot \lambda) .\end{align*}

\end{remark}

\end{remark}

\begin{proposition}[General Formula]

\begin{proposition}[General Formula]

\begin{align*}   \chi(w\cdot \lambda) = \operatorname{sgn}(w) \chi(\lambda) && \operatorname{sgn}(w) \mathrel{\vcenter{:}}=(-1)^{\ell(w)} ,\end{align*}
with the convention that \(\chi(0) = e^0 = 1\).

\end{proposition}

\end{proposition}

\begin{lemma}[?]

\begin{lemma}[?]

Let \(\lambda \in X(T)\) where
\(\sum a_\mu e^|mu \in {\mathbb{Z}}[X(T)]^W\), so (as we proved)
\begin{align*}   \chi(\lambda) \qty{ \sum_\mu a_\mu e^\mu } = \sum_\mu a_\mu \chi(\lambda + \mu) .\end{align*}
In the special case \(\lambda = 0\), we have
\(\chi(\lambda) = \chi(0) = e^0\), we obtain
\begin{align*}   \sum_\mu a_\mu e^\mu = \sum_\mu a_\mu \chi(\mu) .\end{align*}

Extend this to a field by letting
\(\lambda \in X(T) \otimes_{\mathbb{Z}}{\mathbb{Q}}\), then define
\begin{align*}   A(\lambda) \mathrel{\vcenter{:}}=\sum_{w\in W} \operatorname{sgn}(w) e^{w \lambda} \in {\mathbb{Z}}[ (X(T) \otimes{\mathbb{Q}}] .\end{align*}

Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(w' A(\lambda) = \operatorname{sgn}(w') A(\lambda)\).
\item
  \(A(\mu) A(\lambda) \in {\mathbb{Z}}[X(T) \otimes{\mathbb{Q}}]^W\).
\end{enumerate}

\end{lemma}

\end{lemma}

Proof of 1: exercise.

\begin{proof}[of 2]

\begin{proof}[of 2]

We can compute
\begin{align*}   w(A(\mu) A(\lambda) )  &= w A(\mu)  w A(\lambda) \\ &= \operatorname{sgn}(w) A(\mu)  \operatorname{sgn}(w) A(\lambda) \\ &= \operatorname{sgn}(w)^2 A(\mu) A(\lambda) \\ &= A(\mu) A(\lambda) .\end{align*}

\end{proof}

\end{proof}

\begin{theorem}[Weyl's Character Formula]

\begin{theorem}[Weyl's Character Formula]

Let \(\lambda \in X(T)\) be any weight, then
\begin{align*}   \chi(\lambda) = { A(\lambda + \rho) \over A(\rho) } ,\end{align*}
where \(\rho = {1\over 2} \sum_{\alpha \in \Phi^+} \alpha\).

\end{theorem}

\end{theorem}

\begin{quote}
Note: this says that one formal sum divides another.
\end{quote}

A corollary is an analog of Weyl's dimension formula: :::\{.corollary
title=``?''\} Let \(\lambda \in X(T)_+\) be a dominant weight. Then
\begin{align*}   \operatorname{char}~H^0(\lambda) = { A(\lambda + \rho) \over A(\rho) } .\end{align*}
:::

Big question: suppose
\(k = \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}\mkern-1.5mu}\mkern 1.5mu_p\).
What are \(\operatorname{char}~L(\lambda)\) and \(\lambda \in X(T)_+\)?
We know this for \(p\gg 0\), but in general it's wide open. There are
expressions in terms of ``\(p{\hbox{-}}\)bases'', but these are hard to
compute. There are only recursive formulas, none that are closed (and
these may not exist).

Next time:

\begin{itemize}
\tightlist
\item
  Proof of Weyl's character formula
\item
  Compute an example.
\end{itemize}

Idea of the proof: we'll have some
\(\chi(\lambda) = \sum_\mu a_\mu e^\mu\). Well also have
\(A(\rho) \qty{ \sum_\mu a_\mu e^\mu } = A(\lambda + \rho)\). This will
reduce to equating coefficients of two formal sums, which will result in
a system of linear equations.

\hypertarget{friday-october-16}{%
\section{Friday, October 16}\label{friday-october-16}}

\hypertarget{example-weyls-character-formula}{%
\subsection{Example: Weyl's Character
Formula}\label{example-weyls-character-formula}}

Review: suppose the following is invariant under the Weyl group, so
\(\sum a_\mu e^\mu \in {\mathbb{Z}}[X(T)]^W\). In this case, we have an
equality
\begin{align*}   \sum a_\mu e^\mu = \sum a_\mu \chi(\mu) ,\end{align*}
where
\(\chi(\mu) = \sum_{i\geq 0} (-1)^i \operatorname{char}~H^i(\mu)\). We
also had a relation
\begin{align*}   \chi(w\cdot \mu) = (-1)^{\ell(w)} \chi(\mu) = \operatorname{sgn}(w) \chi(\mu) .\end{align*}

Now let \(\lambda \in X(T) \otimes{\mathbb{Q}}\), then we defined
\begin{align*}   A(\lambda) = \sum_{w\in W} \operatorname{sgn}(w) e^{w\lambda} \in {\mathbb{Z}}[X(T) \otimes{\mathbb{Q}}] .\end{align*}

We obtain

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(w' A(\lambda) = \operatorname{sgn}(w') A(\lambda)\)
\item
  \(A(\mu) A(\lambda) = {\mathbb{Z}}[X(T) \otimes{\mathbb{Q}}]^W\).
\end{enumerate}

\begin{theorem}[Weyl's Character Formula]

\begin{theorem}[Weyl's Character Formula]

\begin{align*}   \lambda\in X(T) \implies \chi(\lambda) = {A(\lambda + \rho) \over A(\lambda)} .\end{align*}

As a special case when \(\lambda \in X(T)_+\), all higher sheaf
cohomology vanishes and thus
\begin{align*}   \operatorname{char}~H^0(\lambda) = {A(\lambda + \rho) \over A(\lambda)} .\end{align*}

\end{theorem}

\end{theorem}

\begin{proof}

\begin{proof}

We first perform a \emph{reindexing} step:
\begin{align*}   \sum_{w, w'} \operatorname{sgn}(w\cdot w') e^{w(\lambda+\rho) + w'\rho} &= \sum_{w, w'} \operatorname{sgn}(w^{-1} w') e^{w(\lambda+\rho) + w'\rho} \\ &= \sum_{w, y} \operatorname{sgn}(y) e^{w(\lambda+\rho) + wy\rho} && y = w^{-1}w' \implies w' = wy \\ &= \sum_{w, y} \operatorname{sgn}(y) e^{w(\lambda + \rho + y\rho)} .\end{align*}

Now let \(\lambda\in X(T)\), we then compute
\begin{align*}   A(\lambda + \rho) A(\rho) &= \sum_{w} \operatorname{sgn}(w) e^{w(\lambda + \rho)} + \sum_{w'} \operatorname{sgn}(w') e^{w'(\lambda + \rho)}  \\ &= \sum_{w, w'} \operatorname{sgn}(ww') e^{w(\lambda + \rho) + w'\rho} \\ &=  \sum_{w, w'} \operatorname{sgn}(w') e^{w(\lambda + \rho + w'\rho)} && \text{from reindexing above, setting } y\mathrel{\vcenter{:}}= w' \\ &= \sum_{w, w'} \operatorname{sgn}(w') \chi\qty{w(\lambda + \rho + w'\rho)} \\ &= \sum_{w, w'} \operatorname{sgn}(w') \chi\qty{w\cdot (\lambda + w'\rho + w^{-1} \rho)} && \text{definition of dot action}\\ &= \sum_{w, w'} \operatorname{sgn}(ww') \chi\qty{\lambda + w'\rho + w\rho }  && \text{swapping } w\leadsto w^{-1}   .\end{align*}

Note that \(\chi\) can be introduced since
\(A(\lambda + \rho)A(\rho) \in {\mathbb{Z}}[X(T) \otimes{\mathbb{Q}}]^{W\cdot}\).

\todo[inline]{Not sure, double check.}

We can now conclude that
\begin{align*}   A(\rho)^2 = \sum_{w, w'} \operatorname{sgn}(ww') e^{w\rho + w' \rho} .\end{align*}
Since this quantity is \(W{\hbox{-}}\)invariant, since it's a square, we
can move the \(\chi\) inside:
\begin{align*}   \chi(\lambda) \qty{ \sum a_\mu e^\mu } = \sum a_\mu \chi(\lambda + \mu) \\ \implies \chi(\lambda) A(\rho)^2 = \sum_{w, w'} \operatorname{sgn}(ww') \chi(\lambda + w\rho + w'\rho) ,\end{align*}
which is exactly what the first calculation resulted in. So we can
conclude
\begin{align*}   A(\lambda + \rho) A(\rho) = \chi(\lambda) A(\rho)^2 .\end{align*}
Note that \(A(\rho) \neq 0\) since \(w\rho \neq \rho\) unless
\(w=\text{id}\). Thus we are actually working in
\({\mathbb{Z}}[X(T) + {\mathbb{Z}}\rho]\), which is an integral domain,
and thus we can apply cancellation laws to obtains
\begin{align*}   A(\lambda + \rho) = \chi(\lambda) A(\rho) .\end{align*}

\end{proof}

\end{proof}

\begin{example}

\begin{example}

Let \(G = \operatorname{GL}_3(k)\), which has a natural 3-dimensional
representation \(V\). Let \(\lambda = (1,0,0)\), so \(L(1,0,0) = V\).
This is a polynomial representation, so by permuting we can obtain
\begin{align*}   \operatorname{char}~V = e^{(1,0,0)} + e^{(0,1,0)} + e^{(0,0,1)} = \chi(1,0,0) ,\end{align*}
where the last equality holds since \(\lambda\) is dominant.

We can write \(\rho = (2,1,0)\), since the fundamental weights are given
by \(w_1 = (1,0,0)\) and \(w_2 = (1,1,0)\) (since we're in an
\({\text{SL}}_2\) and/or \(A_2\) situation). We then obtain
\(\lambda + \rho = (3,1,0)\), and since \(W= S_3\),
\begin{align*}   A(\lambda + \rho) = \sum_{w\in W} \operatorname{sgn}(w) e^{w(\lambda + \rho)} = e^{(3,1,0)} - e^{(1,3,0)} +  e^{(1,0,3)} -  e^{(0,1,3)} +  e^{(0,3,1)} -  e^{(3,0,1)} .\end{align*}

Thus
\begin{align*}   A(\rho) = e^{(2,1,0)} - e^{(1,2,0)} +  e^{(1,0,2)} -  e^{(0,1,2)} +  e^{(0,2,1)} -  e^{(2,0,1)} .\end{align*}

We can then compute
\begin{align*}   \chi(1,0,0) A(\rho) = &e^{(3,1,0)} - e^{(2,2,0)} +  e^{(2,0,2)}  -e^{(1,1,2)} +  e^{(1,2,1)} - e^{(3,0,1)} +  \\ &e^{(2,2,0)} - e^{(1,3,0)} +  e^{(1,1,2)} -  e^{(0,2,2)} +  e^{(0,3,1)} -  e^{(2,1,1)} +  \\ &e^{(2,1,1)} - e^{(1,2,1)} +  e^{(1,0,3)} -  e^{(0,1,3)} +  e^{(0,2,2)} -  e^{(2,0,2)} .\end{align*}

After cancellation, you'll find that this expression is equal to
\(A(\lambda + \rho)\).

\end{example}

\end{example}

\hypertarget{strong-linkage-principle}{%
\subsection{Strong Linkage Principle}\label{strong-linkage-principle}}

We'll consider representations in characteristic zero, so we can take
\(k={\mathbb{C}}\). Let \(G\) bet a complex simple group,
\({\mathfrak{g}}= \operatorname{Lie}(G)\), \(t\) a maximal torus, \(X\)
the weights, and \(X_+\) the dominant weights. We have a correspondence
\Large
\begin{align*}   \left\{{\substack{(g, t)}}\right\} \iff \left\{{\substack{(\Phi, W)}}\right\} \end{align*}
\normalsize

where \(\Phi\) is an irreducible root system and \(W\) is the Weyl
group. We'll have a set of simple roots \(\Delta\subseteq \Phi^+\). For
\(\lambda\in X\), we have
\begin{align*}   Z(\lambda) = U({\mathfrak{g}}) \otimes_{U({\mathfrak{b}}^+)} \lambda \twoheadrightarrow L(\lambda) .\end{align*}

Then \(\lambda \in X_+ \iff L(\lambda)\) is finite dimensional. We have
\(W\) acting on \(X\) via reflections, which we can extend to a dot
action
\begin{align*}   w\cdot \lambda = w(\lambda + \rho) - \rho, \hspace{4em} \rho = {1\over 2}\sum_{\alpha\in\Phi^+} \alpha .\end{align*}

We define Category \({\mathcal{O}}\) which has objects
\({\mathfrak{g}}{\hbox{-}}\)modules with a weight space decomposition
which is locally finite wrt \({\mathfrak{n}}^+\).

\hypertarget{linkage-in-category-mathcalo}{%
\subsubsection{\texorpdfstring{Linkage in Category
\({\mathcal{O}}\)}{Linkage in Category \{\textbackslash mathcal\{O\}\}}}\label{linkage-in-category-mathcalo}}

Set \(Z(\lambda) = \Delta(\lambda)\), then
\begin{align*}   [Z(\lambda) : L(\mu)] \neq 0 \implies \lambda \in W\cdot \mu .\end{align*}
The LHS is computed by evaluating certain Kazhdan-Lusztig polynomials at
\(x=1\).

\begin{example}

\begin{example}

Let \(\Phi= A_2\), then

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-16-14-43-26.png}
\caption{Image}
\end{figure}

\({\mathcal{O}}_0\) is the principal block, and the irreducibles
correspond to \(\left\{{L(w\cdot 0) ~{\text{s.t.}}~w\in W}\right\}\),
and the number of irreducibles in given by
\({\left\lvert {W} \right\rvert}\). In this case, there is only 1
finite-dimensional module in any given block of category
\({\mathcal{O}}\).

\end{example}

\end{example}

\begin{example}

\begin{example}

For \(\Phi = A_1\), we have the following situation:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-16-14-46-27.png}
\caption{Image}
\end{figure}

In \({\mathcal{O}}_0\), there are two irreducible representations given
by the Verma modules \(L(0), L(-2)\), and we find that

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-16-14-48-12.png}
\caption{Image}
\end{figure}

In this case, the projectives are given by

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-16-14-51-51.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\hypertarget{monday-october-19}{%
\section{Monday, October 19}\label{monday-october-19}}

\todo[inline]{Missing notes from first 10m! See phone screenshot.}

\hypertarget{representations-in-positive-characteristic}{%
\subsection{Representations in Positive
Characteristic}\label{representations-in-positive-characteristic}}

We have the following setup:
\begin{align*}   G && \text{a semisimple, simply connected algebraic group} \\ k && \text{an algebraically closed field of characteristic $p>0$} \\ T && \text{a maximal torus} \\ B && \text{a Borel (negative roots)} \\ X(T) = X && \text{weights} \\ X(T)_+ = X_+ && \text{dominant weights} \\ \Phi && \text{roots} .\end{align*}

For \(\lambda \in X_+\), we consider the induced module
\(H^0(\lambda) = \operatorname{Ind}_B^G \lambda\). Not that this is not
a simple module in general, so we instead ask about its composition
factors.

Question: For all \(\lambda, \mu \in X_+\), what are the multiplicities
\([H^0(\lambda): L(\mu)]\).

\begin{example}

\begin{example}

Let \(G = {\text{SL}}_2(k)\), so \(\Phi = A_1\). Then
\(\lambda \in X_+ = \left\{{0,1,2,\cdots}\right\}\) as we know from
standard facts in lie algebras. Define
\(X_1 = \left\{{0, 1, \cdots, p-1}\right\}\), then
\(\dim H^0(\lambda) = \lambda + 1\). We can write the weight
\(p{\hbox{-}}\)adically as \(\lambda = \sum_{i=0}^t \lambda_i p^i\) for
some \(\lambda_j\in X_1\). Thus
\(L(\lambda) = L(\lambda_0) \bigotimes_{i=1}^t L(\lambda_i)^{(i)}\).

Consider \(p=3, \lambda = 7\), then \(\dim H^0(7) = 8\). We can write
\(7\) 3-adically as \(7 = (1)3^0 + (2)3^1\), and so
\begin{align*}   L(7) \cong L(1) \otimes L(2)^{(1)} .\end{align*} The
first summand is 2-dimensional, and the second is 3-dimensional, so
\(L(7)\) is 6-dimensional. Note that \(L(7) \hookrightarrow H^0(7)\).

We can calculate the weights in the tensor product: the first has
weights \(\left\{{\pm 1}\right\}\), we take the adjoint weights in the
second factor and multiply by the twist 3 to get
\(\left\{{2\cdot 3, 0\cdot 3, -2\cdot 3}\right\}\). Taking all
combinations of sums from these yields
\(\left\{{7,5,1,-1,-5,-7}\right\}\).

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-19-14-14-46.png}
\caption{Comparing what's left over}
\end{figure}

Since \(\pm 3\) are left over, we know \([H^0(7): L(3)] \neq 0\). We can
continue with \(3 = (1)3^1\) and write \(L(3) = L(1)^{(1)}\). We get
weights of the form \(1\cdot 3, 1\cdot -3\), so nothing is left over and
we're done. We thus get a decomposition

\begin{center}
\begin{tikzcd}
 & & L(3) \ar[dd] \\
H^0(7): & & \\
 & & L(7)
\end{tikzcd}
\end{center}

Note the difference to Verma modules in category \({\mathcal{O}}\): we
have to consider the action of the \emph{affine} Weyl group, where
\(W_a \mathrel{\vcenter{:}}= W \rtimes p{\mathbb{Z}}\Phi\). Here we have
hyperplanes at \(p-1, 2p-1, 3p-1\), and 7 is \emph{linked} to 3 (in the
same orbit) for this action:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-19-14-21-35.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

\begin{quote}
Once characters are known, can find composition factors.
\end{quote}

\hypertarget{affine-weyl-group}{%
\subsection{Affine Weyl Group}\label{affine-weyl-group}}

Letting \(a\in {\mathbb{N}}\), we have
\(W_a = W\rtimes a({\mathbb{Z}}\Phi)\) where \({\mathbb{Z}}\Phi\) is the
root lattice. Note that there are other variants:

\begin{itemize}
\tightlist
\item
  \(W_a = W\rtimes a({\mathbb{Z}}\Phi^\vee)\),
\item
  \(W_{\text{ext}} = W \rtimes X(T)\).
\end{itemize}

So we set \(W_p = W\rtimes p({\mathbb{Z}}\Phi)\) where \(p\) is a prime.
What's in this group? We know it contains ``products'' of reflections
with translations. We find that \(W_p\) is generated by
\begin{align*}   s_{\beta, np}(\lambda) = \lambda - {\left\langle {\lambda},~{\beta^\vee} \right\rangle}\beta + np \beta .\end{align*}

It is also the case that \(W_p\) acts on \(X(T)\) and there exists a dot
action
\begin{align*}   w\cdot \lambda = w(\lambda + \rho) - \rho .\end{align*}

\begin{example}

\begin{example}

Consider \(A_1\), so \(\alpha = 2\). We consider what the stabilizer is:
\begin{align*}   s_{\alpha, np}\cdot \lambda &= \lambda \\ s_{\alpha, np}(\lambda + \rho) - \rho &= \lambda \\ (\lambda + \rho) - {\left\langle {\lambda _ \rho},~{\alpha^\vee} \right\rangle}\alpha + np\alpha - \rho &= \lambda .\end{align*}

After cancellation in the last line above, we obtain
\begin{align*}   \lambda = np-1 ,\end{align*} which exactly yields the
\(p-1, 2p-1, \cdots\) we saw before.

\end{example}

\end{example}

\begin{example}

\begin{example}

Consider \(A_2\). We obtain ``alcoves'':

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-19-14-36-02.png}
\caption{Image}
\end{figure}

\end{example}

\end{example}

We can get a stronger version of weak linkage, which we'll just call
linkage:

\begin{theorem}[Linkage]

\begin{theorem}[Linkage]

\begin{align*}   [H^0(\lambda): L(\mu)] \neq 0 \implies \lambda \in W_p \cdot \mu .\end{align*}

\end{theorem}

\end{theorem}

\begin{warning}

\begin{warning}

These are difficult to compute in general, or to even detect when
they're zero. For \(p\gg 0\), these multiplicities are computed via
Kazhdan-Lusztig polynomials.

\end{warning}

\end{warning}

\hypertarget{ordering-of-weights}{%
\subsubsection{Ordering of Weights}\label{ordering-of-weights}}

There is a partial ordering on the weight lattice given by
\begin{align*}   \mu \leq \lambda \iff \lambda - \mu = \sum_{\alpha\in \Phi^+} n_\alpha \alpha, \quad n_\alpha \geq 0 .\end{align*}

\begin{definition}[Strong Linkage]

\begin{definition}[Strong Linkage]

For \(\mu, \lambda \in X(T)\), we say \(\mu\) is \textbf{strongly
linked} to \(\lambda\), denoted \(\mu \uparrow \lambda\), if there
exists a sequence of weights \(\mu_1, \cdots, \mu_r \in X(T)\) and
reflections \(s_1, \cdots, s_r\) such that
\begin{align*}   \mu \leq \mu_1 = s_1 \cdot \mu \leq \mu_2 = s_2\cdot \mu 1 \leq \cdots \leq s_r \mu_{r-1} .\end{align*}

\end{definition}

\end{definition}

\begin{remark}

\begin{remark}

Note that

\begin{itemize}
\tightlist
\item
  \(\mu \uparrow \lambda \implies \mu \leq \lambda\), so this is
  stronger than the usual linkage
\item
  \(\mu \uparrow \lambda \implies \mu \in W_p \cdot \lambda\).
\end{itemize}

\end{remark}

\end{remark}

\begin{theorem}[Strong Linkage Principle]

\begin{theorem}[Strong Linkage Principle]

\begin{align*}   [H^0(\lambda): L(\mu)] \neq 0 \implies \lambda \in \mu \uparrow \lambda .\end{align*}

Moreover, there is a version of strong linkage for \(H^i(\lambda)\) for
\(i> 1\).

\end{theorem}

\end{theorem}

\begin{quote}
Next time: history of strong linkage, and translation functors.
\end{quote}

\hypertarget{wednesday-october-21}{%
\section{Wednesday, October 21}\label{wednesday-october-21}}

\hypertarget{strong-linkage}{%
\subsection{Strong Linkage}\label{strong-linkage}}

Let \(G\) be a semisimple algebraic group and
\(k = \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}_p\mkern-1.5mu}\mkern 1.5mu\).
We found that the \emph{affine Weyl group} \(W_p\) played an important
role here.

\begin{theorem}[Strong Linkage I]

\begin{theorem}[Strong Linkage I]

Suppose we have a nonzero composition factor in the induced/Weyl module.
Then
\begin{align*} [H^0 \lambda : L(\mu)] \neq 0]\implies \mu \uparrow \lambda .\end{align*}

In other words, there's a series of reflections sending \(\mu\) to
\(\lambda\) which doesn't increase it's value in the ordering.

\end{theorem}

\end{theorem}

\begin{theorem}[Strong Linkage II]

\begin{theorem}[Strong Linkage II]

Let \(\lambda \in X(T)\) with
\({\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} \geq 0\)
for all \(\alpha\in \Delta\). Suppose \(\mu \in X(T)_+\).
\begin{align*} [H^i w\cdot \lambda : L(\mu)] \neq 0 \text{ for some } i\geq 0 \implies \mu \uparrow \lambda .\end{align*}

\end{theorem}

\end{theorem}

\begin{remark}

\begin{remark}

Note that this is tells us slightly more than Bott-Borel-Weil.

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

There is some history here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Verma conjectured the first theorem in 1971.
\item
  Humphreys (1971) proved it for
  \(Z_r(\lambda) = \operatorname{Ind}_{B_r}^{G_r} \lambda\).
\item
  Strong Linkage II proved by Andersen in 1980.
\item
  Jantzen proved strong linkage for \(Z_r\), which implies strong
  linkage for \(V(\lambda)\).
\item
  Doty (1987) proved strong linkage for \(Z_r(\lambda)\) as a
  \(G_rT{\hbox{-}}\)modules, which implies strong linkage for
  \(V(\lambda)\).
\end{enumerate}

\end{remark}

\end{remark}

\begin{remark}

\begin{remark}

One application is the following: let \(\lambda, \mu \in X(T)_+\), then
\(\operatorname{Ext}_G^n(L(\lambda), L(\mu)) \neq 0\) for some
\(n \geq 0\). This implies that \(\lambda \in W_p \cdot \mu\).

We can consider some cases

\begin{itemize}
\tightlist
\item
  If \(n=0\), we're reduced to previous situations.
\item
  If \(n=1\), we can conclude that \(L(\lambda)\) is in the second socle
  layer of \(H^0 \mu\), or vice-versa. In either case,
  \(\lambda \in W_p \cdot \mu\).
\end{itemize}

We can compute this ext by considering an minimal injective resolution
\begin{align*}   0 \to L(\mu) \to I_0 = I(\mu) \to I_1 \to \cdots .\end{align*}

We can conclude that
\begin{align*} [I(\mu) : H^0(\sigma)] = [H^0(\sigma): L(\mu)] \neq 0 .\end{align*}
by Brauer-Humphreys reciprocity, so \(\sigma \in W_p \cdot \mu\).
Similarly \([I(\mu): L(\gamma)] \neq 0\) implies that
\(\gamma \in W_p \cdot \mu\), and continuing in this way we can write
\begin{align*} I_1 = \bigoplus_{j=1}^t I(\gamma_j)  \text{ with each }  \gamma_j \in W_p \cdot \mu .\end{align*}
So all of these weights are strongly linked to \(\mu\).

But then we know \(\operatorname{Ext}_G^n (L(\lambda), L(\mu)) \neq 0\)
is a subquotient of \(\hom_G(L(\lambda), I_n)\), which thus can not be
zero. So \(\lambda \in W_p \cdot \mu\)

\end{remark}

\end{remark}

\hypertarget{translation-functors}{%
\subsection{Translation Functors}\label{translation-functors}}

Consider the case from category \({\mathcal{O}}\), e.g.~by taking
\({\mathfrak{g}}= {\mathfrak{sl}}_3({\mathbb{C}})\):

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-21-14-19-53.png}
\caption{Image}
\end{figure}

For \(\lambda\) a regular weight, the principal block \(\mathcal{B}_0\)
is Morita-equivalent to \(\mathcal{B}_\lambda\). If \(\mu\) is a
singular weight, then by Jantzen there are translation functors

\begin{align*}   T_\lambda^\mu: \mathcal{B}_\lambda &\to \mathcal{B}_\mu \\ T_\mu^\lambda: \mathcal{B}_\mu &\to \mathcal{B}_\lambda .\end{align*}

In the case where \(G\) is a semisimple algebraic group and
\(k = \mkern 1.5mu\overline{\mkern-1.5mu{\mathbb{F}}\mkern-1.5mu}\mkern 1.5mu_p\),
we have the following picture instead:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-21-14-23-24.png}
\caption{Image}
\end{figure}

\hypertarget{blocks}{%
\subsubsection{Blocks}\label{blocks}}

Two simple modules \(S, T\) are in the same \emph{block} if we have a
sequence \(T_1, \cdots, T_n\) such that \(S=T_1\) and \(T_n = T\) where
\(\operatorname{Ext}^1(T_i, T_{i+1}) \neq 0\).

\begin{lemma}[?]

\begin{lemma}[?]

Let \(M, M'\) be \(H{\hbox{-}}\)modules and \(\mathcal{B}(H)\) be the
blocks of \(H\). Then

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(M = \bigoplus_{b\in \mathcal{B}(H)} M_b\) where
  \(M_b = \sum_{M'\leq M} M'\) the sum of all submodules such that \(M\)
  has composition in the block \(b\).
\item
  \begin{align*} \operatorname{Ext}_H^i(, M') = \prod_{b\in\mathcal{B}(H)} \operatorname{Ext}_H^i (M_b, M_b') \end{align*}
\end{enumerate}

\end{lemma}

\end{lemma}

So the question becomes, what are the blocks of \(H\)? Let
\(\lambda \in X(T)_+\), so we can define \(L(\lambda)\), and let
\(b(\lambda)\) be the \(G{\hbox{-}}\)block containing \(L(\lambda)\).

We have \(b(\lambda) \in \mathcal{B}(G)\) and \(b(\lambda)\)
\(\subseteq X(T)_+ \cap W_p \cdot \lambda\), i.e.~we have strong
linkage.

\begin{quote}
Here we refer to \(b(\lambda)\) as both the block and the weights it
contains.
\end{quote}

\begin{theorem}[Donkin]

\begin{theorem}[Donkin]

Let \(\lambda \in X(T)_+\) be a dominant weight and let
\(r\in {\mathbb{Z}}\) be the largest integer such that
\(p^r {~\Bigm|~}{\left\langle { \lambda + \rho},~{\alpha^\vee} \right\rangle}\)
for all \(\alpha\in \Phi\). Then
\begin{align*} b(\lambda) = W_p^{(r)} \cdot \lambda \cap X(T)_+ \text{ where } W_p^{(r)} = W\rtimes p^r {\mathbb{Z}}\Phi .\end{align*}

\end{theorem}

\end{theorem}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(B\) be a \(G{\hbox{-}}\)module and \(\lambda \in X(T)\). Set
\({\operatorname{pr}}_\lambda V\) to be the sum of all submodules of
\(V\) with composition factors of the form \(L(\mu)\) where
\(\mu \in W_p \cdot \lambda\). Then

\begin{itemize}
\item
  \(V = \bigoplus_{\lambda \in Z} {\operatorname{pr}}_\lambda V\) where
  \(Z\) are representatives of the \(W_p\) orbits, i.e.~one
  representative from each alcove in the weight lattice.
\item
  \begin{align*} \operatorname{Ext}_G^i(V, V') = \prod_{\lambda \in Z} \operatorname{Ext}_G^i ({\operatorname{pr}}_\lambda V, {\operatorname{pr}}_\lambda V') \end{align*}
\item
  The projection functors \({\operatorname{pr}}_\lambda({\,\cdot\,})\)
  are exact.
\end{itemize}

\begin{quote}
Note that this still works for singular weights, not just regular
weights.
\end{quote}

\end{proposition}

\end{proposition}

\begin{example}

\begin{example}

We can compute
\begin{align*}   {\operatorname{pr}}_\lambda L(\mu) =  \begin{cases} 0 &= \lambda \not\in W_p \cdot \mu \\ L(\mu) &= \lambda \in W_p \cdot \mu \end{cases} .\end{align*}

Similarly, by strong linkage,
\begin{align*}   {\operatorname{pr}}_\lambda H^i(\mu) = \begin{cases} 0 &= \lambda \not\in W_p \cdot \mu \\ H^i(\mu) &= \lambda \in W_p \cdot \mu \end{cases} .\end{align*}

\end{example}

\end{example}

Recall that
\begin{align*}   \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\mathrel{\vcenter{:}}=\left\{{ \lambda \in X(T) ~{\text{s.t.}}~ 0 \leq {\left\langle {\lambda + \rho},~{\beta^\vee} \right\rangle} \leq p \,\, \forall \beta\in\Phi^+ }\right\} .\end{align*}
For every
\(\mu, \lambda \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\),
consider \(\mu - \lambda \in X(T)\). Then there is a way to conjugate it
under the ordinary \(W\) action to land in the dominant region,
i.e.~some unique \(\nu\) such that
\(\nu \in X(T)_+ \cap W(\mu - \lambda)\).

\begin{definition}[Translation Functors]

\begin{definition}[Translation Functors]

Define
\begin{align*}   T_\lambda^\mu V =  {\operatorname{pr}}_\mu \qty{ L(\nu) \otimes {\operatorname{pr}}_\lambda V } .\end{align*}

So project to \(\lambda\), tensor with an irreducible representation,
then project to \(\mu\). This is an exact functor
\begin{align*}   T_{\lambda}^\mu: G{\hbox{-}}\mathrm{mod} &\to G{\hbox{-}}\mathrm{mod} .\end{align*}

\end{definition}

\end{definition}

Next time: we'll show that \(T_\lambda^\mu\) and \(T_\mu^\lambda\) form
an adjoint pair. Note that if \(\mu, \lambda\) are in the same block,
these are the exact functor which product the categorical equivalence.

\hypertarget{friday-october-23}{%
\section{Friday, October 23}\label{friday-october-23}}

\hypertarget{facets}{%
\subsection{Facets}\label{facets}}

\(W_p\) has a dot action on
\(E \mathrel{\vcenter{:}}= X(T) \otimes_{\mathbb{Z}}{\mathbb{R}}\).

\begin{definition}[Facet]

\begin{definition}[Facet]

We can write \(\Phi^+ = \Phi_0^+ \cup\Phi_1^+\), and define the
\emph{facet} as
\begin{align*}   F \mathrel{\vcenter{:}}=\left\{{ \lambda \in E ~{\text{s.t.}}~{\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} = n_\alpha p\,\, \forall\alpha\in \Phi_0^+(F),\,\, (n_\alpha - 1)p < {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} < n_\alpha p \,\,\forall \alpha\in \Phi_1^+(F) }\right\} .\end{align*}
The first condition corresponds to being on a vertex in the following
diagram, while the second corresponds to being in the interior of a
triangle:

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-23-14-04-42.png}
\caption{Image}
\end{figure}

\end{definition}

\end{definition}

\begin{definition}[Closure of a Facet]

\begin{definition}[Closure of a Facet]

The \emph{closure} of a facet is defined by replacing the second
condition with an inequality.
\begin{align*}   \mkern 1.5mu\overline{\mkern-1.5muF\mkern-1.5mu}\mkern 1.5mu \mathrel{\vcenter{:}}=\left\{{ \lambda \in E ~{\text{s.t.}}~{\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} = n_\alpha p\,\,  \forall\alpha\in \Phi_0^+(F),\,\, n_\alpha - 1 \leq  {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} \leq n_\alpha p  \,\,\forall \alpha\in \Phi_1^+(F) }\right\} .\end{align*}
This includes all of the walls of the triangle.

\end{definition}

\end{definition}

\begin{definition}[Upper Closure of a Facet]

\begin{definition}[Upper Closure of a Facet]

Finally, we define the \emph{upper closure} by replacing one inequality
with a strict inequality:
\begin{align*}   \widehat{F} \mathrel{\vcenter{:}}=\left\{{ \lambda \in E ~{\text{s.t.}}~{\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} = n_\alpha p\,\, \forall\alpha\in \Phi_0^+(F),\,\, n_\alpha - 1 < {\left\langle {\lambda + \rho},~{\alpha^\vee} \right\rangle} \leq n_\alpha p \,\,\forall \alpha\in \Phi_1^+(F) }\right\} .\end{align*}

\end{definition}

\end{definition}

\begin{definition}[Alcove]

\begin{definition}[Alcove]

A facet is called an \textbf{alcove} for \(W_p\) iff
\(\Phi_0^+(F) = \emptyset\).

\end{definition}

\end{definition}

\begin{remark}

\begin{remark}

Note that if \(F\) is an alcove for \(W_p\), then \(\widehat{F}\) is a
fundamental domain for \(W_p\curvearrowright E\) with the dot action.

\end{remark}

\end{remark}

\hypertarget{translation-functors-1}{%
\subsection{Translation Functors}\label{translation-functors-1}}

Let
\(\lambda, \mu\in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\),
and define
\begin{align*}   T_\lambda^\mu({\,\cdot\,}) \mathrel{\vcenter{:}}= {\operatorname{pr}}_\mu \qty{ L(\nu_1) \otimes{\operatorname{pr}}_\lambda({\,\cdot\,}) }\\ \text{where }  \nu_1 \in X(T)_+ \cap W(\mu-\lambda) .\end{align*}

This is exact as a composition of exact functors, since we're tensoring
over a field and taking projections (which are themselves exact).

\begin{lemma}[?]

\begin{lemma}[?]

Let \(\lambda,\mu\in X(T)\) and \(M\) be a finite-dimensional
\(G{\hbox{-}}\)module. Then the functors
\begin{align*}   F({\,\cdot\,}) &\mathrel{\vcenter{:}}={\operatorname{pr}}_\mu \circ \qty{M\otimes_k {\,\cdot\,}} \circ {\operatorname{pr}}_\lambda \\ G({\,\cdot\,}) &\mathrel{\vcenter{:}}={\operatorname{pr}}_\lambda \circ \qty{M^\vee\otimes_k {\,\cdot\,}} \circ {\operatorname{pr}}_\mu \\ \end{align*}
define an adjoint pair,
i.e.~\begin{align*}   \hom_\mathcal{C}(G({\,\cdot\,}), A) &= \hom_\mathcal{D}({\,\cdot\,}, F(A)) \\ \hom_\mathcal{C}({\,\cdot\,}, G(A)) &= \hom_\mathcal{D}( F({\,\cdot\,}), {\,\cdot\,}) \\ .\end{align*}

\end{lemma}

\end{lemma}

\begin{proof}

\begin{proof}

Let \(V, V'\) be \(G{\hbox{-}}\)modules. Then
\begin{align*}   \hom_G(FV, V')  &= \hom_G( {\operatorname{pr}}_\mu\qty{ M\otimes{\operatorname{pr}}_\lambda V  }, V') \\ &= \hom_G(  M\otimes{\operatorname{pr}}_\lambda V  , {\operatorname{pr}}_\mu V') \\ &= \hom_G(  {\operatorname{pr}}_\mu \qty{ M\otimes{\operatorname{pr}}_\lambda V }  , {\operatorname{pr}}_\mu V') \\ &= \hom_G(  {\operatorname{pr}}_\lambda V  , M^\vee\otimes_k {\operatorname{pr}}_\mu V') \\ &= \hom_G(  {\operatorname{pr}}_\lambda V  , {\operatorname{pr}}_\lambda\qty{ M^\vee\otimes_k {\operatorname{pr}}_\mu V'} ) \\ &= \hom_G(  V  , {\operatorname{pr}}_\lambda\qty{ M^\vee\otimes_k {\operatorname{pr}}_\mu V'} ) \\ &= \hom_G(V, GV') .\end{align*}

Here we've used the fact that there no nontrivial homs between distinct
blocks.

\end{proof}

\end{proof}

\begin{theorem}[?]

\begin{theorem}[?]

Let
\(\lambda, \mu \in \mkern 1.5mu\overline{\mkern-1.5muC\mkern-1.5mu}\mkern 1.5mu_{\mathbb{Z}}\)
are in the closure of the bottom alcove. Then
\(T_\lambda^\mu \leftrightarrows T_\mu \lambda\) form an adjoint pair.

\end{theorem}

\end{theorem}

\begin{proof}

\begin{proof}

Applying the previous corollary, we just need to show the last equality
in the following:
\begin{align*}   T_\lambda^\mu({\,\cdot\,})  &= {\operatorname{pr}}_\mu \qty{ L(\nu_1) \otimes{\operatorname{pr}}_\lambda({\,\cdot\,}) } \\ &= {\operatorname{pr}}_\lambda \qty{ L(\nu_1)^\vee\otimes{\operatorname{pr}}_\mu({\,\cdot\,}) } \\ &=_? T_\mu^\lambda .\end{align*}

This requires checking the highest weight condition on
\(L(\nu_1)^\vee= L(-w_0 \nu_1)\). We know
\(\nu_1 \in X(T)_+ \cap W(\mu-\lambda)\), so if
\(\nu_1 = w(\mu-\lambda)\), we have
\(-w_0 \nu_1 = w_0 w (\lambda - \mu) \in W(\lambda - \mu)\). Since
\(-w_0 \nu_1 \in X(T)_+\), this verifies the condition.

\end{proof}

\end{proof}

\begin{remark}

\begin{remark}

The adjointness can be extended from homs to exts:
\begin{align*}   \operatorname{Ext}_G^i(T_\mu^\lambda V, V' ) \cong \operatorname{Ext}_G^i(V, T_\lambda^\mu V') .\end{align*}

\end{remark}

\end{remark}

\hypertarget{technical-preliminaries}{%
\subsection{Technical Preliminaries}\label{technical-preliminaries}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \(\lambda \in X(T)\) and
  \begin{align*}         \sum_\mu a(\mu) e^\mu \in {\mathbb{Z}}[X(T)]^W       \end{align*}
  is \(W{\hbox{-}}\)invariant, then we proved that
  \begin{align*}         \chi(\lambda)       \qty{       \sum_\mu a(\mu) e^{\mu}       }       = \sum_\mu a(\mu) \chi(\lambda + \mu)       .\end{align*}
\item
  If \({\operatorname{pr}}_\lambda V = V\), then we have
  \begin{align*}       \operatorname{char}~(M\otimes V)      &= \operatorname{char}~(M) \operatorname{char}~(V) \\     &= \operatorname{char}~(M) \qty{\sum_{w\in W_p} a_w \chi(w\cdot\lambda) } \\     &= \qty{ \sum_{\nu \in X(T)} \dim M_\nu e^\nu } \qty{\sum_{w\in W_p} a_w \chi(w\cdot\lambda) }     .\end{align*}
\end{enumerate}

\begin{proposition}[?]

\begin{proposition}[?]

Let \(V\) be a finite dimensional \(G{\hbox{-}}\)module with
\({\operatorname{pr}}_\lambda V = V\). Write
\begin{align*}   \operatorname{char}~(V) = \sum_{w\in W_p} a_w \chi(w\cdot \lambda) \quad a_w\in {\mathbb{Z}},\, \text{cofinitely zero} .\end{align*}
Then
\begin{align*}   \operatorname{char}~\qty{{\operatorname{pr}}_\lambda \qty{ M\otimes V } } =  \sum_{w\in W} a_w  \qty{ \sum_{\substack{ \nu \in X(T) \\ \lambda + \nu \in W_p\cdot \mu} } \dim M_\nu } \chi(w\cdot (\lambda + \nu) ) .\end{align*}

\end{proposition}

\end{proposition}

\begin{proof}

\begin{proof}

Using (1) and (2), we can write
\begin{align*}   \operatorname{char}~(M\otimes V) =  \sum_{w\in W_p} a_w \sum_\nu \dim M_\nu \chi(w\cdot \lambda + \nu) .\end{align*}
Note that \(w\cdot \lambda + \nu = w\cdot (\lambda + w_1 \nu)\) where
\(w_1 \mathrel{\vcenter{:}}= w^{-1}\), using the fact that the dot
action acts linearly on the second term. This comes from the following
computation:
\begin{align*}   w\cdot(\mu_1 + \mu_2) &= w(\mu_1 + \mu_2 - \rho) + \rho \\ &= w(\mu_1 + \rho) - \rho + w\mu_2 \\ &= w\cdot \mu_1 + w\mu_2 .\end{align*}

We can thus write
\begin{align*}   \operatorname{char}~(M\otimes V) =  \sum_{w\in W_p} a_w \qty{ \sum_\nu \dim M_\nu \chi(w\cdot \qty{\lambda + \nu})} ,\end{align*}
since summing over \(\nu\) is the same as summing over \(w\nu\) for any
\(w\).

To get \(\operatorname{char}~({\operatorname{pr}}_\mu(M\otimes V))\),
take \(\chi(w(\lambda + \nu))\) and note that
\(\lambda + \nu \in W_p \cdot \mu\).

\end{proof}

\end{proof}

\begin{remark}

\begin{remark}

Given \(\operatorname{char}~V\), one can write
\(\operatorname{char}~T_\lambda^\mu V\). What will be important here are
stabilizers. If \(\lambda\) is on a wall, the stabilizer fixes the
corresponding hyperplane.

\begin{figure}
\centering
\includegraphics{figures/image_2020-10-23-14-50-27.png}
\caption{Image}
\end{figure}

\end{remark}

\end{remark}

\newpage

\newpage
\section{Indices}
\listoftodos[List of Todos]

% Hook into amsthm environments to list them.
\renewcommand{\listtheoremname}{Definitions}
\listoftheorems[ignoreall,show={definition}, numwidth=3.5em]

\renewcommand{\listtheoremname}{Theorems}
\listoftheorems[ignoreall,show={theorem,proposition}, numwidth=3.5em]

\renewcommand{\listtheoremname}{Exercises}
\listoftheorems[ignoreall,show={exercise}, numwidth=3.5em]

\listoffigures


\printbibliography[title=Bibliography]


\end{document}
