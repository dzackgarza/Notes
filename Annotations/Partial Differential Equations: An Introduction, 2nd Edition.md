# Partial Differential Equations: An Introduction, 2nd Edition, Walter A. Strauss/home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf## Notes<hr>## HighlightsPREFACE Our understanding of the fundamental processes of the natural world is based to a large extent on partial differential equations. Examples are the vibrations of solids, the flow of fluids, the diffusion of chemicals, the spread of heat, the structure of molecules, the interactions of photons and electrons, and the radiation of electromagnetic waves. Partial differential equations also play a central role in modern mathematics, especially in geometry and analysis. The availability of powerful computers is gradually shifting the emphasis in partial differential equations away from the analytical computation of solutions and toward both their numerical analysis and the qualitative theory. This book provides an introduction to the basic properties of partial differential equations (PDEs) and to the techniques that have proved useful in analyzing them. My purpose is to provide for the student a broad perspective on the subject, to illustrate the rich variety of phenomena encompassed by it, and to impart a working knowledge of the most important techniques of analysis of the solutions of the equations. One of the most important techniques is the method of separation of variables. Many textbooks heavily emphasize this technique to the point of excluding other points of view. The problem with that approach is that only certain kinds of partial differential equations can be solved by it, whereas others cannot. In this book it plays a very important but not an overriding role. Other texts, which bring in relatively advanced theoretical ideas, require too much mathematical knowledge for the typical undergraduate student. I have tried to minimize the advanced concepts and the mathematical jargon in this book. However, because partial differential equations is a subject at the forefront of research in modern science, I have not hesitated to mention advanced ideas as further topics for the ambitious student to pursue. This is an undergraduate textbook. It is designed for juniors and seniors who are science, engineering, or mathematics majors. Graduate students, especially in the sciences, could surely learn from it, but it is in no way conceived of as a graduate text. The main prerequisite is a solid knowledge of calculus, especially multivariate. The other prerequisites are small amounts of ordinary differential v PREFACE Our understanding of the fundamental processes of the natural world is based to a large extent on partial differential equations. Examples are the vibrations of solids, the flow of fluids, the diffusion of chemicals, the spread of heat, the structure of molecules, the interactions of photons and electrons, and the radiation of electromagnetic waves. Partial differential equations also play a central role in modern mathematics, especially in geometry and analysis. The availability of powerful computers is gradually shifting the emphasis in partial differential equations away from the analytical computation of solutions and toward both their numerical analysis and the qualitative theory. This book provides an introduction to the basic properties of partial differential equations (PDEs) and to the techniques that have proved useful in analyzing them. My purpose is to provide for the student a broad perspective on the subject, to illustrate the rich variety of phenomena encompassed by it, and to impart a working knowledge of the most important techniques of analysis of the solutions of the equations. One of the most important techniques is the method of separation of variables. Many textbooks heavily emphasize this technique to the point of excluding other points of view. The problem with that approach is that only certain kinds of partial differential equations can be solved by it, whereas others cannot. In this book it plays a very important but not an overriding role. Other texts, which bring in relatively advanced theoretical ideas, require too much mathematical knowledge for the typical undergraduate student. I have tried to minimize the advanced concepts and the mathematical jargon in this book. However, because partial differential equations is a subject at the forefront of research in modern science, I have not hesitated to mention advanced ideas as further topics for the ambitious student to pursue. This is an undergraduate textbook. It is designed for juniors and seniors who are science, engineering, or mathematics majors. Graduate students, especially in the sciences, could surely learn from it, but it is in no way conceived of as a graduate text. The main prerequisite is a solid knowledge of calculus, especially multivariate. The other prerequisites are small amounts of ordinary differential v (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=7" target="_blank">Walter A. Strauss 7</a>)</p>
One of the most important techniques is the method of separation of variables. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=7" target="_blank">Walter A. Strauss 7</a>)</p>
F(x, y, u, u x , u y ) = 0. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=13" target="_blank">Walter A. Strauss 13</a>)</p>
This is the most general PDE in two independent variables of first order. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=13" target="_blank">Walter A. Strauss 13</a>)</p>
The most general (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=13" target="_blank">Walter A. Strauss 13</a>)</p>
second-order PDE in two independent variables is (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=13" target="_blank">Walter A. Strauss 13</a>)</p>
F(x, y, u, u x , u y , u x x , u x y , u yy ) = 0. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=13" target="_blank">Walter A. Strauss 13</a>)</p>
Examples 3, 5, and 6 are distinguished from the others in that they are not “linear. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=14" target="_blank">Walter A. Strauss 14</a>)</p>
2 CHAPTER 1 WHERE PDEs COME FROM Some examples of PDEs (all of which occur in physical theory) are: 1. u x + u y = 0 (transport) 2. u x + yu y = 0 (transport) 3. u x + uu y = 0 (shock wave) 4. u x x + u yy = 0 (Laplace’s equation) 5. u tt − u x x + u 3 = 0 (wave with interaction) 6. u t + uu x + u x x x = 0 (dispersive wave) 7. u tt + u x x x x = 0 (vibrating bar) √ 8. u t − iux x = 0 (i = −1) (quantum mechanics) Each of these has two independent variables, written either as x and y or as x and t. Examples 1 to 3 have order one; 4, 5, and 8 have order two; 6 has order three; and 7 has order four. Examples 3, 5, and 6 are distinguished from the others in that they are not “linear.” We shall now explain this concept. Linearity means the following. Write the equation in the form lu = 0, where l is an operator. That is, if v is any function, lv is a new function. For instance, l = ∂/∂x is the operator that takes v into its partial derivative vx . In Example 2, the operator l is l = ∂/∂ x + y∂/∂ y. (lu = u x + yu y .) The definition we want for linearity is l(u + v) = lu + lv l(cu) = clu (3) for any functions u, v and any constant c. Whenever (3) holds (for all choices of u, v, and c), l is called linear operator. The equation lu = 0 (4) is called linear if l is a linear operator. Equation (4) is called a homogeneous linear equation. The equation lu = g, (5) where g = 0 is a given function of the independent variables, is called an inhomogeneous linear equation. For instance, the equation (cos x y 2 )u x − y 2 u y = tan(x 2 + y 2 ) (6) is an inhomogeneous linear equation. As you can easily verify, five of the eight equations above are linear as well as homogeneous. Example 5, on the other hand, is not linear because although (u + v)x x = u x x + vx x and (u + v)tt = u tt + vtt satisfy property (3), the cubic term does not: (u + v)3 = u 3 + 3u 2 v + 3uv 2 + v 3 = u 3 + v 3 . 2 CHAPTER 1 WHERE PDEs COME FROM Some examples of PDEs (all of which occur in physical theory) are: 1. u x + u y = 0 (transport) 2. u x + yu y = 0 (transport) 3. u x + uu y = 0 (shock wave) 4. u x x + u yy = 0 (Laplace’s equation) 5. u tt − u x x + u 3 = 0 (wave with interaction) 6. u t + uu x + u x x x = 0 (dispersive wave) 7. u tt + u x x x x = 0 (vibrating bar) √ 8. u t − iux x = 0 (i = −1) (quantum mechanics) Each of these has two independent variables, written either as x and y or as x and t. Examples 1 to 3 have order one; 4, 5, and 8 have order two; 6 has order three; and 7 has order four. Examples 3, 5, and 6 are distinguished from the others in that they are not “linear.” We shall now explain this concept. Linearity means the following. Write the equation in the form lu = 0, where l is an operator. That is, if v is any function, lv is a new function. For instance, l = ∂/∂x is the operator that takes v into its partial derivative vx . In Example 2, the operator l is l = ∂/∂ x + y∂/∂ y. (lu = u x + yu y .) The definition we want for linearity is l(u + v) = lu + lv l(cu) = clu (3) for any functions u, v and any constant c. Whenever (3) holds (for all choices of u, v, and c), l is called linear operator. The equation lu = 0 (4) is called linear if l is a linear operator. Equation (4) is called a homogeneous linear equation. The equation lu = g, (5) where g = 0 is a given function of the independent variables, is called an inhomogeneous linear equation. For instance, the equation (cos x y 2 )u x − y 2 u y = tan(x 2 + y 2 ) (6) is an inhomogeneous linear equation. As you can easily verify, five of the eight equations above are linear as well as homogeneous. Example 5, on the other hand, is not linear because although (u + v)x x = u x x + vx x and (u + v)tt = u tt + vtt satisfy property (3), the cubic term does not: (u + v)3 = u 3 + 3u 2 v + 3uv 2 + v 3 = u 3 + v 3 . (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=14" target="_blank">Walter A. Strauss 14</a>)</p>
2 CHAPTER 1 WHERE PDEs COME FROM Some examples of PDEs (all of which occur in physical theory) are: 1. u x + u y = 0 (transport) 2. u x + yu y = 0 (transport) 3. u x + uu y = 0 (shock wave) 4. u x x + u yy = 0 (Laplace’s equation) 5. u tt − u x x + u 3 = 0 (wave with interaction) 6. u t + uu x + u x x x = 0 (dispersive wave) 7. u tt + u x x x x = 0 (vibrating bar) √ 8. u t − iux x = 0 (i = −1) (quantum mechanics) Each of these has two independent variables, written either as x and y or as x and t. Examples 1 to 3 have order one; 4, 5, and 8 have order two; 6 has order three; and 7 has order four. Examples 3, 5, and 6 are distinguished from the others in that they are not “linear.” We shall now explain this concept. Linearity means the following. Write the equation in the form lu = 0, where l is an operator. That is, if v is any function, lv is a new function. For instance, l = ∂/∂x is the operator that takes v into its partial derivative vx . In Example 2, the operator l is l = ∂/∂ x + y∂/∂ y. (lu = u x + yu y .) The definition we want for linearity is l(u + v) = lu + lv l(cu) = clu (3) for any functions u, v and any constant c. Whenever (3) holds (for all choices of u, v, and c), l is called linear operator. The equation lu = 0 (4) is called linear if l is a linear operator. Equation (4) is called a homogeneous linear equation. The equation lu = g, (5) where g = 0 is a given function of the independent variables, is called an inhomogeneous linear equation. For instance, the equation (cos x y 2 )u x − y 2 u y = tan(x 2 + y 2 ) (6) is an inhomogeneous linear equation. As you can easily verify, five of the eight equations above are linear as well as homogeneous. Example 5, on the other hand, is not linear because although (u + v)x x = u x x + vx x and (u + v)tt = u tt + vtt satisfy property (3), the cubic term does not: (u + v)3 = u 3 + 3u 2 v + 3uv 2 + v 3 = u 3 + v 3 . (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=14" target="_blank">Walter A. Strauss 14</a>)</p>
We’ll study, almost exclusively, linear systems with constant coefficients. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=15" target="_blank">Walter A. Strauss 15</a>)</p>
For an ODE of order m, you get m arbitrary constants. (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=15" target="_blank">Walter A. Strauss 15</a>)</p>
1.1 WHAT IS A PARTIAL DIFFERENTIAL EQUATION? 3 The advantage of linearity for the equation lu = 0 is that if u and v are both solutions, so is (u + v). If u1 , . . . , un are all solutions, so is any linear combination  n c1 u 1 (x) + · · · + cn u n (x) = c j u j (x) (cj = constants). j=1 (This is sometimes called the superposition principle.) Another consequence of linearity is that if you add a homogeneous solution [a solution of (4)] to an inhomogeneous solution [a solution of (5)], you get an inhomogeneous solution. (Why?) The mathematical structure that deals with linear combinations and linear operators is the vector space. Exercises 5–10 are review problems on vector spaces. We’ll study, almost exclusively, linear systems with constant coefficients. Recall that for ODEs you get linear combinations. The coefficients are the arbitrary constants. For an ODE of order m, you get m arbitrary constants. Let’s look at some PDEs. Example 1. Find all u(x, y) satisfying the equation uxx = 0. Well, we can integrate once to get ux = constant. But that’s not really right since there’s another variable y. What we really get is ux (x, y) = f (y), where f (y) is arbitrary. Do it again to get u(x, y) = f (y)x + g(y). This is the solution formula. Note that there are two arbitrary functions in the solution. We see this as well in the next two examples.  Example 2. Solve the PDE u x x + u = 0. Again, it’s really an ODE with an extra variable y. We know how to solve the ODE, so the solution is u = f (y) cos x + g(y) sin x, where again f (y) and g(y) are two arbitrary functions of y. You can easily check this formula by differentiating twice to verify that u x x = −u.  Example 3. Solve the PDE uxy = 0. This isn’t too hard either. First let’s integrate in x, regarding y as fixed. So we get u y (x, y) = f (y). Next let’s integrate in y regarding x as fixed. We get the solution u(x, y) = F(y) + G(x), where F ′ = f.  1.1 WHAT IS A PARTIAL DIFFERENTIAL EQUATION? 3 The advantage of linearity for the equation lu = 0 is that if u and v are both solutions, so is (u + v). If u1 , . . . , un are all solutions, so is any linear combination  n c1 u 1 (x) + · · · + cn u n (x) = c j u j (x) (cj = constants). j=1 (This is sometimes called the superposition principle.) Another consequence of linearity is that if you add a homogeneous solution [a solution of (4)] to an inhomogeneous solution [a solution of (5)], you get an inhomogeneous solution. (Why?) The mathematical structure that deals with linear combinations and linear operators is the vector space. Exercises 5–10 are review problems on vector spaces. We’ll study, almost exclusively, linear systems with constant coefficients. Recall that for ODEs you get linear combinations. The coefficients are the arbitrary constants. For an ODE of order m, you get m arbitrary constants. Let’s look at some PDEs. Example 1. Find all u(x, y) satisfying the equation uxx = 0. Well, we can integrate once to get ux = constant. But that’s not really right since there’s another variable y. What we really get is ux (x, y) = f (y), where f (y) is arbitrary. Do it again to get u(x, y) = f (y)x + g(y). This is the solution formula. Note that there are two arbitrary functions in the solution. We see this as well in the next two examples.  Example 2. Solve the PDE u x x + u = 0. Again, it’s really an ODE with an extra variable y. We know how to solve the ODE, so the solution is u = f (y) cos x + g(y) sin x, where again f (y) and g(y) are two arbitrary functions of y. You can easily check this formula by differentiating twice to verify that u x x = −u.  Example 3. Solve the PDE uxy = 0. This isn’t too hard either. First let’s integrate in x, regarding y as fixed. So we get u y (x, y) = f (y). Next let’s integrate in y regarding x as fixed. We get the solution u(x, y) = F(y) + G(x), where F ′ = f.  (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=15" target="_blank">Walter A. Strauss 15</a>)</p>
1.1 WHAT IS A PARTIAL DIFFERENTIAL EQUATION? 3 The advantage of linearity for the equation lu = 0 is that if u and v are both solutions, so is (u + v). If u1 , . . . , un are all solutions, so is any linear combination  n c1 u 1 (x) + · · · + cn u n (x) = c j u j (x) (cj = constants). j=1 (This is sometimes called the superposition principle.) Another consequence of linearity is that if you add a homogeneous solution [a solution of (4)] to an inhomogeneous solution [a solution of (5)], you get an inhomogeneous solution. (Why?) The mathematical structure that deals with linear combinations and linear operators is the vector space. Exercises 5–10 are review problems on vector spaces. We’ll study, almost exclusively, linear systems with constant coefficients. Recall that for ODEs you get linear combinations. The coefficients are the arbitrary constants. For an ODE of order m, you get m arbitrary constants. Let’s look at some PDEs. Example 1. Find all u(x, y) satisfying the equation uxx = 0. Well, we can integrate once to get ux = constant. But that’s not really right since there’s another variable y. What we really get is ux (x, y) = f (y), where f (y) is arbitrary. Do it again to get u(x, y) = f (y)x + g(y). This is the solution formula. Note that there are two arbitrary functions in the solution. We see this as well in the next two examples.  Example 2. Solve the PDE u x x + u = 0. Again, it’s really an ODE with an extra variable y. We know how to solve the ODE, so the solution is u = f (y) cos x + g(y) sin x, where again f (y) and g(y) are two arbitrary functions of y. You can easily check this formula by differentiating twice to verify that u x x = −u.  Example 3. Solve the PDE uxy = 0. This isn’t too hard either. First let’s integrate in x, regarding y as fixed. So we get u y (x, y) = f (y). Next let’s integrate in y regarding x as fixed. We get the solution u(x, y) = F(y) + G(x), where F ′ = f.  (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=15" target="_blank">Walter A. Strauss 15</a>)</p>
1.1 WHAT IS A PARTIAL DIFFERENTIAL EQUATION? 3 The advantage of linearity for the equation lu = 0 is that if u and v are both solutions, so is (u + v). If u1 , . . . , un are all solutions, so is any linear combination  n c1 u 1 (x) + · · · + cn u n (x) = c j u j (x) (cj = constants). j=1 (This is sometimes called the superposition principle.) Another consequence of linearity is that if you add a homogeneous solution [a solution of (4)] to an inhomogeneous solution [a solution of (5)], you get an inhomogeneous solution. (Why?) The mathematical structure that deals with linear combinations and linear operators is the vector space. Exercises 5–10 are review problems on vector spaces. We’ll study, almost exclusively, linear systems with constant coefficients. Recall that for ODEs you get linear combinations. The coefficients are the arbitrary constants. For an ODE of order m, you get m arbitrary constants. Let’s look at some PDEs. Example 1. Find all u(x, y) satisfying the equation uxx = 0. Well, we can integrate once to get ux = constant. But that’s not really right since there’s another variable y. What we really get is ux (x, y) = f (y), where f (y) is arbitrary. Do it again to get u(x, y) = f (y)x + g(y). This is the solution formula. Note that there are two arbitrary functions in the solution. We see this as well in the next two examples.  Example 2. Solve the PDE u x x + u = 0. Again, it’s really an ODE with an extra variable y. We know how to solve the ODE, so the solution is u = f (y) cos x + g(y) sin x, where again f (y) and g(y) are two arbitrary functions of y. You can easily check this formula by differentiating twice to verify that u x x = −u.  Example 3. Solve the PDE uxy = 0. This isn’t too hard either. First let’s integrate in x, regarding y as fixed. So we get u y (x, y) = f (y). Next let’s integrate in y regarding x as fixed. We get the solution u(x, y) = F(y) + G(x), where F ′ = f.  1.1 WHAT IS A PARTIAL DIFFERENTIAL EQUATION? 3 The advantage of linearity for the equation lu = 0 is that if u and v are both solutions, so is (u + v). If u1 , . . . , un are all solutions, so is any linear combination  n c1 u 1 (x) + · · · + cn u n (x) = c j u j (x) (cj = constants). j=1 (This is sometimes called the superposition principle.) Another consequence of linearity is that if you add a homogeneous solution [a solution of (4)] to an inhomogeneous solution [a solution of (5)], you get an inhomogeneous solution. (Why?) The mathematical structure that deals with linear combinations and linear operators is the vector space. Exercises 5–10 are review problems on vector spaces. We’ll study, almost exclusively, linear systems with constant coefficients. Recall that for ODEs you get linear combinations. The coefficients are the arbitrary constants. For an ODE of order m, you get m arbitrary constants. Let’s look at some PDEs. Example 1. Find all u(x, y) satisfying the equation uxx = 0. Well, we can integrate once to get ux = constant. But that’s not really right since there’s another variable y. What we really get is ux (x, y) = f (y), where f (y) is arbitrary. Do it again to get u(x, y) = f (y)x + g(y). This is the solution formula. Note that there are two arbitrary functions in the solution. We see this as well in the next two examples.  Example 2. Solve the PDE u x x + u = 0. Again, it’s really an ODE with an extra variable y. We know how to solve the ODE, so the solution is u = f (y) cos x + g(y) sin x, where again f (y) and g(y) are two arbitrary functions of y. You can easily check this formula by differentiating twice to verify that u x x = −u.  Example 3. Solve the PDE uxy = 0. This isn’t too hard either. First let’s integrate in x, regarding y as fixed. So we get u y (x, y) = f (y). Next let’s integrate in y regarding x as fixed. We get the solution u(x, y) = F(y) + G(x), where F ′ = f.  (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=15" target="_blank">Walter A. Strauss 15</a>)</p>
30 CHAPTER 1 WHERE PDEs COME FROM Convert to the new variables using the chain rule: ∂  ∂ξk ∂ = ∂ xi k ∂ xi ∂ξ k and    ∂  ∂ u xi x j = bki bl j u. k ∂ξk l ∂ξl Therefore the PDE is converted to     aij u xi x j = bki aij bl j u ξk ξl . (7) i, j k,l i, j (Watch out that on the left side u is considered as a function of x, whereas on the right side it is considered as a function of ξ.) So you get a second-order equation in the new variables ξ, but with the new coefficient matrix given within the parentheses. That is, the new matrix is BAt B, where A = (aij ) is the original coefficient matrix, the matrix B = (bij ) defines the transformation, and tB = (bji ) is its transpose. Now a theorem of linear algebra says that for any symmetric real matrix A, there is a rotation B (an orthogonal matrix with determinant 1) such that BAt B is the diagonal matrix ⎛ ⎞ d1 ⎜ ⎜ d2 ⎟ ⎟ · ⎜ ⎟ t BA B = D = ⎜ ⎟. (8) ⎜ ⎟ ⎜ ⎜ · ⎟ ⎟ ⎝ · ⎠ dn The real numbers d1 , . . . , dn are the eigenvalues of A. Finally, a change of scale would convert D into a diagonal matrix with each of the d’s equal to +1, −1, or 0. (This is what we did, in effect, early in this section for the case n = 2.) Thus any PDE of the form (5) can be converted by means of a linear change of variables into a PDE with a diagonal coefficient matrix. Definition. The PDE (5) is called elliptic if all the eigenvalues d1 , . . . , dn are positive or all are negative. [This is equivalent to saying that the original coefficient matrix A (or −A) is positive definite.] The PDE is called hyperbolic if none of the d1 , . . . , dn vanish and one of them has the opposite sign from the (n − 1) others. If none vanish, but at least two of them are positive and at least two are negative, it is called ultrahyperbolic. If exactly 30 CHAPTER 1 WHERE PDEs COME FROM Convert to the new variables using the chain rule: ∂  ∂ξk ∂ = ∂ xi k ∂ xi ∂ξ k and    ∂  ∂ u xi x j = bki bl j u. k ∂ξk l ∂ξl Therefore the PDE is converted to     aij u xi x j = bki aij bl j u ξk ξl . (7) i, j k,l i, j (Watch out that on the left side u is considered as a function of x, whereas on the right side it is considered as a function of ξ.) So you get a second-order equation in the new variables ξ, but with the new coefficient matrix given within the parentheses. That is, the new matrix is BAt B, where A = (aij ) is the original coefficient matrix, the matrix B = (bij ) defines the transformation, and tB = (bji ) is its transpose. Now a theorem of linear algebra says that for any symmetric real matrix A, there is a rotation B (an orthogonal matrix with determinant 1) such that BAt B is the diagonal matrix ⎛ ⎞ d1 ⎜ ⎜ d2 ⎟ ⎟ · ⎜ ⎟ t BA B = D = ⎜ ⎟. (8) ⎜ ⎟ ⎜ ⎜ · ⎟ ⎟ ⎝ · ⎠ dn The real numbers d1 , . . . , dn are the eigenvalues of A. Finally, a change of scale would convert D into a diagonal matrix with each of the d’s equal to +1, −1, or 0. (This is what we did, in effect, early in this section for the case n = 2.) Thus any PDE of the form (5) can be converted by means of a linear change of variables into a PDE with a diagonal coefficient matrix. Definition. The PDE (5) is called elliptic if all the eigenvalues d1 , . . . , dn are positive or all are negative. [This is equivalent to saying that the original coefficient matrix A (or −A) is positive definite.] The PDE is called hyperbolic if none of the d1 , . . . , dn vanish and one of them has the opposite sign from the (n − 1) others. If none vanish, but at least two of them are positive and at least two are negative, it is called ultrahyperbolic. If exactly (<a href="file:////home/zack/Dropbox/Library/Walter A. Strauss/Partial Differential Equations_ An Introduction, 2nd Edition (452)/Partial Differential Equations_ An Introdu - Walter A. Strauss.pdf#page=42" target="_blank">Walter A. Strauss 42</a>)</p><hr>