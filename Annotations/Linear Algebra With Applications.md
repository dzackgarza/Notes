# Linear Algebra With Applications, Steven J. Leon
/home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf
## Notes
Examples of computing fundamental spaces (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=239" target="_blank">Steven J. Leon 239</a>)</p>
Derivation of least squares geometrically using the fundamental subspaces theorem (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=244" target="_blank">Steven J. Leon 244</a>)</p>
Fitting a degree n polynomial to a set of observations (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=248" target="_blank">Steven J. Leon 248</a>)</p>
Why orthonormal bases are important (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=266" target="_blank">Steven J. Leon 266</a>)</p>
Computing an integral without antiderivatives using norms (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=267" target="_blank">Steven J. Leon 267</a>)</p>
Parseval's Formula (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=267" target="_blank">Steven J. Leon 267</a>)</p>
How orthogonal matrices make least squares solutions much easier. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=270" target="_blank">Steven J. Leon 270</a>)</p><hr>
## Highlights
each of its rows is a multiple of yT and each of its column (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=94" target="_blank">Steven J. Leon 94</a>)</p>
vectors is a multiple of x. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=94" target="_blank">Steven J. Leon 94</a>)</p>
If the linear system Ax = b is consistent and x0 is a particular solution, then a vect (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=144" target="_blank">Steven J. Leon 144</a>)</p>
y will also be a solution if and only if y = x0 + z where z ∈ N(A). (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=144" target="_blank">Steven J. Leon 144</a>)</p>
A minimal spanning set is called a basis. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=149" target="_blank">Steven J. Leon 149</a>)</p>
Let x1 , x2 , . . . , xn be n vectors in Rn and let X = (x1 , . . . , xn ). The vectors x1 , x2 , . . . , (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=152" target="_blank">Steven J. Leon 152</a>)</p>
will be linearly dependent if and only if X is singular. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=152" target="_blank">Steven J. Leon 152</a>)</p>
ny subset of fewer than n linearly independent vectors can be extended (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=162" target="_blank">Steven J. Leon 162</a>)</p>
form a basis for V (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=162" target="_blank">Steven J. Leon 162</a>)</p>
The vector c defined in this way is called the (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=170" target="_blank">Steven J. Leon 170</a>)</p>
coordinate vector of v with respect to the ordered basis E and is denoted [v]E . (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=170" target="_blank">Steven J. Leon 170</a>)</p>
Thus the equatio (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=172" target="_blank">Steven J. Leon 172</a>)</p>
Sx = 0 has only the trivial solution and hence the matrix S is nonsingular. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=172" target="_blank">Steven J. Leon 172</a>)</p>
The rank of a matrix A, denoted rank(A), is the dimension of the row space of A. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=175" target="_blank">Steven J. Leon 175</a>)</p>
A linear system Ax = b is consistent if and only if b is in the column space of A (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=175" target="_blank">Steven J. Leon 175</a>)</p>
The linear system Ax = b is consistent for every b ∈ Rm if and (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=175" target="_blank">Steven J. Leon 175</a>)</p>
only if the column vectors of A span Rm . The system Ax = b has at most one solution (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=175" target="_blank">Steven J. Leon 175</a>)</p>
for every b ∈ Rm if and only if the column vectors of A are linearly independent. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=175" target="_blank">Steven J. Leon 175</a>)</p>
We cannot use the column vectors from U, since, in general, U and A have different (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=178" target="_blank">Steven J. Leon 178</a>)</p>
column spaces. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=178" target="_blank">Steven J. Leon 178</a>)</p>
The subspace Span(x1 , x2 , x3 , x4 ) is the same as the column space of the matrix (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=179" target="_blank">Steven J. Leon 179</a>)</p>
In particular, it is much easier to calculate the coordinates of a given vector v with respect to an orthonormal basis. Once these coordinates have been determined, they can be used to compute v. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=266" target="_blank">Steven J. Leon 266</a>)</p>
An n × n matrix Q is orthogonal if and only if QTQ = I (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=268" target="_blank">Steven J. Leon 268</a>)</p>
If the column vectors of A form an orthonormal set of vectors in Rm , then ATA = I and the solution to the least squares problem is x̂ = AT b (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=270" target="_blank">Steven J. Leon 270</a>)</p>
What if the columns of A are not orthonormal? In the next section we will learn a method for finding an orthonormal basis for R(A). From this method we will obtain a factorization of A into a product QR, where Q has an orthonormal set of column vectors and R is upper triangular. With this factorization, the least squares problem is easily solved. (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=271" target="_blank">Steven J. Leon 271</a>)</p>
However, the main difficulty with this method is that, in forming the normal equations, we may well end up transforming the problem into an ill-conditioned one (<a href="file:////home/zack/Dropbox/Library/Steven J. Leon/Linear Algebra With Applications (675)/Linear Algebra With Applications - Steven J. Leon.pdf#page=469" target="_blank">Steven J. Leon 469</a>)</p><hr>
